<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Guo Xudong's Blog·郭旭东的博客 – Kubernetes</title><link>https://guoxudong.io/tags/kubernetes/</link><description>Recent content in Kubernetes on Guo Xudong's Blog·郭旭东的博客</description><generator>Hugo -- gohugo.io</generator><language>zh</language><lastBuildDate>Wed, 17 Mar 2021 09:54:18 +0800</lastBuildDate><atom:link href="https://guoxudong.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Post: Kubectl Plugin 推荐（三）| 插件开发篇</title><link>https://guoxudong.io/post/kubectl-plugin-recommended-3/</link><pubDate>Wed, 17 Mar 2021 09:54:18 +0800</pubDate><guid>https://guoxudong.io/post/kubectl-plugin-recommended-3/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>之前的两篇文章中笔者推荐了一些好用的 Kubectl Plugin。但在实践中那些插件不一定能满足全部需求，这时不妨动手开发一个，花费时间不多，但却能极高的提升工作效率和使用体验。&lt;/p>
&lt;p>本篇文章就来讲解如何快速开发一款自己的 Kubectl Plugin。&lt;/p>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>Kubectl Plugin 的开发流程和注意事项：&lt;/p>
&lt;ul>
&lt;li>编写一个二进制可执行文件以 &lt;code>kubectl-xxx&lt;/code> 命名&lt;/li>
&lt;li>需要将可执行文件放在环境变量 &lt;code>PATH&lt;/code> 中&lt;/li>
&lt;li>之后就可以使用 &lt;code>kubectl xxx&lt;/code> 来调用了&lt;/li>
&lt;li>无法覆盖 &lt;code>kubectl&lt;/code> 内置的命令&lt;/li>
&lt;/ul>
&lt;p>二进制可执行文件可以是任何语言开发，本文主要讲解使用 go 语言开发，官方推荐使用 &lt;a href="https://github.com/kubernetes/cli-runtime/">cli-runtime&lt;/a> 项目，可以参考 &lt;a href="https://github.com/kubernetes/sample-cli-plugin">sample-cli-plugin&lt;/a> 示例。&lt;/p>
&lt;h2 id="使用-github-template">使用 GitHub Template&lt;/h2>
&lt;p>模板地址：https://github.com/replicatedhq/krew-plugin-template&lt;/p>
&lt;p>推荐使用 GitHub Template 创建 Plugin 项目，该模板遵循最佳实践开发，并集成了一些简化开发流程的工具，使用 &lt;a href="https://goreleaser.com/">GoReleaser&lt;/a> 和 GitHub Action 进行自动化发布。该 template 也是官方文档推荐的 &lt;strong>非官方 GitHub Template&lt;/strong>。&lt;/p>
&lt;h3 id="创建项目">创建项目&lt;/h3>
&lt;p>进入 krew-plugin-template 项目，点击 &lt;code>Use this template&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gomp3m8xjqj22w81naaqb.jpg" alt="使用模板">&lt;/p>
&lt;p>输入 &lt;code>Repository name&lt;/code>，点击 &lt;code>Create repository from template&lt;/code> 创建 repo&lt;/p>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1gomp5bbcl2j21fk0x4wis.jpg" alt="创建项目">&lt;/p>
&lt;h3 id="配置项目">配置项目&lt;/h3>
&lt;p>待项目创建完成后， clone 该项目并在本地通过终端进入该项目所在目录。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ git clone https://github.com/sunny0826/kubectl-demo.git
$ &lt;span style="color:#24909d">cd&lt;/span> kubectl-demo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 &lt;code>make setup&lt;/code> 命令开始配置&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gomq1rr8vzj20y80eg0wp.jpg" alt="set up">&lt;/p>
&lt;p>根据提示，填入 &lt;code>GitHub Organization or Username&lt;/code>、&lt;code>GitHub Repo Namek&lt;/code> 和 &lt;code>Plugin Name&lt;/code> 后，会自动对项目进行配置。&lt;/p>
&lt;h3 id="项目结构">项目结构&lt;/h3>
&lt;p>配置完成后，一个 Kubectl Plugin 项目的基本框架就完成了，结构如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">.
├── LICENSE
├── Makefile
├── README.md
├── cmd
│   └── plugin
│   ├── cli
│   │   └── root.go &lt;span style="color:#999;font-style:italic"># cli 配置&lt;/span>
│   └── main.go &lt;span style="color:#999;font-style:italic"># 项目入口&lt;/span>
├── deploy
│   └── krew
│   └── plugin.yaml &lt;span style="color:#999;font-style:italic"># krew-index 配置&lt;/span>
├── doc
│   └── USAGE.md
├── go.mod
├── go.sum
└── pkg
├── logger
│   └── logger.go
└── plugin
└── plugin.go &lt;span style="color:#999;font-style:italic"># 业务逻辑代码&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>接下来就是业务逻辑的开发，主要的业务逻辑代码就写在 &lt;code>pkg/plugn/plugin.go&lt;/code> 中；CLI 的相关配置，如 &lt;code>flag&lt;/code> 和子命令的配置则在 &lt;code>cmd/plugin/cli/root.go&lt;/code> 中。开发所需的 client-go 、k8s API 等资源也都已经集成在项目中，可直接使用。&lt;/p>
&lt;h3 id="构建测试">构建测试&lt;/h3>
&lt;p>在业务逻辑完成后，需要先在本地进行测试。使用 &lt;code>make bin&lt;/code> 命令可以将项目构建为可执行文件并用来测试，该命令会完成基础的 &lt;code>fmt&lt;/code>、&lt;code>vet&lt;/code> 测试并完成 &lt;code>build&lt;/code>。&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gomqjcj5krj21py0uiwnd.jpg" alt="make bin">&lt;/p>
&lt;h3 id="创建-release">创建 Release&lt;/h3>
&lt;p>在完成代码逻辑和测试后，就可以将其发布到 github release 了，GitHub Action 和 &lt;a href="https://goreleaser.com/">GoReleaser&lt;/a> 会自动完成 Release 相关操作，只需给项目打上 tag 并 push 代码，无需任何手动操作。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ git tag v0.1.0 -m &lt;span style="color:#ed9d13">&amp;#39;initial release&amp;#39;&lt;/span>
$ git push --tags
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>如果是首次 Release，会出现 Release 成功但是 GitHub Action 失败的情况，这里可以忽略，失败的是自动推送 PR 到 krew-index 的步骤。&lt;/p>
&lt;/blockquote>
&lt;h2 id="推送到-krew-index">推送到 krew-index&lt;/h2>
&lt;p>Release 完成后，就可以将已经开发好的 Kubectl Plugin 推送到 &lt;a href="https://github.com/kubernetes-sigs/krew-index">krew-index&lt;/a> 了，这样就可以使用 &lt;code>kubectl krew install&lt;/code> 安装了。&lt;/p>
&lt;h3 id="首次推送">首次推送&lt;/h3>
&lt;p>首次提交需要手动 fork krew-index 项目并提交 PR，拷贝 &lt;code>deploy/krew/plugin.yaml&lt;/code> 中的内容，根据 release &lt;code>checksums.txt&lt;/code> 内容补全不同平台可执行文件的 &lt;code>sha256&lt;/code> 和 &lt;code>description&lt;/code> 值，将其放入 &lt;code>plugin&lt;/code> 目录并提交 PR。&lt;/p>
&lt;h3 id="自动推送">自动推送&lt;/h3>
&lt;p>完成首次 PR 提交后，就可以使用 GitHub Action 自动提交 PR 到 krew-index 了，通过&lt;a href="https://github.com/rajatjindal/krew-release-bot"> krew-release-bot&lt;/a> 机器人自动提交的 PR 无需 review 自动 merge，大大降低了更新流程。&lt;/p>
&lt;p>使用这个 GitHub Action，首先需要一份 &lt;code>.krew.yaml&lt;/code> 配置文件，该项目作者提供了一个不错的工具，可以根据已经提交的 Kubectl Plugin 自动生成 &lt;code>.krew.yaml&lt;/code> 内容，将生成的配置拷贝到 &lt;code>.krew.yaml&lt;/code>，之后的 Release 成功后会自动提交 PR 到 krew-index。&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gomu5iw2ngj22bk116afg.jpg" alt="Krew Release Bot Helper">&lt;/p>
&lt;p>工具地址：https://rajatjindal.com/tools/krew-release-bot-helper/&lt;/p>
&lt;p>在 &lt;code>&amp;lt;your-git-root&amp;gt;/.github/workflows/release.yml&lt;/code> 添加配置（GitHub Template 中已包含该配置）：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>release&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">on&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">push&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tags&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#ed9d13">&amp;#39;v*.*.*&amp;#39;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">jobs&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">goreleaser&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">runs-on&lt;/span>:&lt;span style="color:#666"> &lt;/span>ubuntu-latest&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">steps&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>Checkout&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">uses&lt;/span>:&lt;span style="color:#666"> &lt;/span>actions/checkout@master&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>Setup Go&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">uses&lt;/span>:&lt;span style="color:#666"> &lt;/span>actions/setup-go@v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">with&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">go-version&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1.13&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>GoReleaser&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">uses&lt;/span>:&lt;span style="color:#666"> &lt;/span>goreleaser/goreleaser-action@v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">with&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>latest&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">args&lt;/span>:&lt;span style="color:#666"> &lt;/span>release --rm-dist&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">GITHUB_TOKEN&lt;/span>:&lt;span style="color:#666"> &lt;/span>${{ secrets.GITHUB_TOKEN }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>Update new version in krew-index&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">uses&lt;/span>:&lt;span style="color:#666"> &lt;/span>rajatjindal/krew-release-bot@v0.0.38&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>之后每次 Release 都会自动推送更新 PR，效果如下：&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1gomu9xo7gij21ym1rgdu7.jpg" alt="PR 自动合并">&lt;/p>
&lt;h2 id="注意事项">注意事项&lt;/h2>
&lt;p>官方提供了&lt;a href="https://krew.sigs.k8s.io/docs/developer-guide/develop/naming-guide/">插件命名指南&lt;/a>，大致有以下内容：&lt;/p>
&lt;ul>
&lt;li>使用小写字母和连字符，不要使用驼峰式命名&lt;/li>
&lt;li>表意明确，独一无二&lt;/li>
&lt;li>使用动词和资源类型命名，如 &lt;code>open-svc&lt;/code>&lt;/li>
&lt;li>如果是供应商插件，前缀请使用供应商，如 &lt;code>gke-login&lt;/code>&lt;/li>
&lt;li>不能包含 &lt;code>kube&lt;/code> 前缀&lt;/li>
&lt;li>避免资源缩写，如 &lt;code>debug-ingress&lt;/code> 而不能是 &lt;code>new-ing&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>同时 &lt;code>description&lt;/code> 要描述清楚，且每行不要操作 80 个字符，这样可以方便窄屏幕的用户使用。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>本篇为《Kubectl Plugin 推荐》系列最后一篇，授人以鱼不如授人以渔，开发一个 Kubectl Plugin 并不会花费很多时间，但根据实际使用情况，为 kubectl 增加更多的功能和拓展，大大提升工作效率和使用体验，非常值得一试。&lt;/p></description></item><item><title>Post: Kubectl Plugin 推荐（二）| 简化操作篇</title><link>https://guoxudong.io/post/kubectl-plugin-recommended-2/</link><pubDate>Tue, 09 Mar 2021 11:18:48 +0800</pubDate><guid>https://guoxudong.io/post/kubectl-plugin-recommended-2/</guid><description>
&lt;h2 id="补充">补充&lt;/h2>
&lt;p>开始介绍简化操作的插件之前，先补充一个增强可观测性的插件。&lt;/p>
&lt;h3 id="pod-lens">pod-lens&lt;/h3>
&lt;p>该插件使用树状图和表格展示 pod 相关资源，在排查问题可以非常方便的查看 Pod 相关资源信息和状态。&lt;/p>
&lt;p>项目地址：https://github.com/sunny0826/kubectl-pod-lens&lt;/p>
&lt;h4 id="安装">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install pod-lens
$ kubectl pod-lens --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例">示例&lt;/h4>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1godp0s6wj6j219014ugx8.jpg" alt="pod-lens">&lt;/p>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>&lt;a href="../kubectl-plugin-recommended">上一篇文章&lt;/a>中我们介绍一些提升观测性的 Kubectl Plugin，本篇笔者将继续推荐一些能够简化操作，提升工作效率的 Kubectl Plugin。&lt;/p>
&lt;h2 id="插件推荐">插件推荐&lt;/h2>
&lt;h3 id="iexec">iexec&lt;/h3>
&lt;p>工作中，我们经常会使用 &lt;code>kubectl exec&lt;/code> 命令进入容器中进行问题排查 和 debug。而在实际操作中，除了需要加 &lt;code>-it&lt;/code> 等参数外，还需要选择 Pod name 和 Container name，比较费事且经常操作失误。而 &lt;code>kubectl-iexec&lt;/code> 这款插件很好的简化了这一系列操作。&lt;/p>
&lt;p>项目地址：https://github.com/gabeduke/kubectl-iexec&lt;/p>
&lt;h4 id="安装-1">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install iexec
$ kubectl iexec --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="用法">用法&lt;/h4>
&lt;p>该插件极大的简化了 &lt;code>kubectl exec&lt;/code> 操作。其可以模糊匹配 pod name，如果只有一个 pod 匹配输入的名称，将会直接进入该 Pod。&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1godnu79ttxj20rs0fkq5e.jpg" alt="单个匹配">&lt;/p>
&lt;p>如果匹配到多个 Pod，则会出现下拉菜单来选择要进入的 Pod 和 Container。&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1godnw22airj20pw0gajts.jpg" alt="多个匹配">&lt;/p>
&lt;h3 id="open-svc">open-svc&lt;/h3>
&lt;p>日常工作中，常常需要使用 &lt;code>kubectl port-forward&lt;/code> 命令来在本地访问部署在 k8s 中的服务，&lt;code>open-svc&lt;/code> 则简化了这一步骤，输入命令，相应服务会直接在浏览器中弹出。&lt;/p>
&lt;p>项目地址：https://github.com/superbrothers/kubectl-open-svc-plugin&lt;/p>
&lt;h4 id="安装-2">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install open-svc
$ kubectl open-svc --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-1">示例&lt;/h4>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1godnz8c836g20ok0aymzp.gif" alt="open-svc">&lt;/p>
&lt;h3 id="view-secret">view-secret&lt;/h3>
&lt;p>当需要查看 Secret 中的信息时，往往需要执行以下步骤：&lt;/p>
&lt;ol>
&lt;li>&lt;code>kubectl get secret &amp;lt;secret&amp;gt; -o yaml&lt;/code>&lt;/li>
&lt;li>复制 secret 中的数据&lt;/li>
&lt;li>&lt;code>echo &amp;quot;&amp;lt;secret-data&amp;gt;&amp;quot; | base64 -d&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>而 &lt;code>view-secret&lt;/code> 这个插件就简化了这一步骤，直接在终端打印解码后的内容。&lt;/p>
&lt;p>项目地址：https://github.com/elsesiy/kubectl-view-secret&lt;/p>
&lt;h4 id="安装-3">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install view-secret
$ kubectl view-secret --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-2">示例&lt;/h4>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1godoks7qwbj20oa11oq9n.jpg" alt="view-secret">&lt;/p>
&lt;h3 id="ksniff">ksniff&lt;/h3>
&lt;p>当需要在 k8s 中进行抓包时，&lt;code>ksniff&lt;/code> 是个不错的选择，该插件使用 tcpdump 和 Wireshark 在 k8s 中进行抓包。&lt;/p>
&lt;p>项目地址：https://github.com/eldadru/ksniff&lt;/p>
&lt;h4 id="安装-4">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install sniff
$ kubectl sniff --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-3">示例&lt;/h4>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1godop5l1hqg21bp0oval7.gif" alt="ksniff">&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>在日常工作中使用好这些插件，可以极大的提高工作效率，将运维人员从繁琐的工作中释放出来。&lt;strong>把有意义的事情做的有意思&lt;/strong>，这也是工作的乐趣所在吧。&lt;/p></description></item><item><title>Post: Kubectl Plugin 推荐（一）| 可观测性篇</title><link>https://guoxudong.io/post/kubectl-plugin-recommended/</link><pubDate>Thu, 04 Mar 2021 17:36:15 +0800</pubDate><guid>https://guoxudong.io/post/kubectl-plugin-recommended/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>&lt;code>kubectl&lt;/code> 作为最重要的 Kubernetes 客户端工具一直以来都被广泛的应用与各种场景，其对于 YAML 工程师的作用就像战士手中的枪，用的好不好完全可以影响到 YAML 工程师的整体工作效率。虽然 &lt;code>kubectl&lt;/code> 本身迭代的速度非常快，但是也很难满足所有人的全部需求，这时 kubectl 的插件机制就可以很好的弥补这个问题。&lt;/p>
&lt;h2 id="krew">Krew&lt;/h2>
&lt;p>Krew 是 kubernetes SIG 项目，是 &lt;code>kubectl&lt;/code> 的插件管理器，其提供了类似 brew 的包管理功能，用户可以方便的使用 krew 安装和使用 kubectl 插件，极大的方便了 kubectl 插件的开发和管理。&lt;/p>
&lt;h3 id="安装">安装&lt;/h3>
&lt;p>Krew 虽然也可以使用 &lt;code>brew&lt;/code> 进行安装，但是官方貌似并不积极支持该方式。这里使用如下命令脚本来完成安装：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">(
&lt;span style="color:#24909d">set&lt;/span> -x; &lt;span style="color:#24909d">cd&lt;/span> &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>mktemp -d&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> &amp;amp;&amp;amp;
&lt;span style="color:#40ffff">OS&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>uname | tr &lt;span style="color:#ed9d13">&amp;#39;[:upper:]&amp;#39;&lt;/span> &lt;span style="color:#ed9d13">&amp;#39;[:lower:]&amp;#39;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> &amp;amp;&amp;amp;
&lt;span style="color:#40ffff">ARCH&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>uname -m | sed -e &lt;span style="color:#ed9d13">&amp;#39;s/x86_64/amd64/&amp;#39;&lt;/span> -e &lt;span style="color:#ed9d13">&amp;#39;s/\(arm\)\(64\)\?.*/\1\2/&amp;#39;&lt;/span> -e &lt;span style="color:#ed9d13">&amp;#39;s/aarch64$/arm64/&amp;#39;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> &amp;amp;&amp;amp;
curl -fsSLO &lt;span style="color:#ed9d13">&amp;#34;https://github.com/kubernetes-sigs/krew/releases/latest/download/krew.tar.gz&amp;#34;&lt;/span> &amp;amp;&amp;amp;
tar zxvf krew.tar.gz &amp;amp;&amp;amp;
&lt;span style="color:#40ffff">KREW&lt;/span>=./krew-&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">OS&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">_&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">ARCH&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> &amp;amp;&amp;amp;
&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#40ffff">$KREW&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> install krew
)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>脚本运行成功后，将 &lt;code>$HOME/.krew/bin&lt;/code> 添加到 &lt;code>PATH&lt;/code> 中，在 &lt;code>.bashrc&lt;/code> 或 &lt;code>.zshrc&lt;/code> 文件中添加以下内容：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#24909d">export&lt;/span> &lt;span style="color:#40ffff">PATH&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">KREW_ROOT&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">:-&lt;/span>&lt;span style="color:#40ffff">$HOME&lt;/span>/.krew&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">/bin:&lt;/span>&lt;span style="color:#40ffff">$PATH&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>添加完成后请重启终端，使用 &lt;code>kubectl krew&lt;/code> 检查是否安装成功。&lt;/p>
&lt;h2 id="插件推荐">插件推荐&lt;/h2>
&lt;p>接下来推荐一些增强可观测性的 kubectl plugin。&lt;/p>
&lt;h3 id="tree">tree&lt;/h3>
&lt;p>该插件是由 Google 大佬开发，通过 &lt;code>ownerReferences&lt;/code> 来发现 kubernetes 对象之间的相互关联，并通过树状图来展示，对资源的关系一目了然。&lt;/p>
&lt;p>项目地址：https://github.com/ahmetb/kubectl-tree&lt;/p>
&lt;h4 id="安装-1">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install tree
$ kubectl tree --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例">示例&lt;/h4>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1go810e9dtxj21ps0rwtyh.jpg" alt="kubectl tree">&lt;/p>
&lt;h3 id="status">status&lt;/h3>
&lt;p>kubectl-status 这个插件简化了 &lt;code>get&lt;/code> 和 &lt;code>describe&lt;/code> 操作，采用不同颜色和箭头等元素来展示 kubernetes 资源的生命周期和状态信息，可以查看单个资源，也可以查看该 namespace 下的所有该资源的状态，极大的缩短了问题排查的时间，减少了操作步骤。&lt;/p>
&lt;p>项目地址：https://github.com/bergerx/kubectl-status&lt;/p>
&lt;h4 id="安装-2">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install status
$ kubectl status --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-1">示例&lt;/h4>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1go81g4jkwxj21da0yg0vn.jpg" alt="Pod">&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1go81gfyc56j21da0s8abh.jpg" alt="StatefulSet">&lt;/p>
&lt;h3 id="view-allocations">view-allocations&lt;/h3>
&lt;p>kubectl-view-allocations 可以非常方便的展示 CPU、内存、GPU 等资源的分布情况，并可以对 namespace、node、pod 等维度进行展示。&lt;/p>
&lt;p>项目地址：https://github.com/davidB/kubectl-view-allocations&lt;/p>
&lt;h4 id="安装-3">安装&lt;/h4>
&lt;p>&lt;strong>脚本安装&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl https://raw.githubusercontent.com/davidB/kubectl-view-allocations/master/scripts/getLatest.sh | bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>krew&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install view-allocations
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>cargo&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ cargo install kubectl-view-allocations
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-2">示例&lt;/h4>
&lt;p>&lt;strong>展示 GPU 的分配情况&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl-view-allocations -r gpu
Resource Requested Limit Allocatable Free
nvidia.com/gpu (71%) 10.0 (71%) 10.0 14.0 4.0
├─ node-gpu1 (0%) 0.0 (0%) 0.0 2.0 2.0
├─ node-gpu2 (0%) 0.0 (0%) 0.0 2.0 2.0
├─ node-gpu3 (100%) 2.0 (100%) 2.0 2.0 0.0
│ └─ fah-gpu-cpu-d29sc 2.0 2.0
├─ node-gpu4 (100%) 2.0 (100%) 2.0 2.0 0.0
│ └─ fah-gpu-cpu-hkg59 2.0 2.0
├─ node-gpu5 (100%) 2.0 (100%) 2.0 2.0 0.0
│ └─ fah-gpu-cpu-nw9fc 2.0 2.0
├─ node-gpu6 (100%) 2.0 (100%) 2.0 2.0 0.0
│ └─ fah-gpu-cpu-gtwsf 2.0 2.0
└─ node-gpu7 (100%) 2.0 (100%) 2.0 2.0 0.0
└─ fah-gpu-cpu-x7zfb 2.0 2.0
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>展示 namespace 维度资源的分配情况&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl-view-allocations -g namespace
Resource Requested Limit Allocatable Free
cpu (21%) 56.7 (65%) 176.1 272.0 95.9
├─ default 42.1 57.4
├─ dev 5.3 102.1
├─ dns-external 200.0m 0.0
├─ docs 150.0m 600.0m
├─ ingress-nginx 200.0m 1.0
├─ kube-system 2.1 1.4
├─ loki 1.2 2.4
├─ monitoring 3.5 7.0
├─ sharelatex 700.0m 2.4
└─ weave 1.3 1.8
ephemeral-storage (0%) 0.0 (0%) 0.0 38.4T 38.4T
memory (8%) 52.7Gi (15%) 101.3Gi 675.6Gi 574.3Gi
├─ default 34.6Gi 60.0Gi
├─ dev 5.3Gi 22.1Gi
├─ dns-external 140.0Mi 340.0Mi
├─ docs 448.0Mi 768.0Mi
├─ ingress-nginx 256.0Mi 1.0Gi
├─ kube-system 840.0Mi 1.0Gi
├─ loki 1.5Gi 1.6Gi
├─ monitoring 5.9Gi 5.7Gi
├─ sharelatex 2.5Gi 7.0Gi
└─ weave 1.3Gi 1.8Gi
nvidia.com/gpu (71%) 10.0 (71%) 10.0 14.0 4.0
└─ dev 10.0 10.0
pods (9%) 147.0 (9%) 147.0 1.6k 1.5k
├─ cert-manager 3.0 3.0
├─ default 13.0 13.0
├─ dev 9.0 9.0
├─ dns-external 2.0 2.0
├─ docs 8.0 8.0
├─ ingress-nginx 2.0 2.0
├─ kube-system 43.0 43.0
├─ loki 12.0 12.0
├─ monitoring 38.0 38.0
├─ sharelatex 3.0 3.0
└─ weave 14.0 14.0
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="images">images&lt;/h3>
&lt;p>kubectl-images 可以展示集群中正在使用的镜像，并对 namespace 进行一个简单的统计。使用这个插件可以非常方面的查看 namespace 中使用了哪些镜像，尤其在排查问题需要查看镜像版本时非常有用。&lt;/p>
&lt;p>项目地址：https://github.com/chenjiandongx/kubectl-images&lt;/p>
&lt;h4 id="安装-4">安装&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install images
$ kubectl images --help
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="示例-3">示例&lt;/h4>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1go81ui9oidj21sk17qx3l.jpg" alt="kubectl-images">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>有了 plugin 的加持，可以轻松为 kubectl 打造出一整套适合自己操作习惯的工具体系。如果这些插件都不符合要求，大可以自己开发一款插件，这样做可以大大提升工作效率，将自己从重复的劳动中解放出来！这也是笔者不常加班的原因之一。&lt;/p></description></item><item><title>Post: 使用 kubectl-rabbitmq 部署和运维 K8S 上的 RabbitMQ 集群</title><link>https://guoxudong.io/post/kubectl-rabbitmq/</link><pubDate>Fri, 15 Jan 2021 15:34:10 +0800</pubDate><guid>https://guoxudong.io/post/kubectl-rabbitmq/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近接到一个在 K8S 中部署一个 RabbitMQ 集群的任务，既然是部署在 K8S 集群中，首选的当然是 RabbitMQ Operator 了。不过在浏览官方文档时，意外的官方也有开发一个 kubectl-rabbitmq 的插件来帮助部署和运维 RabbitMQ Operator，在试用后发现体验意外的不错。那么本文我们就使用 kubectl-rabbitmq 来部署一个 RabbitMQ 集群吧！&lt;/p>
&lt;h2 id="插件安装">插件安装&lt;/h2>
&lt;p>安装插件前需要安装 &lt;a href="https://krew.sigs.k8s.io/">krew&lt;/a>，也就是 kubectl 的插件管理工具，krew 的安装这里就不做详细说明了。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;amp; kubectl krew install rabbitmq
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装完成后就可以使用 &lt;code>kubectl rabbitmq&lt;/code> 来部署和管理 RabbitMQ 集群了。&lt;/p>
&lt;h3 id="安装-rabbitmq-operator">安装 RabbitMQ Operator&lt;/h3>
&lt;p>使用 &lt;code>kubectl-rabbitmq&lt;/code> 安装 RabbitMQ Operator 非常简单，只需一行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq install-cluster-operator
namespace/rabbitmq-system created
customresourcedefinition.apiextensions.k8s.io/rabbitmqclusters.rabbitmq.com created
serviceaccount/rabbitmq-cluster-operator created
role.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-role created
clusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-operator-role created
rolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-operator-rolebinding created
deployment.apps/rabbitmq-cluster-operator created
&lt;/code>&lt;/pre>&lt;/div>&lt;p>之后就可以看到 &lt;code>rabbitmq-cluster-operator&lt;/code> 已经不再在 namespace： &lt;code>rabbitmq-system&lt;/code> 中了：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl get pod -n rabbitmq-system
NAME READY STATUS RESTARTS AGE
rabbitmq-cluster-operator-7bbbb8d559-k8zwm 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 35m
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="创建-rabbitmq-集群">创建 RabbitMQ 集群&lt;/h3>
&lt;p>创建 RabbitMQ 集群同样简单，也是一行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq create &amp;lt;rabbitmq-cluster-name&amp;gt; --replicas &lt;span style="color:#3677a9">1&lt;/span> --service ClusterIP --image rabbitmq:3.8.9-management
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里除了 &lt;code>&amp;lt;rabbitmq-cluster-name&amp;gt;&lt;/code> 以外，其余参数均为可选项，内容为 RabbitMQ Operator 的 CR 文件。此处的原理也比较简单，只是生成了一份 CR 配置。更多参数请参考&lt;a href="https://www.rabbitmq.com/kubernetes/operator/using-operator.html">官方文档&lt;/a>。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl get RabbitmqCluster
NAME AGE STATUS
test-rabbitmq 54s
&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="alert alert-warning" role="alert">
&lt;h4 class="alert-heading">注意&lt;/h4>
请确保你集群有可用的 &lt;code>StorageClass&lt;/code>，因为默认情况下 RabbitMQ Operator 创建的 RabbitMQ 集群会为每个实例使用 &lt;code>StorageClass&lt;/code> 分配一个 10G 的 PVC
&lt;/div>
&lt;h3 id="查看集群中所有-rabbitmq">查看集群中所有 RabbitMQ&lt;/h3>
&lt;p>可以使用 &lt;code>list&lt;/code> 命令查看集群中所有使用 RabbitMQ Operator 创建的 RabbitMQ 集群：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq list
NAME AGE STATUS
test-rabbitmq 10m
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="查看指定-rabbitmq-的所有资源">查看指定 RabbitMQ 的所有资源&lt;/h3>
&lt;p>使用 &lt;code>get&lt;/code> 命令可以轻松查看指定 RabbitMQ 集群的全部资源：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq get test-rabbitmq
NAME READY STATUS RESTARTS AGE
pod/test-rabbitmq-server-0 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 11m
NAME DATA AGE
configmap/test-rabbitmq-plugins-conf &lt;span style="color:#3677a9">1&lt;/span> 11m
configmap/test-rabbitmq-server-conf &lt;span style="color:#3677a9">2&lt;/span> 11m
NAME READY AGE
statefulset.apps/test-rabbitmq-server 1/1 11m
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/test-rabbitmq ClusterIP 10.96.84.122 &amp;lt;none&amp;gt; 15672/TCP,5672/TCP 11m
service/test-rabbitmq-nodes ClusterIP None &amp;lt;none&amp;gt; 4369/TCP,25672/TCP 11m
NAME TYPE DATA AGE
secret/test-rabbitmq-default-user Opaque &lt;span style="color:#3677a9">3&lt;/span> 11m
secret/test-rabbitmq-erlang-cookie Opaque &lt;span style="color:#3677a9">1&lt;/span> 11m
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="打开-rabbitmq-ui">打开 RabbitMQ UI&lt;/h3>
&lt;p>一般情况下，我们访问 ClusterIP 类型的 svc 都要使用到 &lt;code>pord-forward&lt;/code> 的方式，&lt;code>kubectl-rabbitmq&lt;/code> 则封装了该方法，使用 &lt;code>manage&lt;/code> 命令即可马上弹出 UI 界面：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq manage test-rabbitmq
Forwarding from 127.0.0.1:15672 -&amp;gt; &lt;span style="color:#3677a9">15672&lt;/span>
Forwarding from [::1]:15672 -&amp;gt; &lt;span style="color:#3677a9">15672&lt;/span>
Handling connection &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> &lt;span style="color:#3677a9">15672&lt;/span>
Handling connection &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> &lt;span style="color:#3677a9">15672&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="获取默认用户">获取默认用户&lt;/h3>
&lt;p>既然已经可以访问 UI 界面了，那么下一步肯定是获取默认用户名/密码，使用 &lt;code>secrets&lt;/code> 命令即可：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq secrets test-rabbitmq
username: sLSVWbiixZSB_XKL6SoI9kB_Pdefe477
password: zm0oV3UraiadH9E2NNot6Igq8woeEyRi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>当然也可以直接查看 &lt;code>secrets&lt;/code> 资源：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#999;font-style:italic"># user&lt;/span>
kubectl -n NAMESPACE get secret INSTANCE-default-user -o &lt;span style="color:#40ffff">jsonpath&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;{.data.username}&amp;#34;&lt;/span> | base64 --decode
&lt;span style="color:#999;font-style:italic"># pass&lt;/span>
kubectl -n NAMESPACE get secret INSTANCE-default-user -o &lt;span style="color:#40ffff">jsonpath&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;{.data.password}&amp;#34;&lt;/span> | base64 --decode
&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在就顺利登陆 UI 界面了&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1gmoh3scl4pj23ra1aidox.jpg" alt="RabbitMQ UI">&lt;/p>
&lt;h3 id="监控-rabbitmq">监控 RabbitMQ&lt;/h3>
&lt;p>使用 &lt;code>observe&lt;/code> 可以在终端观察指定 RabbitMQ 节点的监控信息，如下命令是查看 &lt;code>test-rabbitmq-server-0&lt;/code> 的监控信息：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq observe test-rabbitmq &lt;span style="color:#3677a9">0&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gmoh8s8qe0j21rc1a87lq.jpg" alt="image">&lt;/p>
&lt;h3 id="验证-rabbitmq">验证 RabbitMQ&lt;/h3>
&lt;p>为了验证 RabbitMQ 是否正常运行，使用 &lt;code>perf-test&lt;/code> 来进行：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq perf-test test-rabbitmq --rate &lt;span style="color:#3677a9">100&lt;/span>
service/perf-test created
pod/perf-test created
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里可以看到拉起了 &lt;code>perf-test&lt;/code> 的 pod 和 svc，查看其日志：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl logs -f perf-test
id: test-091555-328, starting consumer &lt;span style="color:#999;font-style:italic">#0&lt;/span>
id: test-091555-328, starting consumer &lt;span style="color:#999;font-style:italic">#0, channel #0&lt;/span>
id: test-091555-328, starting producer &lt;span style="color:#999;font-style:italic">#0&lt;/span>
id: test-091555-328, starting producer &lt;span style="color:#999;font-style:italic">#0, channel #0&lt;/span>
id: test-091555-328, time: 1.000s, sent: &lt;span style="color:#3677a9">15259&lt;/span> msg/s, received: &lt;span style="color:#3677a9">9462&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 5337/140173/167205/239702/259102 µs
id: test-091555-328, time: 2.000s, sent: &lt;span style="color:#3677a9">44288&lt;/span> msg/s, received: &lt;span style="color:#3677a9">13328&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 281875/625383/726050/825489/844442 µs
id: test-091555-328, time: 3.000s, sent: &lt;span style="color:#3677a9">35377&lt;/span> msg/s, received: &lt;span style="color:#3677a9">16624&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 869436/1176394/1463207/1500775/1509740 µs
id: test-091555-328, time: 4.001s, sent: &lt;span style="color:#3677a9">15490&lt;/span> msg/s, received: &lt;span style="color:#3677a9">21770&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 1404599/1549405/1735201/1917333/1953431 µs
id: test-091555-328, time: 5.001s, sent: &lt;span style="color:#3677a9">17367&lt;/span> msg/s, received: &lt;span style="color:#3677a9">18243&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 1967969/2297884/2502092/2649344/2678139 µs
id: test-091555-328, time: 6.005s, sent: &lt;span style="color:#3677a9">16679&lt;/span> msg/s, received: &lt;span style="color:#3677a9">17953&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 2484404/2998748/3165893/3294687/3326600 µs
id: test-091555-328, time: 7.006s, sent: &lt;span style="color:#3677a9">16729&lt;/span> msg/s, received: &lt;span style="color:#3677a9">18375&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 2393535/2753560/2990014/3194592/3224623 µs
id: test-091555-328, time: 8.006s, sent: &lt;span style="color:#3677a9">20648&lt;/span> msg/s, received: &lt;span style="color:#3677a9">17156&lt;/span> msg/s, min/median/75th/95th/99th consumer latency: 2472263/2861278/3079786/3256128/3313167 µs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 UI 上也可以看到监控发生了变化。&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1gmohfwtciuj23p21g8qfb.jpg" alt="">&lt;/p>
&lt;p>验证完成后删除 &lt;code>perf-test&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl delete pod,svc perf-test
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="删除-rabbitmq-集群">删除 RabbitMQ 集群&lt;/h3>
&lt;p>完成测试后，使用 &lt;code>delete&lt;/code> 即可删除 RabbitMQ 集群。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl rabbitmq delete test-rabbitmq
rabbitmqcluster.rabbitmq.com &lt;span style="color:#ed9d13">&amp;#34;test-rabbitmq&amp;#34;&lt;/span> deleted
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="总结">总结&lt;/h2>
&lt;p>以上的这些功能，使用 &lt;code>kubectl&lt;/code> 和 yaml 文件也可以完成同样的效果，只不过有些操作比较繁琐。&lt;code>kubectl rabbitmq&lt;/code> 简化了很多操作，在实际管理和维护 RabbitMQ 集群时，是一个非常不错的工具。&lt;/p></description></item><item><title>Post: K8S 资源可视化利器：Kubectl-Graph</title><link>https://guoxudong.io/post/kubectl-graph/</link><pubDate>Tue, 29 Dec 2020 10:19:18 +0800</pubDate><guid>https://guoxudong.io/post/kubectl-graph/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近接手了一个规模比较大的集群，光是整理集群中的资源就使人头昏眼花，虽然我自认 &lt;code>kubectl&lt;/code> 使用的已经十分熟练，但是上千个 kubernetes resource 看下来还是不堪重负。在不能为集群安装任何其他工具的情况下，可以改造的就只有我自己的 client 端，也就是 &lt;code>kubectl&lt;/code> 了。本文就介绍一个有趣的 kubectl 插件：&lt;code>kubectl-graph&lt;/code>。&lt;/p>
&lt;h2 id="krew">krew&lt;/h2>
&lt;p>要介绍 kubectl 的 plugin 机制，首先要介绍的就是 &lt;a href="https://krew.sigs.k8s.io/">krew&lt;/a> 。 krew 是 kubernetes &lt;a href="https://github.com/kubernetes/community/blob/master/sig-cli/README.md#cli-special-interest-group">CLI SIG&lt;/a> 项目，是用来管理 kubectl 插件的工具，作用类似于 yum 和 brew，可以用来搜索、安装和管理 kubectl 插件。&lt;/p>
&lt;h2 id="kubectl-graph">kubectl-graph&lt;/h2>
&lt;p>kubectl-graph 是一款可视化 kubernetes resource 及资源间关系的 kubectl 插件，可以将集群中的资源以关系图的方式进行展示。&lt;/p>
&lt;p>目前支持两种展示方法：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://graphviz.org/">Graphviz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://neo4j.com/">Neo4j&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="前期准备">前期准备&lt;/h2>
&lt;p>除了 &lt;code>kubectl&lt;/code>，由于需要进行绘图，所以还需安装上面两种展示方式的依赖。&lt;/p>
&lt;h3 id="graphviz">Graphviz&lt;/h3>
&lt;p>安装 Graphviz 用来生成关系图，需要使用 &lt;code>dot&lt;/code> CLI 工具，并将图像输出为 SVG 格式：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ brew install graphviz
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="neo4j">Neo4j&lt;/h3>
&lt;p>Neo4j 是一个高性能的 NoSQL 图形数据库，它将结构化数据存储在网络上而不是表中，很适合用来展示 kubernetes resource 之间的关系，但 Neo4j 的依赖较多，需要一点时间来安装。&lt;/p>
&lt;h4 id="安装-java">安装 Java&lt;/h4>
&lt;p>Neo4j 依赖 Java 环境，如果本机上没有安装 Java，请先前往 &lt;a href="http://www.java.com">http://www.java.com&lt;/a> 下载并安装。&lt;/p>
&lt;h4 id="安装-cypher-shell">安装 cypher-shell&lt;/h4>
&lt;p>因为需要连接到 Neo4j 数据库，所以要安装 &lt;code>cypher-shell&lt;/code> CLI：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ brew install cypher-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="安装-neo4j-desktop可选">安装 Neo4j Desktop（可选）&lt;/h4>
&lt;p>接下来就是 Neo4j 本身的安装，我这里使用了 &lt;code>Neo4j Desktop&lt;/code>，使用和管理起来比较方便，也是使用 &lt;code>brew&lt;/code> 安装：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ brew install --cask neo4j
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装好后，运行 &lt;code>Neo4j Desktop&lt;/code>，完成设置即可&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gm4ngqfkvzj21z41kwgqi.jpg" alt="设置 neo4j">&lt;/p>
&lt;h4 id="使用-docker-运行-neo4j可选">使用 docker 运行 Neo4j（可选）&lt;/h4>
&lt;p>当然，如果你感觉安装 &lt;code>Neo4j Desktop&lt;/code> 比较麻烦，也可以使用 docker 运行 Neo4j：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker run --rm -p 7474:7474 -p 7687:7687 -e &lt;span style="color:#40ffff">NEO4J_AUTH&lt;/span>=none neo4j
&lt;/code>&lt;/pre>&lt;/div>&lt;p>只不过后续查看关系图时，需要使用浏览器访问 http://localhost:7474 来查看结果。&lt;/p>
&lt;h3 id="安装-kubectl-graph">安装 kubectl-graph&lt;/h3>
&lt;p>插件的安装方式比较简单，如果你使用的是 &lt;code>kubectl 1.19&lt;/code> 之前的版本：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl-krew install graph
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 &lt;code>kubectl 1.19&lt;/code> 之后的版本：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl krew install graph
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="使用方式">使用方式&lt;/h2>
&lt;p>安装完成后，就可以开始绘制 kubernetes resource 关系图了。&lt;/p>
&lt;h3 id="graphviz-1">Graphviz&lt;/h3>
&lt;p>使用 &lt;code>kubectl graph&lt;/code> 命令获取 &lt;code>kubec-system&lt;/code> 中正在运行的 pod，并通过管道传递给 &lt;code>dot&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl graph pods --field-selector status.phase=Running -n kube-system | dot -T svg -o pods.svg
&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看 &lt;code>pods.svg&lt;/code> ，资源果然很多：&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1gm4nxnytzkj22d41zq19w.jpg" alt="pods.svg">&lt;/p>
&lt;h3 id="neo4j-1">Neo4j&lt;/h3>
&lt;p>Neo4j 可以展示更为丰富且美观的关系图。在导入 kubernetes resource 之前，需要创建一个 Neo4j 数据库：&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gm4o4b56mzj21z41kw46d.jpg" alt="创建 neo4j 数据库">&lt;/p>
&lt;p>数据库创建好后，点击 &lt;code>Start&lt;/code> 运行并点击 &lt;code>Open&lt;/code> 打开 &lt;code>Neo4j Browser&lt;/code>：&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gm4o605br2j20ow0fkjs1.jpg" alt="打开数据库">&lt;/p>
&lt;p>执行命令将 kubernetes resource 导入 Neo4j：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl graph all -n kube-system -o cypher | cypher-shell -u neo4j -p &amp;lt;your-pass&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="alert alert-warning" role="alert">
&lt;h4 class="alert-heading">注意&lt;/h4>
这里的 &lt;code>-u&lt;/code> 需要输入 &lt;code>neo4j&lt;/code> 而不是你创建的数据库名称，&lt;code>Neo4j Browser&lt;/code> 上也有提示：
&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gm4o9rsqtzj21ve0m440w.jpg" alt="">
&lt;/div>
&lt;p>之后就可以在 Neo4j 上查看了，输入查询语句：&lt;code>MATCH (n) RETURN n&lt;/code>：&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gm4ofe5jiwj22761midzp.jpg" alt="关系图">&lt;/p>
&lt;p>这时一个美观的 kubernetes resource 关系图就出现了。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>kubectl 还有很多好用且有趣的 plugin，后续笔者会介绍如何开发一个 kubectl plugin 并分享更多有趣的 plugin。&lt;/p></description></item><item><title>Post: 使用 Helmfile 解放你的 Helm Chart</title><link>https://guoxudong.io/post/helmfile-quick-start/</link><pubDate>Tue, 22 Dec 2020 15:59:28 +0800</pubDate><guid>https://guoxudong.io/post/helmfile-quick-start/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Helm 作为 Kubernetes 的包管理工具和 CNCF 毕业项目，在业界被广泛使用。但在实际使用场景中的一些需求 helm 并不能很好的满足，需要进行一些修改和适配，如同时部署多个 chart、不同部署环境的区分以及 chart 的版本控制。&lt;code>Helmfile&lt;/code> 就是一个能够很好解决这些问题的小工具。&lt;/p>
&lt;h2 id="基础介绍">基础介绍&lt;/h2>
&lt;p>Helmfile 通过 &lt;code>helmfile.yaml&lt;/code> 文件帮助用户管理和维护众多 helm chart，其最主要作用是：&lt;/p>
&lt;ul>
&lt;li>集成在 CI/CD 系统中，提高部署的可观测性和可重复性，区分环境，免去各种 &lt;code>--set&lt;/code> 造成的困扰。&lt;/li>
&lt;li>方便对 helm chart 进行版本控制，如指定版本范围、锁定版本等。&lt;/li>
&lt;li>定期同步，避免环境中出现不符合预期的配置。&lt;/li>
&lt;/ul>
&lt;h3 id="安装">安装&lt;/h3>
&lt;p>helmfile 提供了多种安装方式，除了直接在 &lt;a href="https://github.com/roboll/helmfile/releases">release 页面&lt;/a>下载，还可以通过如下方式安装：&lt;/p>
&lt;ul>
&lt;li>macOS (使用 homebrew): &lt;code>brew install helmfile&lt;/code>&lt;/li>
&lt;li>Windows (使用 scoop): &lt;code>scoop install helmfile&lt;/code>&lt;/li>
&lt;li>Archlinux: &lt;code>pacman -S helmfile&lt;/code>&lt;/li>
&lt;li>openSUSE: &lt;code>zypper in helmfile&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>同时还支持作为容器运行，可以非常方便的集成到 CI/CD 系统中：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># helm 2&lt;/span>
$ docker run --rm --net=host -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">HOME&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">/.kube:/root/.kube&amp;#34;&lt;/span> -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">HOME&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">/.helm:/root/.helm&amp;#34;&lt;/span> -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">PWD&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">:/wd&amp;#34;&lt;/span> --workdir /wd quay.io/roboll/helmfile:v0.135.0 helmfile sync
&lt;span style="color:#999;font-style:italic"># helm 3&lt;/span>
$ docker run --rm --net=host -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">HOME&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">/.kube:/root/.kube&amp;#34;&lt;/span> -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">HOME&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">/.config/helm:/root/.config/helm&amp;#34;&lt;/span> -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">PWD&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>&lt;span style="color:#ed9d13">:/wd&amp;#34;&lt;/span> --workdir /wd quay.io/roboll/helmfile:helm3-v0.135.0 helmfile sync
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="其他依赖">其他依赖&lt;/h3>
&lt;p>除了安装 helmfile 以外，还需要安装 &lt;code>helm&lt;/code>、&lt;code>kubectl&lt;/code> 以及 helm 插件 &lt;a href="https://github.com/databus23/helm-diff">&lt;code>helm-diff&lt;/code>&lt;/a>。&lt;/p>
&lt;p>helm-diff 安装方式：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helm plugin install https://github.com/databus23/helm-diff
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="helmfileyaml">helmfile.yaml&lt;/h3>
&lt;p>&lt;code>helmfile.yaml&lt;/code> 是 helmfile 的核心文件，其用来声明所有的配置。下面会简要介绍一下，详细内容见&lt;a href="https://github.com/roboll/helmfile#configuration">官方文档&lt;/a>。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># 声明 repo 配置&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">repositories&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&amp;lt;repo-name&amp;gt;&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># url: repo url&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 可以设置基础配置 或 tls 认证&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># certFile: certificate 文件&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># keyFile: key 文件&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># username: 用户名&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># password: 密码&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># helm 二进制文件的路径&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">helmBinary&lt;/span>:&lt;span style="color:#666"> &lt;/span>path/to/helm3&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># helm 的一些默认设置，这些配置与 `helm SUBCOMMAND` 相同，可以通过这个配置声明一些，默认的配置&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">helmDefaults&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tillerNamespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>tiller-namespace &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#dedicated default key for tiller-namespace&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tillerless&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#dedicated default key for tillerless&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kubeContext&lt;/span>:&lt;span style="color:#666"> &lt;/span>kube-context &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#dedicated default key for kube-context (--kube-context)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cleanupOnFail&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#dedicated default key for helm flag --cleanup-on-fail&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># additional and global args passed to helm (default &amp;#34;&amp;#34;)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">args&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#ed9d13">&amp;#34;--set k=v&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># verify the chart before upgrading (only works with packaged charts not directories) (default false)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">verify&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># wait for k8s resources via --wait. (default false)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">wait&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># time in seconds to wait for any individual Kubernetes operation (like Jobs for hooks, and waits on pod/pvc/svc/deployment readiness) (default 300)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeout&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">600&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># performs pods restart for the resource if applicable (default false)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">recreatePods&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># forces resource update through delete/recreate if needed (default false)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">force&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># when using helm 3.2+, automatically create release namespaces if they do not exist (default true)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">createNamespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>...&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 为 helmfile 中所有的 release 设置相同的 label，可用于为所有 release 标记相同的版本&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">commonLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">hello&lt;/span>:&lt;span style="color:#666"> &lt;/span>world&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 设置 release 配置（支持多 release）&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 远程 chart 示例（chart 已经上传到 remote 仓库）&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>vault &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># name of this release&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>vault &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># target namespace&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">createNamespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># helm 3.2+ automatically create release namespace (default true)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Arbitrary key value pairs for filtering releases&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">foo&lt;/span>:&lt;span style="color:#666"> &lt;/span>bar&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart&lt;/span>:&lt;span style="color:#666"> &lt;/span>roboll/vault-secret-manager &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># the chart being installed to create this release, referenced by `repository/chart` syntax&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>~1.24.1 &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># the semver of the chart. range constraint is supported&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">condition&lt;/span>:&lt;span style="color:#666"> &lt;/span>vault.enabled &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># The values lookup key for filtering releases. Corresponds to the boolean value of `vault.enabled`, where `vault` is an arbitrary value&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">missingFileHandler&lt;/span>:&lt;span style="color:#666"> &lt;/span>Warn&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># set to either &amp;#34;Error&amp;#34; or &amp;#34;Warn&amp;#34;. &amp;#34;Error&amp;#34; instructs helmfile to fail when unable to find a values or secrets file. When &amp;#34;Warn&amp;#34;, it prints the file and continues.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Values files used for rendering the chart&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Value files passed via --values&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- vault.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Inline values, passed via a temporary values file and --values, so that it doesn&amp;#39;t suffer from type issues like --set&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">address&lt;/span>:&lt;span style="color:#666"> &lt;/span>https://vault.example.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Go template available in inline values and values files.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># The end result is more or less YAML. So do `quote` to prevent number-like strings from accidentally parsed into numbers!&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># See https://github.com/roboll/helmfile/issues/608&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tag&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;IMAGE_TAG&amp;#34; | quote }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Otherwise:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># tag: &amp;#34;{{ requiredEnv &amp;#34;IMAGE_TAG&amp;#34; }}&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># tag: !!string {{ requiredEnv &amp;#34;IMAGE_TAG&amp;#34; }}&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">db&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">username&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;DB_USERNAME&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># value taken from environment variable. Quotes are necessary. Will throw an error if the environment variable is not set. $DB_PASSWORD needs to be set in the calling environment ex: export DB_PASSWORD=&amp;#39;password1&amp;#39;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">password&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;DB_PASSWORD&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">proxy&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Interpolate environment variable with a fixed string&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">domain&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;PLATFORM_ID&amp;#34; }}.my-domain.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">scheme&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>env &amp;#34;SCHEME&amp;#34; | default &amp;#34;https&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Use `values` whenever possible!&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># `set` translates to helm&amp;#39;s `--set key=val`, that is known to suffer from type issues like https://github.com/roboll/helmfile/issues/608&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">set&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># single value loaded from a local file, translates to --set-file foo.config=path/to/file&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>foo.config&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">file&lt;/span>:&lt;span style="color:#666"> &lt;/span>path/to/file&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># set a single array value in an array, translates to --set bar[0]={1,2}&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>bar[0]&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#3677a9">2&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># set a templated value&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>namespace&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>.Namespace }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># will attempt to decrypt it using helm-secrets plugin&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 本地 chart 示例（chart 保存在本地）&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>grafana &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># name of this release&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>another &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># target namespace&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart&lt;/span>:&lt;span style="color:#666"> &lt;/span>../my-charts/grafana &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># the chart being installed to create this release, referenced by relative path to local helmfile&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#ed9d13">&amp;#34;../../my-values/grafana/values.yaml&amp;#34;&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Values file (relative path to manifest)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- ./values/{{ requiredEnv &amp;#34;PLATFORM_ENV&amp;#34; }}/config.yaml&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Values file taken from path with environment variable. $PLATFORM_ENV must be set in the calling environment.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">wait&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 可以嵌套其他的 helmfiles，支持从本地和远程拉取 helmfile&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">helmfiles&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>path/to/subhelmfile.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># label 选择器可以过滤需要覆盖的 release&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selectors&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- name=prometheus&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 覆盖 value&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 使用文件覆盖&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- additional.values.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 覆盖单独的 key&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">key1&lt;/span>:&lt;span style="color:#666"> &lt;/span>val1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#999;font-style:italic"># 远程拉取配置&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>git::https://github.com/cloudposse/helmfiles.git@releases/kiam.yaml?ref=0.40.0&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 如果指向不存在路径，则打印告警错误&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">missingFileHandler&lt;/span>:&lt;span style="color:#666"> &lt;/span>Error&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 多环境管理&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">environments&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 当没有设置 `--environment NAME` 时，使用 default &lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">default&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 内容可以是文件路径或者 key:value&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- environments/default/values.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">myChartVer&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1.0.0&lt;/span>-dev&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># &amp;#34;production&amp;#34; 环境，当设置了 `helmfile --environment production sync` 时&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">production&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- environment/production/values.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">myChartVer&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1.0.0&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># disable vault release processing&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">vault&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">## `secrets.yaml` is decrypted by `helm-secrets` and available via `{{ .Environment.Values.KEY }}`&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">secrets&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- environment/production/secrets.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 当占不到 `environments.NAME.values` 时，可以设置为 &amp;#34;Error&amp;#34;, &amp;#34;Warn&amp;#34;, &amp;#34;Info&amp;#34;, &amp;#34;Debug&amp;#34;，默认是 &amp;#34;Error&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">missingFileHandler&lt;/span>:&lt;span style="color:#666"> &lt;/span>Error&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># 分层管理，可以将所有文件合并，顺序为：environments.yaml &amp;lt; - defaults.yaml &amp;lt; - templates.yaml &amp;lt; - helmfile.yaml&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">bases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- environments.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- defaults.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- templates.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># API 功能&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersions&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- example/v1&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="apply">Apply&lt;/h3>
&lt;p>&lt;code>helmfile apply&lt;/code> 是 helmfile 中最常用命令，体验与 &lt;code>kubectl apply&lt;/code> 类似，根据 &lt;code>helmfile.yaml&lt;/code> 中声明的配置可以一键执行相应的动作，如：添加 repo、安装或更新 release 等。&lt;/p>
&lt;p>&lt;code>helmfile.yaml&lt;/code> 如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">repositories&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>stable&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>https://charts.helm.sh/stable&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>prom-norbac-ubuntu&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>prometheus&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart&lt;/span>:&lt;span style="color:#666"> &lt;/span>stable/prometheus&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">set&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>rbac.create&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行 &lt;code>helmfile apply&lt;/code> 之后，helmfile 会进行如下操作：&lt;/p>
&lt;ol>
&lt;li>添加 &lt;code>repositories&lt;/code> 中声明的 repo&lt;/li>
&lt;li>运行 &lt;code>helm diff&lt;/code> 进行对比&lt;/li>
&lt;li>根据 &lt;code>release&lt;/code>中声明的配置，安装或更新 chart&lt;/li>
&lt;/ol>
&lt;p>效果如下(由于输出内容过多，这里只节选了部分输出)：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">Adding repo stable https://charts.helm.sh/stable
&lt;span style="color:#ed9d13">&amp;#34;stable&amp;#34;&lt;/span> has been added to your repositories
Comparing &lt;span style="color:#40ffff">release&lt;/span>=prom-norbac-ubuntu, &lt;span style="color:#40ffff">chart&lt;/span>=stable/prometheus
...
prometheus, prom-norbac-ubuntu-prometheus-server, ServiceAccount (v1) has been added:
-
+ &lt;span style="color:#999;font-style:italic"># Source: prometheus/templates/rbac/server-serviceaccount.yaml&lt;/span>
+ apiVersion: v1
+ kind: ServiceAccount
+ metadata:
+ labels:
+ component: &lt;span style="color:#ed9d13">&amp;#34;server&amp;#34;&lt;/span>
+ app: prometheus
+ release: prom-norbac-ubuntu
+ chart: prometheus-11.12.1
+ heritage: Helm
+ name: prom-norbac-ubuntu-prometheus-server
+ namespace: prometheus
+ annotations:
+ {}
Upgrading &lt;span style="color:#40ffff">release&lt;/span>=prom-norbac-ubuntu, &lt;span style="color:#40ffff">chart&lt;/span>=stable/prometheus
Release &lt;span style="color:#ed9d13">&amp;#34;prom-norbac-ubuntu&amp;#34;&lt;/span> does not exist. Installing it now.
NAME: prom-norbac-ubuntu
LAST DEPLOYED: Wed Dec &lt;span style="color:#3677a9">23&lt;/span> 11:23:31 &lt;span style="color:#3677a9">2020&lt;/span>
NAMESPACE: prometheus
STATUS: deployed
REVISION: &lt;span style="color:#3677a9">1&lt;/span>
TEST SUITE: None
NOTES:
...
Listing releases matching ^prom-norbac-ubuntu$
prom-norbac-ubuntu prometheus &lt;span style="color:#3677a9">1&lt;/span> 2020-12-23 11:23:31.779328 +0800 CST deployed prometheus-11.12.1 2.20.1
UPDATED RELEASES:
NAME CHART VERSION
prom-norbac-ubuntu stable/prometheus 11.12.1
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="模板化">模板化&lt;/h3>
&lt;p>helmfile 和 helm templete 一样可以使用 &lt;a href="https://godoc.org/text/template">Go templates&lt;/a>，同时还有一个特殊的功能 &lt;code>requiredEnv&lt;/code>，该函数允许声明模板渲染所需的特定环境变量，如果环境变量未设置或为空，则渲染失败返回错误信息。&lt;/p>
&lt;h3 id="使用环境变量">使用环境变量&lt;/h3>
&lt;p>可以在 helmfile 中直接使用环境变量，使用方式如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">repositories&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>your-private-git-repo-hosted-charts&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>https://{{ requiredEnv &amp;#34;GITHUB_TOKEN&amp;#34;}}@raw.githubusercontent.com/kmzfs/helm-repo-in-github/master/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;NAME&amp;#34; }}-vault&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;NAME&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart&lt;/span>:&lt;span style="color:#666"> &lt;/span>roboll/vault-secret-manager&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">db&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">username&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;DB_USERNAME&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">password&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;DB_PASSWORD&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">set&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>proxy.domain&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>requiredEnv &amp;#34;PLATFORM_ID&amp;#34; }}.my-domain.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>proxy.scheme&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>env &amp;#34;SCHEME&amp;#34; | default &amp;#34;https&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="进阶实践">进阶实践&lt;/h2>
&lt;p>helm 还有一些进阶使用方式，如：版本控制、环境区分、hook、交互式操作、集成 kustomize 等。这里简单介绍几种，更多功能请看&lt;a href="https://github.com/roboll/helmfile">官方文档&lt;/a>。&lt;/p>
&lt;h3 id="版本控制">版本控制&lt;/h3>
&lt;p>helmfile 支持 &lt;a href="https://semver.org/lang/zh-CN/">Semver 2.0&lt;/a> 的版本号，可以锁定主版本，防止误升级导致的错误。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>vault &lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>vault &lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>~1.24.1 &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 限制版本 &amp;gt;=1.24.1 &amp;amp;&amp;amp; &amp;lt; 1.25.0&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>同时还能通过 &lt;code>helmfile deps&lt;/code> 命令生成 lock 文件，在 CD 时，除非修改 lock 文件，否无法发布新版本。&lt;code>helmfile.lock&lt;/code> 内容如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>v0.135.0&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">dependencies&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>prometheus&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">repository&lt;/span>:&lt;span style="color:#666"> &lt;/span>https://charts.helm.sh/stable&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">11.12.1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">digest&lt;/span>:&lt;span style="color:#666"> &lt;/span>sha256:a5158f1361f2bbc4e73a80a22dd92b44538bdebeb2419658c36e31aa603b05fd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">generated&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;2020-12-23T16:26:57.42503+08:00&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>当需要更新时，再次执行 &lt;code>helmfile deps&lt;/code> 即可。&lt;/p>
&lt;h3 id="区分环境">区分环境&lt;/h3>
&lt;p>这也是个使用率较高的功能，使用 &lt;code>environments&lt;/code> 配置·。如果不指定 &lt;code>--environment NAME&lt;/code> 参数，默认使用 &lt;code>default&lt;/code> 配置。&lt;/p>
&lt;p>这里假设有三个文件，&lt;code>helmfile.yaml&lt;/code>、&lt;code>production.yaml&lt;/code> 和 &lt;code>default.yaml&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># helmfile.yaml&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">environments&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">default&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- default.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">production&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- production.yaml &lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>myapp-{{ .Values.releaseName }}&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 根据环境名，可能是 `dev` 或 `prod`&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">values&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>{&lt;span style="color:#666"> &lt;/span>.Values.domain }}&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 根据环境名，可能是 `dev.example.com` 或 `prod.example.com`&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{&lt;span style="color:#666"> &lt;/span>if eq .Environment.Name &amp;#34;production&amp;#34; }}&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 使用 Go template 的&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- values/production-specified-values.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{&lt;span style="color:#666"> &lt;/span>end }}&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># production.yaml&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">domain&lt;/span>:&lt;span style="color:#666"> &lt;/span>prod.example.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releaseName&lt;/span>:&lt;span style="color:#666"> &lt;/span>prod&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># default.yaml&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">domain&lt;/span>:&lt;span style="color:#666"> &lt;/span>dev.example.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releaseName&lt;/span>:&lt;span style="color:#666"> &lt;/span>dev&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在执行 &lt;code>helmfile&lt;/code> 时，只需使用 &lt;code>--environment&lt;/code> 指定需要安装的环境：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helmfile --environment production apply
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="hook">Hook&lt;/h3>
&lt;p>Helmfile hook 是一个每次发布的扩展点，它由以下部分组成：&lt;/p>
&lt;ul>
&lt;li>&lt;code>events&lt;/code>&lt;/li>
&lt;li>&lt;code>command&lt;/code>&lt;/li>
&lt;li>&lt;code>args&lt;/code>&lt;/li>
&lt;li>&lt;code>showlogs&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>helmfile 在运行时，会触发各种事件，一旦事件触发，相关的 &lt;code>hook&lt;/code> 就会被执行，目前支持的如下事件：&lt;/p>
&lt;ul>
&lt;li>&lt;code>prepare&lt;/code>&lt;/li>
&lt;li>&lt;code>presync&lt;/code>&lt;/li>
&lt;li>&lt;code>preuninstall&lt;/code>&lt;/li>
&lt;li>&lt;code>postuninstall&lt;/code>&lt;/li>
&lt;li>&lt;code>postsync&lt;/code>&lt;/li>
&lt;li>&lt;code>cleanup&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>下面这个示例，会打印事件触发时的的上下文信息。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">environments&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">default&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prod&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>myapp&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart&lt;/span>:&lt;span style="color:#666"> &lt;/span>mychart&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># *snip*&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">hooks&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">events&lt;/span>:&lt;span style="color:#666"> &lt;/span>[&lt;span style="color:#ed9d13">&amp;#34;prepare&amp;#34;&lt;/span>,&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;cleanup&amp;#34;&lt;/span>]&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">showlogs&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">command&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;echo&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">args&lt;/span>:&lt;span style="color:#666"> &lt;/span>[&lt;span style="color:#ed9d13">&amp;#34;{{`{{.Environment.Name}}`}}&amp;#34;&lt;/span>,&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;{{`{{.Release.Name}}`}}&amp;#34;&lt;/span>,&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;{{`{{.HelmfileCommand}}`}}\
&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>]&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行命令，可以看到 command 执行成功：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helmfile -e prod sync
helmfile.yaml: &lt;span style="color:#40ffff">basePath&lt;/span>=.
hook[prepare] logs | prod myapp sync
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这也是个十分好用的功能，可以为不同的事件配置不同的 hook，这样在 CD 出现问题时，通过 hook 可以第一时间收到通知，并快速定位问题。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>Helmfile 是一个很不错 Helm 生态工具，很大程度上弥补了 Helm 的不足。提高部署的可观测性和可重复性，提高了效率，最终实现 Release AS Code。&lt;/p></description></item><item><title>Post: 图解 K8S 源码 - QoS 篇</title><link>https://guoxudong.io/post/diagrams-k8s-src-qos/</link><pubDate>Wed, 14 Oct 2020 10:28:06 +0800</pubDate><guid>https://guoxudong.io/post/diagrams-k8s-src-qos/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>日常使用 Kubernetes 时，时长会出现 Node 节点中的 Pod 被 OOMKill 掉的情况，但 Node 节点中 Pod 众多，为什么单单选中这个 Pod Kill 掉呢？这里就引出了 QoS 的概念，本篇文章就会从源码的角度介绍 QoS 的分类、打分机制，并简单介绍不同 QoS 的本质区别。看看这个机制是如何保证运行在 Kubernetes 中服务质量的。&lt;/p>
&lt;h2 id="qos">QoS&lt;/h2>
&lt;p>QoS(Quality of Service) 即服务质量，是 Kubernetes 中的一种控制机制，其会对运行在 Kubernetes 中的 Pod 进行一个质量划分，根据 Pod 中 container 的 Limit 和 request 将 Pod 分为 &lt;code>Guaranteed&lt;/code>，&lt;code>Burstable&lt;/code>，&lt;code>BestEffort&lt;/code> 三类并对所有 Pod 进行一个打分。在资源尤其是内存这种不可压缩资源不够时，为保证整体质量的稳定，Kubernetes 就会根据 QoS 的不同优先级，对 Pod 进行资源回收。这也是有时集群中的 Pod 突然被 kill 掉的原因。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65ly1gjotxqvm4uj20mr0aw78n.jpg" alt="Qos">&lt;/p>
&lt;h3 id="qos-分类">QoS 分类&lt;/h3>
&lt;p>以下代码用来获取 Pod 的 QoS 类，用于区分不同 Pod 的 QoS。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// github/kubernetes/pkg/apis/core/v1/helper/qos/qos.go
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> &lt;span style="color:#447fcf">GetPodQOS&lt;/span>(pod *v1.Pod) v1.PodQOSClass {
requests := v1.ResourceList{}
limits := v1.ResourceList{}
zeroQuantity := resource.&lt;span style="color:#447fcf">MustParse&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;0&amp;#34;&lt;/span>)
isGuaranteed := &lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>
allContainers := []v1.Container{}
allContainers = &lt;span style="color:#24909d">append&lt;/span>(allContainers, pod.Spec.Containers...)
&lt;span style="color:#999;font-style:italic">// InitContainers 容器也会被加入 QoS 的计算中
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> allContainers = &lt;span style="color:#24909d">append&lt;/span>(allContainers, pod.Spec.InitContainers...)
&lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> _, container := &lt;span style="color:#6ab825;font-weight:bold">range&lt;/span> allContainers {
&lt;span style="color:#999;font-style:italic">// 遍历 requests 中的 CPU 和 memory 值
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> name, quantity := &lt;span style="color:#6ab825;font-weight:bold">range&lt;/span> container.Resources.Requests {
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> !&lt;span style="color:#447fcf">isSupportedQoSComputeResource&lt;/span>(name) {
&lt;span style="color:#6ab825;font-weight:bold">continue&lt;/span>
}
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> quantity.&lt;span style="color:#447fcf">Cmp&lt;/span>(zeroQuantity) == &lt;span style="color:#3677a9">1&lt;/span> {
delta := quantity.&lt;span style="color:#447fcf">DeepCopy&lt;/span>()
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> _, exists := requests[name]; !exists {
requests[name] = delta
} &lt;span style="color:#6ab825;font-weight:bold">else&lt;/span> {
delta.&lt;span style="color:#447fcf">Add&lt;/span>(requests[name])
requests[name] = delta
}
}
}
&lt;span style="color:#999;font-style:italic">// 遍历 limits 中的 CPU 和 memory 值
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> qosLimitsFound := sets.&lt;span style="color:#447fcf">NewString&lt;/span>()
&lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> name, quantity := &lt;span style="color:#6ab825;font-weight:bold">range&lt;/span> container.Resources.Limits {
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> !&lt;span style="color:#447fcf">isSupportedQoSComputeResource&lt;/span>(name) {
&lt;span style="color:#6ab825;font-weight:bold">continue&lt;/span>
}
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> quantity.&lt;span style="color:#447fcf">Cmp&lt;/span>(zeroQuantity) == &lt;span style="color:#3677a9">1&lt;/span> {
qosLimitsFound.&lt;span style="color:#447fcf">Insert&lt;/span>(&lt;span style="color:#24909d">string&lt;/span>(name))
delta := quantity.&lt;span style="color:#447fcf">DeepCopy&lt;/span>()
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> _, exists := limits[name]; !exists {
limits[name] = delta
} &lt;span style="color:#6ab825;font-weight:bold">else&lt;/span> {
delta.&lt;span style="color:#447fcf">Add&lt;/span>(limits[name])
limits[name] = delta
}
}
}
&lt;span style="color:#999;font-style:italic">// 判断是否同时设置了 limits 和 requests，如果没有则不是 Guaranteed
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> !qosLimitsFound.&lt;span style="color:#447fcf">HasAll&lt;/span>(&lt;span style="color:#24909d">string&lt;/span>(v1.ResourceMemory), &lt;span style="color:#24909d">string&lt;/span>(v1.ResourceCPU)) {
isGuaranteed = &lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>
}
}
&lt;span style="color:#999;font-style:italic">// 如果 requests 和 limits 都没有设置，则为 BestEffort
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> &lt;span style="color:#24909d">len&lt;/span>(requests) == &lt;span style="color:#3677a9">0&lt;/span> &amp;amp;&amp;amp; &lt;span style="color:#24909d">len&lt;/span>(limits) == &lt;span style="color:#3677a9">0&lt;/span> {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> v1.PodQOSBestEffort
}
&lt;span style="color:#999;font-style:italic">// 检查所有资源的 requests 和 limits 是否都相等
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> isGuaranteed {
&lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> name, req := &lt;span style="color:#6ab825;font-weight:bold">range&lt;/span> requests {
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> lim, exists := limits[name]; !exists || lim.&lt;span style="color:#447fcf">Cmp&lt;/span>(req) != &lt;span style="color:#3677a9">0&lt;/span> {
isGuaranteed = &lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>
&lt;span style="color:#6ab825;font-weight:bold">break&lt;/span>
}
}
}
&lt;span style="color:#999;font-style:italic">// 都设置了 requests 和 limits，则为 Guaranteed
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> isGuaranteed &amp;amp;&amp;amp;
&lt;span style="color:#24909d">len&lt;/span>(requests) == &lt;span style="color:#24909d">len&lt;/span>(limits) {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> v1.PodQOSGuaranteed
}
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> v1.PodQOSBurstable
}
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="qos-打分">QoS 打分&lt;/h3>
&lt;p>QoS 会根据不同的分类进行 OOMScore 打分，当宿主机上内存不足时，系统会优先 kill 掉 OOMScore 分数高的进程。&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65ly1gjoqlfe8cgj20mr0pcqmy.jpg" alt="QoS 打分">&lt;/p>
&lt;p>值得注意的是不久之前 &lt;code>guaranteedOOMScoreAdj&lt;/code> 的值还是 &lt;code>-998&lt;/code>，今年 9 月 22 日才合并 &lt;a href="https://github.com/kubernetes/kubernetes/pull/71269">PR&lt;/a> 将其修改为 &lt;code>-997&lt;/code>，而修改的 PR 及 &lt;a href="https://github.com/kubernetes/kubernetes/issues/72294">相关 ISSUE&lt;/a> 在 2018 年就已经提出了，感兴趣的同学可以去看看。这里附上源码：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// github/kubernetes/pkg/kubelet/qos/policy.go
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">const&lt;/span> (
&lt;span style="color:#999;font-style:italic">// KubeletOOMScoreAdj is the OOM score adjustment for Kubelet
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> KubeletOOMScoreAdj &lt;span style="color:#6ab825;font-weight:bold">int&lt;/span> = -&lt;span style="color:#3677a9">999&lt;/span>
&lt;span style="color:#999;font-style:italic">// KubeProxyOOMScoreAdj is the OOM score adjustment for kube-proxy
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> KubeProxyOOMScoreAdj &lt;span style="color:#6ab825;font-weight:bold">int&lt;/span> = -&lt;span style="color:#3677a9">999&lt;/span>
guaranteedOOMScoreAdj &lt;span style="color:#6ab825;font-weight:bold">int&lt;/span> = -&lt;span style="color:#3677a9">997&lt;/span>
besteffortOOMScoreAdj &lt;span style="color:#6ab825;font-weight:bold">int&lt;/span> = &lt;span style="color:#3677a9">1000&lt;/span>
)
&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> &lt;span style="color:#447fcf">GetContainerOOMScoreAdjust&lt;/span>(pod *v1.Pod, container *v1.Container, memoryCapacity &lt;span style="color:#6ab825;font-weight:bold">int64&lt;/span>) &lt;span style="color:#6ab825;font-weight:bold">int&lt;/span> {
&lt;span style="color:#999;font-style:italic">// 高优先级 Pod 直接返回 guaranteedOOMScoreAdj
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> types.&lt;span style="color:#447fcf">IsCriticalPod&lt;/span>(pod) {
&lt;span style="color:#999;font-style:italic">// Critical pods should be the last to get killed.
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> guaranteedOOMScoreAdj
}
&lt;span style="color:#999;font-style:italic">// 根据 QoS 等级，返回 guaranteedOOMScoreAdj 或 besteffortOOMScoreAdj 的分数，这里只处理 Guaranteed 与 BestEffort
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">switch&lt;/span> v1qos.&lt;span style="color:#447fcf">GetPodQOS&lt;/span>(pod) {
&lt;span style="color:#6ab825;font-weight:bold">case&lt;/span> v1.PodQOSGuaranteed:
&lt;span style="color:#999;font-style:italic">// Guaranteed containers should be the last to get killed.
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> guaranteedOOMScoreAdj
&lt;span style="color:#6ab825;font-weight:bold">case&lt;/span> v1.PodQOSBestEffort:
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> besteffortOOMScoreAdj
}
memoryRequest := container.Resources.Requests.&lt;span style="color:#447fcf">Memory&lt;/span>().&lt;span style="color:#447fcf">Value&lt;/span>()
&lt;span style="color:#999;font-style:italic">// 内存占用越少，分数越高
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> oomScoreAdjust := &lt;span style="color:#3677a9">1000&lt;/span> - (&lt;span style="color:#3677a9">1000&lt;/span>*memoryRequest)/memoryCapacity
&lt;span style="color:#999;font-style:italic">// 保证 Burstable 分数高于 Guaranteed
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> &lt;span style="color:#24909d">int&lt;/span>(oomScoreAdjust) &amp;lt; (&lt;span style="color:#3677a9">1000&lt;/span> + guaranteedOOMScoreAdj) {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> (&lt;span style="color:#3677a9">1000&lt;/span> + guaranteedOOMScoreAdj)
}
&lt;span style="color:#999;font-style:italic">// 保证 Burstable 分数低于 BestEffect
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> &lt;span style="color:#24909d">int&lt;/span>(oomScoreAdjust) == besteffortOOMScoreAdj {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> &lt;span style="color:#24909d">int&lt;/span>(oomScoreAdjust - &lt;span style="color:#3677a9">1&lt;/span>)
}
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> &lt;span style="color:#24909d">int&lt;/span>(oomScoreAdjust)
}
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="qos-的本质区别">QoS 的本质区别&lt;/h3>
&lt;p>三种 QoS 在调度和实现都存在着区别：&lt;/p>
&lt;ul>
&lt;li>调度时，调度器只会根据 request 值进行调度，这也就解释了有些 Node 节点 Resource Limit 超出 100% 的情况&lt;/li>
&lt;li>当 OOM 时，系统会根据 &lt;code>oom_score&lt;/code> 值来选择优先 kill 掉的进程，分数越高越先被 kill 掉。&lt;code>oom_score&lt;/code> 由系统计算所得，用户是不能设置的。但是如上文所述，而根据 QoS 的类型，kubelet 会计算出 &lt;code>oom_score_adj&lt;/code> 的值，通过 &lt;code>oom_score_adj&lt;/code> 来调整 &lt;code>oom_score&lt;/code> 的分数，从而影响 OOM 被 kill 进程的优先级。&lt;/li>
&lt;li>对于资源的限制，是由 CGroup 来完成的。kubelet 会为三种 QoS 分别创建 QoS level CGroup：
&lt;ul>
&lt;li>&lt;code>Guaranteed&lt;/code> Pod Qos 的 CGroup level 会直接创建在 &lt;code>RootCgroup/kubepods&lt;/code> 下&lt;/li>
&lt;li>&lt;code>Burstable&lt;/code> Pod Qos 的创建在 &lt;code>RootCgroup/kubepods/burstable&lt;/code> 下&lt;/li>
&lt;li>&lt;code>BestEffort&lt;/code> Pod Qos 的创建在 &lt;code>RootCgroup/kubepods/BestEffort&lt;/code>下&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>而在 Pod level CGroup 中还会创建 Container level CGroup，其结构如下图所示：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65ly1gjoxdsmfs0j20mr0e8tjg.jpg" alt="Qos-CGroup">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>本文我们讨论了 Kubernetes 中 QoS 机制的分类、打分及其本质，除了这些 QoS 的实现 &lt;code>QOSContainerManager&lt;/code> 中还有三种 QoS 以宿主机上 allocatable 资源量为基础为 Pod 分配资源，并通过多个 level cgroup 进行层层限制的逻辑，由于篇幅有限，就不做详细介绍了。&lt;/p></description></item><item><title>Post: 图解 K8S 源码 - Informer 篇（上）</title><link>https://guoxudong.io/post/diagrams-k8s-src-informer/</link><pubDate>Mon, 12 Oct 2020 15:21:14 +0800</pubDate><guid>https://guoxudong.io/post/diagrams-k8s-src-informer/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>众所周知，在 Kubernetes 中各组件是通过 HTTP 协议进行通信的，而组件间的通信也并没有依赖任何中间件，那么如何保证消息的实时性、可靠性、顺序性呢？&lt;strong>Informer 机制&lt;/strong>很好的解决了这个问题。Kubernetes 中各组件与 API Server 的通信都是通过 client-go 的 informer 机制来保证和完成的。&lt;/p>
&lt;h2 id="控制器模式">控制器模式&lt;/h2>
&lt;p>控制器模式最核心的就是控制循环的概念。而 Informer 机制，也就是控制循环中负责观察系统的传感器（Sensor）主要由 Reflector、Informer、Indexer 三个组件构成。其与各种资源的 Controller 相配合，就可以完成完整的控制循环，不断的使系统向终态趋近 &lt;code>status&lt;/code> -&amp;gt; &lt;code>spec&lt;/code>。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65ly1gjme5nhuykj20mr0fmn6j.jpg" alt="informer 机制">&lt;/p>
&lt;h3 id="informer">Informer&lt;/h3>
&lt;p>所谓 informer，其实就是一个带有本地缓存和索引机制的，可以注册 EventHandler 的 client，目的是为了减轻频繁通信 API Server 的压力而抽取出来的一层 cache，客户端对 API Server 数据的&lt;strong>读取&lt;/strong>和&lt;strong>监测&lt;/strong>操作都通过本地的 informer 来进行。&lt;/p>
&lt;p>每一个 Kubernetes 资源上都实现了 informer 机制，每一个 informer 上都会实现 &lt;code>Informer()&lt;/code> 和 &lt;code>Lister()&lt;/code> 方法：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// client-go/informers/core/v1/pod.go
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span> PodInformer &lt;span style="color:#6ab825;font-weight:bold">interface&lt;/span> {
&lt;span style="color:#447fcf">Informer&lt;/span>() cache.SharedIndexInformer
&lt;span style="color:#447fcf">Lister&lt;/span>() v1.PodLister
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>定义不同资源的 Informer，允许监控不同资源事件。同时为了避免同一资源的 Informer 被实例化多次，而每个 Informer 都会使用一个 Reflector，这样会运行过多相同的 ListAndWatch，从而加重 API Server 的压力，Informer 还提供了共享机制，多个 Informer 可以共享一个 Reflector，从而达到节约资源的目的。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// client-go/informers/factory.go
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span> sharedInformerFactory &lt;span style="color:#6ab825;font-weight:bold">struct&lt;/span> {
client kubernetes.Interface
namespace &lt;span style="color:#6ab825;font-weight:bold">string&lt;/span>
tweakListOptions internalinterfaces.TweakListOptionsFunc
lock sync.Mutex
defaultResync time.Duration
customResync &lt;span style="color:#6ab825;font-weight:bold">map&lt;/span>[reflect.Type]time.Duration
informers &lt;span style="color:#6ab825;font-weight:bold">map&lt;/span>[reflect.Type]cache.SharedIndexInformer
&lt;span style="color:#999;font-style:italic">// startedInformers is used for tracking which informers have been started.
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#999;font-style:italic">// This allows Start() to be called multiple times safely.
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> startedInformers &lt;span style="color:#6ab825;font-weight:bold">map&lt;/span>[reflect.Type]&lt;span style="color:#6ab825;font-weight:bold">bool&lt;/span>
}
...
&lt;span style="color:#999;font-style:italic">// InternalInformerFor returns the SharedIndexInformer for obj using an internal client.
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> (f *sharedInformerFactory) &lt;span style="color:#447fcf">InformerFor&lt;/span>(obj runtime.Object, newFunc internalinterfaces.NewInformerFunc) cache.SharedIndexInformer {
f.lock.&lt;span style="color:#447fcf">Lock&lt;/span>()
&lt;span style="color:#6ab825;font-weight:bold">defer&lt;/span> f.lock.&lt;span style="color:#447fcf">Unlock&lt;/span>()
informerType := reflect.&lt;span style="color:#447fcf">TypeOf&lt;/span>(obj)
informer, exists := f.informers[informerType]
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> exists {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> informer
}
resyncPeriod, exists := f.customResync[informerType]
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> !exists {
resyncPeriod = f.defaultResync
}
informer = &lt;span style="color:#447fcf">newFunc&lt;/span>(f.client, resyncPeriod)
f.informers[informerType] = informer
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> informer
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 map 数据结构实现共享 Informer 机制，在 &lt;code>InformerFor()&lt;/code> 函数添加了不同资源的 Informer，在添加过程中如果已经存在同类型的 Informer，则返回当前 Informer，不再继续添加。如下就是 &lt;code>deployment&lt;/code> 的 &lt;code>Informer()&lt;/code> 方法，其中就调用了 &lt;code>InformerFor()&lt;/code> 函数。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// client-go/informers/apps/v1beta1/deployment.go
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> (f *deploymentInformer) &lt;span style="color:#447fcf">Informer&lt;/span>() cache.SharedIndexInformer {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> f.factory.&lt;span style="color:#447fcf">InformerFor&lt;/span>(&amp;amp;appsv1beta1.Deployment{}, f.defaultInformer)
}
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="reflector">Reflector&lt;/h3>
&lt;p>Reflector 用于监测制定 Kubernetes 资源，当资源发生变化时，触发相应的事件，如：Added（资源添加）事件、Update（资源更新）事件、Delete（资源删除）事件，并将事件及资源名称添加到 DeltaFIFO 中。&lt;/p>
&lt;h4 id="listandwatch">ListAndWatch&lt;/h4>
&lt;p>在实例化 Reflector 时，必须传入 ListerWatcher 接口对象，其拥有 &lt;code>List()&lt;/code> 和 &lt;code>Watch()&lt;/code> 方法。Reflector 通过 &lt;code>Run()&lt;/code> 方法启动监控并处理事件。在程序第一次运行时，会执行 &lt;code>List()&lt;/code> 方法将所有的对象数据存入 DeltaFIFO 中，每次 Controller 重启，都会执行 &lt;code>List()&lt;/code> 方法；同时，Reflector 实例中还有 &lt;code>resyncPeriod&lt;/code> 参数，如果该参数不为 0，则会根据该参数值周期性的执行 &lt;code>List()&lt;/code> 操作，此时这些资源对象会被设置为 Sync 操作类型（不同于 Add、Update 等）。&lt;/p>
&lt;p>而 &lt;code>Watch()&lt;/code> 则会根据 Reflector 实例 &lt;code>period&lt;/code> 参数，周期性的监控资源对象是否有变更。如果发生变更，则通过 &lt;code>r.watchHandler&lt;/code> 处理变更事件。&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65ly1gjmkxmiboej20mr0uwh9f.jpg" alt="Reflector">&lt;/p>
&lt;h4 id="deltafifo">DeltaFIFO&lt;/h4>
&lt;p>DeltaFIFO 顾名思义，Delta 是一个资源对象存储，可以保持操作类型（Add、Update、Delete、Sync等）；而 FIFO 则是一个先进先出的队列。其是一个生产者与消费者的队列，其中 Reflector 是生产者，消费者则调用 &lt;code>Pop()&lt;/code> 方法取出最早进入队列的对象数据。&lt;/p>
&lt;h3 id="indexer">Indexer&lt;/h3>
&lt;p>Indexer 是 client-go 用来存储资源对象并自带索引功能的本地存储，Reflector 从 DeltaFIFO 中将消费出来的资源对象存储至 Indexer。同时 Indexer 中的数据与 Etcd 中的数据保持完全一致。client-go 可以很方便的从本次存储中读取相应的资源对象数据，而无需每次都从远程 Etcd 集群中读取，从而降低了 API Server 和 Etcd 集群的压力。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>要了解 Kubernetes，Informer 是绕不过的内容，其在 Kubernetes 中非常重要。本文主要图解了 Informer 机制以及 Reflector，由于篇幅有限，DeltaFIFO，Indexer 等概念只做了简单介绍，这些内容会在后续的文章中进行详解，敬请期待。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>《Kubernetes 源码剖析 - 郑东旭著》&lt;/li>
&lt;/ul></description></item><item><title>Post: 图解 K8S 源码 - Deployment Controller 篇</title><link>https://guoxudong.io/post/diagrams-k8s-src-deployment-controller/</link><pubDate>Mon, 28 Sep 2020 15:00:38 +0800</pubDate><guid>https://guoxudong.io/post/diagrams-k8s-src-deployment-controller/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Kubernetes 最为云原生领域的绝对 leader，可以说是当下最著名开源项目之一，拥有着庞大的贡献者群体以及更庞大的用户群体。作为使用 Go 语言开发的明星项目，其源码也是非常有趣的。笔者在研究 Kubernetes 源码时，常常发现很多让人眼前一亮的设计和拍案叫绝的逻辑。但由于 Kubernetes 的代码量十分庞大，函数间的调用也十分复杂，在阅读源码时常常被绕的找不着北，正好手边有一本《图解算法》，于是就萌生了图解 Kubernetes 源码的想法。本文为本系列第一篇文章，尝试使用流程图来分析 Kubernetes Controller Manager 中 的 Deployment Controller 逻辑。&lt;/p>
&lt;h2 id="deployment-controller">Deployment Controller&lt;/h2>
&lt;p>Deployment Controller 是 Kube-Controller-Manager 中最常用的 Controller 之一管理 Deployment 资源。而 Deployment 的本质就是通过管理 ReplicaSet 和 Pod 在 Kubernetes 集群中部署 &lt;strong>无状态&lt;/strong> Workload。&lt;/p>
&lt;h3 id="deploymentreplicaset-和-pod">Deployment、ReplicaSet 和 Pod&lt;/h3>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gj6twofn24j20es09s43a.jpg" alt="deployment-controller">&lt;/p>
&lt;p>Deployment 通过控制 ReplicaSet，ReplicaSet 再控制 Pod，最终由 Controller 驱动达到期望状态。在控制器模式下，每次操作对象都会触发一次事件，然后 controller 会进行一次 syncLoop 操作，controller 是通过 informer 监听事件以及进行 ListWatch 操作的。&lt;/p>
&lt;p>Deployment Controller 会监听 DeploymentInformer、ReplicaSetInformer、PodInformer 三种资源。这三种资源变化时，都会触发 syncLoop 也就是下面代码 &lt;code>dc.Run()&lt;/code> 中的 &lt;code>dc.syncDeployment&lt;/code> 操作，来进行状态更新逻辑。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> &lt;span style="color:#447fcf">startDeploymentController&lt;/span>(ctx ControllerContext) (http.Handler, &lt;span style="color:#6ab825;font-weight:bold">bool&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">error&lt;/span>) {
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> !ctx.AvailableResources[schema.GroupVersionResource{Group: &lt;span style="color:#ed9d13">&amp;#34;apps&amp;#34;&lt;/span>, Version: &lt;span style="color:#ed9d13">&amp;#34;v1&amp;#34;&lt;/span>, Resource: &lt;span style="color:#ed9d13">&amp;#34;deployments&amp;#34;&lt;/span>}] {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
dc, err := deployment.&lt;span style="color:#447fcf">NewDeploymentController&lt;/span>(
ctx.InformerFactory.&lt;span style="color:#447fcf">Apps&lt;/span>().&lt;span style="color:#447fcf">V1&lt;/span>().&lt;span style="color:#447fcf">Deployments&lt;/span>(),
ctx.InformerFactory.&lt;span style="color:#447fcf">Apps&lt;/span>().&lt;span style="color:#447fcf">V1&lt;/span>().&lt;span style="color:#447fcf">ReplicaSets&lt;/span>(),
ctx.InformerFactory.&lt;span style="color:#447fcf">Core&lt;/span>().&lt;span style="color:#447fcf">V1&lt;/span>().&lt;span style="color:#447fcf">Pods&lt;/span>(),
ctx.ClientBuilder.&lt;span style="color:#447fcf">ClientOrDie&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;deployment-controller&amp;#34;&lt;/span>),
)
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> err != &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span> {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>, fmt.&lt;span style="color:#447fcf">Errorf&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;error creating Deployment controller: %v&amp;#34;&lt;/span>, err)
}
&lt;span style="color:#6ab825;font-weight:bold">go&lt;/span> dc.&lt;span style="color:#447fcf">Run&lt;/span>(&lt;span style="color:#24909d">int&lt;/span>(ctx.ComponentConfig.DeploymentController.ConcurrentDeploymentSyncs), ctx.Stop)
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="deployment-controller-启动流程">Deployment Controller 启动流程&lt;/h3>
&lt;p>那么先从启动逻辑开始，Kube-Controller-Manager 中所有的 Controller 的启动逻辑都差不多，都是在 &lt;code>Run()&lt;/code> 方法中完成初始化并启动，&lt;code>NewControllerInitializers&lt;/code> 会初始化所有 Controller，而 &lt;code>startXXXXController()&lt;/code> 则会启动对应的 Controller。&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gj6rw439nrj20mh12o7wh.jpg" alt="deployment-controller-启动流程">&lt;/p>
&lt;h3 id="核心逻辑-synchandler">核心逻辑 syncHandler&lt;/h3>
&lt;p>Deployment Controller 在初始化时指定了 &lt;code>dc.syncHandler = dc.syncDeployment&lt;/code>，所以核心逻辑就是围绕 &lt;code>syncDeployment()&lt;/code> 来展开的。&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gj6s4tfuynj20my1zq7wi.jpg" alt="deployment-controller-核心逻辑">&lt;/p>
&lt;p>从源码可以看出，删除、暂停、回滚、扩缩容、更新策略的优先级为 &lt;code>delete &amp;gt; pause &amp;gt; rollback &amp;gt; scale &amp;gt; rollout&lt;/code>。而最终都不是直接更新或修改对应资源，而是通过 &lt;code>dc.client.AppsV1().Deployments().UpdateStatus()&lt;/code> 更新 Deployment Status。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>以上就是 Deployment Controller 代码逻辑，通过流程图，希望能描述的更加清晰。因为是第一次尝试图解，可能有遗漏和不足，欢迎留言指正。图解 Kubernetes 源码将作为一个系列继续下去，后续会带来更多的源码图解。&lt;/p></description></item><item><title>Post: 熟悉又陌生的 k8s 字段：finalizers</title><link>https://guoxudong.io/post/k8s-gc-finalizers/</link><pubDate>Fri, 11 Sep 2020 08:47:51 +0800</pubDate><guid>https://guoxudong.io/post/k8s-gc-finalizers/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>经常操作 Kubernetes 集群的同学肯定对 &lt;code>finalizers&lt;/code> 字段不陌生，每当删除 namespace 或 pod 等一些 Kubernetes 资源时，有时资源状态会卡在 &lt;code>Terminating&lt;/code>，很长时间无法删除，甚至有时增加 &lt;code>--force&lt;/code> flag 之后还是无法正常删除。这时就需要 &lt;code>edit&lt;/code> 该资源，将 &lt;code>finalizers&lt;/code> 字段设置为 []，之后 Kubernetes 资源就正常删除了。&lt;/p>
&lt;p>这是一个比较常见的操作，但是当有人问 &lt;code>finalizers&lt;/code> 字段的作用是什么的时候，我是懵逼的，我甚至不知道这个熟悉又陌生的单词怎么读！那么这篇文章就来探索一下 &lt;code>finalizers&lt;/code> 这个字段到底是做什么的，在实践中应该怎么应用这个字段。（另外，这个单词读作 &lt;strong>[&amp;lsquo;faɪnəlaɪzər]&lt;/strong>）&lt;/p>
&lt;h2 id="finalizers">Finalizers&lt;/h2>
&lt;p>Finalizers 字段属于 Kubernetes GC 垃圾收集器，是一种删除拦截机制，能够让控制器实现异步的删除前（Pre-delete）回调。其存在于任何一个资源对象的 &lt;a href="https://github.com/kubernetes/apimachinery/blob/master/pkg/apis/meta/v1/types.go#L246">Meta&lt;/a> 中，在 k8s 源码中声明为 &lt;code>[]string&lt;/code>，该 Slice 的内容为需要执行的拦截器名称。&lt;/p>
&lt;p>对带有 Finalizer 的对象的第一个删除请求会为其 &lt;code>metadata.deletionTimestamp&lt;/code> 设置一个值，但不会真的删除对象。一旦此值被设置，finalizers 列表中的值就&lt;strong>只能&lt;/strong>被移除。&lt;/p>
&lt;p>当 &lt;code>metadata.deletionTimestamp&lt;/code> 字段被设置时，负责监测该对象的各个控制器会通过&lt;strong>轮询&lt;/strong>对该对象的更新请求来执行它们所要处理的所有 Finalizer。 当所有 Finalizer 都被执行过，资源被删除。&lt;/p>
&lt;p>&lt;code>metadata.deletionGracePeriodSeconds&lt;/code> 的取值控制对更新的轮询周期。&lt;/p>
&lt;p>每个控制器要负责将其 Finalizer 从列表中去除。&lt;/p>
&lt;p>每执行完一个就从 &lt;code>finalizers&lt;/code> 中移除一个，直到 &lt;code>finalizers&lt;/code> 为空，之后其宿主资源才会被真正的删除。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// DeletionTimestamp is RFC 3339 date and time at which this resource will be deleted. This
&lt;/span>&lt;span style="color:#999;font-style:italic">// field is set by the server when a graceful deletion is requested by the user, and is not
&lt;/span>&lt;span style="color:#999;font-style:italic">// directly settable by a client. The resource is expected to be deleted (no longer visible
&lt;/span>&lt;span style="color:#999;font-style:italic">// from resource lists, and not reachable by name) after the time in this field, once the
&lt;/span>&lt;span style="color:#999;font-style:italic">// finalizers list is empty. As long as the finalizers list contains items, deletion is blocked.
&lt;/span>&lt;span style="color:#999;font-style:italic">// Once the deletionTimestamp is set, this value may not be unset or be set further into the
&lt;/span>&lt;span style="color:#999;font-style:italic">// future, although it may be shortened or the resource may be deleted prior to this time.
&lt;/span>&lt;span style="color:#999;font-style:italic">// For example, a user may request that a pod is deleted in 30 seconds. The Kubelet will react
&lt;/span>&lt;span style="color:#999;font-style:italic">// by sending a graceful termination signal to the containers in the pod. After that 30 seconds,
&lt;/span>&lt;span style="color:#999;font-style:italic">// the Kubelet will send a hard termination signal (SIGKILL) to the container and after cleanup,
&lt;/span>&lt;span style="color:#999;font-style:italic">// remove the pod from the API. In the presence of network partitions, this object may still
&lt;/span>&lt;span style="color:#999;font-style:italic">// exist after this timestamp, until an administrator or automated process can determine the
&lt;/span>&lt;span style="color:#999;font-style:italic">// resource is fully terminated.
&lt;/span>&lt;span style="color:#999;font-style:italic">// If not set, graceful deletion of the object has not been requested.
&lt;/span>&lt;span style="color:#999;font-style:italic">//
&lt;/span>&lt;span style="color:#999;font-style:italic">// Populated by the system when a graceful deletion is requested.
&lt;/span>&lt;span style="color:#999;font-style:italic">// Read-only.
&lt;/span>&lt;span style="color:#999;font-style:italic">// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
&lt;/span>&lt;span style="color:#999;font-style:italic">// +optional
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>DeletionTimestamp *Time &lt;span style="color:#ed9d13">`json:&amp;#34;deletionTimestamp,omitempty&amp;#34; protobuf:&amp;#34;bytes,9,opt,name=deletionTimestamp&amp;#34;`&lt;/span>
&lt;span style="color:#999;font-style:italic">// Number of seconds allowed for this object to gracefully terminate before
&lt;/span>&lt;span style="color:#999;font-style:italic">// it will be removed from the system. Only set when deletionTimestamp is also set.
&lt;/span>&lt;span style="color:#999;font-style:italic">// May only be shortened.
&lt;/span>&lt;span style="color:#999;font-style:italic">// Read-only.
&lt;/span>&lt;span style="color:#999;font-style:italic">// +optional
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>DeletionGracePeriodSeconds *&lt;span style="color:#6ab825;font-weight:bold">int64&lt;/span> &lt;span style="color:#ed9d13">`json:&amp;#34;deletionGracePeriodSeconds,omitempty&amp;#34; protobuf:&amp;#34;varint,10,opt,name=deletionGracePeriodSeconds&amp;#34;`&lt;/span>
&lt;span style="color:#999;font-style:italic">// Must be empty before the object is deleted from the registry. Each entry
&lt;/span>&lt;span style="color:#999;font-style:italic">// is an identifier for the responsible component that will remove the entry
&lt;/span>&lt;span style="color:#999;font-style:italic">// from the list. If the deletionTimestamp of the object is non-nil, entries
&lt;/span>&lt;span style="color:#999;font-style:italic">// in this list can only be removed.
&lt;/span>&lt;span style="color:#999;font-style:italic">// Finalizers may be processed and removed in any order. Order is NOT enforced
&lt;/span>&lt;span style="color:#999;font-style:italic">// because it introduces significant risk of stuck finalizers.
&lt;/span>&lt;span style="color:#999;font-style:italic">// finalizers is a shared field, any actor with permission can reorder it.
&lt;/span>&lt;span style="color:#999;font-style:italic">// If the finalizer list is processed in order, then this can lead to a situation
&lt;/span>&lt;span style="color:#999;font-style:italic">// in which the component responsible for the first finalizer in the list is
&lt;/span>&lt;span style="color:#999;font-style:italic">// waiting for a signal (field value, external system, or other) produced by a
&lt;/span>&lt;span style="color:#999;font-style:italic">// component responsible for a finalizer later in the list, resulting in a deadlock.
&lt;/span>&lt;span style="color:#999;font-style:italic">// Without enforced ordering finalizers are free to order amongst themselves and
&lt;/span>&lt;span style="color:#999;font-style:italic">// are not vulnerable to ordering changes in the list.
&lt;/span>&lt;span style="color:#999;font-style:italic">// +optional
&lt;/span>&lt;span style="color:#999;font-style:italic">// +patchStrategy=merge
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>Finalizers []&lt;span style="color:#6ab825;font-weight:bold">string&lt;/span> &lt;span style="color:#ed9d13">`json:&amp;#34;finalizers,omitempty&amp;#34; patchStrategy:&amp;#34;merge&amp;#34; protobuf:&amp;#34;bytes,14,rep,name=finalizers&amp;#34;`&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="在-operator-中的应用">在 Operator 中的应用&lt;/h2>
&lt;p>知道了 Finalizers 是什么，那么当然也要知道怎么用 Finalizers 了。在实际开发 Operator 时，删除前（Pre-delete）回调是一个比较常见的功能，用于处理一些在资源删除前需要处理的逻辑，如：关联资源释放、释放资源通知、相关数据清理，甚至是阻止资源删除。一般 Finalizers 的处理也是会 &lt;code>Reconcile&lt;/code> 中实现的，下面就使用 &lt;a href="https://github.com/chaosblade-io/chaosblade-operator">chaosblade-operator&lt;/a> 中的源码，简单介绍一些 Finalizers 的使用方式。&lt;/p>
&lt;p>首先要了解的是 ChaosBlade-Operator 的工作原理：每个实验都会以 CR 的形式部署到 k8s 集群中，之后由 &lt;code>chaosblade-operator&lt;/code> 来操作以 DaemonSet 形式部署 &lt;code>chaosblade-tool&lt;/code> 对具体资源进行混沌实验。停止实验只需删除对应 CR 即可，在删除 CR 时，首先会执行一遍实验恢复逻辑，之后才会将 CR 删除。但如果恢复实验失败，则会将 CR 的 &lt;code>Phase&lt;/code> 设置为 &lt;code>Destroying&lt;/code>，而在 &lt;code>Reconcile&lt;/code> 中观测到 &lt;code>Phase&lt;/code> 状态为 &lt;code>Destroying&lt;/code> 或者 &lt;code>metadata.deletionTimestamp&lt;/code> 不为空时，就会不会移除 &lt;code>finalizers&lt;/code> 中的拦截器名称，阻止该 CR 被删除。&lt;/p>
&lt;p>这样设计的目的是为了在实验恢复失败后，让用户去主动查看实验恢复失败原因，如果是一些意外原因导致的实验恢复失败，及时去处理。在确认原因后，可使用 CLI 工具增加 &lt;code>--force-remove&lt;/code> 进去强制删除，项目维护者在 &lt;a href="https://github.com/chaosblade-io/chaosblade/issues/368">Issue#368&lt;/a> 中也就这个设计给出了解答。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#999;font-style:italic">// pkg/controller/chaosblade/controller.go 部分源码
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span>...
&lt;span style="color:#6ab825;font-weight:bold">const&lt;/span> chaosbladeFinalizer = &lt;span style="color:#ed9d13">&amp;#34;finalizer.chaosblade.io&amp;#34;&lt;/span>
...
&lt;span style="color:#6ab825;font-weight:bold">func&lt;/span> (r *ReconcileChaosBlade) &lt;span style="color:#447fcf">Reconcile&lt;/span>(request reconcile.Request) (reconcile.Result, &lt;span style="color:#6ab825;font-weight:bold">error&lt;/span>) {
reqLogger := logrus.&lt;span style="color:#447fcf">WithField&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;Request.Name&amp;#34;&lt;/span>, request.Name)
forget := reconcile.Result{}
&lt;span style="color:#999;font-style:italic">// Fetch the RC instance
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> cb := &amp;amp;v1alpha1.ChaosBlade{}
err := r.client.&lt;span style="color:#447fcf">Get&lt;/span>(context.&lt;span style="color:#447fcf">TODO&lt;/span>(), request.NamespacedName, cb)
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> err != &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span> {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> forget, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> &lt;span style="color:#24909d">len&lt;/span>(cb.Spec.Experiments) == &lt;span style="color:#3677a9">0&lt;/span> {
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> forget, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
&lt;span style="color:#999;font-style:italic">// Destroyed-&amp;gt;delete
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#999;font-style:italic">// Remove the Finalizer if the CR object status is destroyed to delete it
&lt;/span>&lt;span style="color:#999;font-style:italic">&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> cb.Status.Phase == v1alpha1.ClusterPhaseDestroyed {
cb.&lt;span style="color:#447fcf">SetFinalizers&lt;/span>(&lt;span style="color:#447fcf">remove&lt;/span>(cb.&lt;span style="color:#447fcf">GetFinalizers&lt;/span>(), chaosbladeFinalizer))
err := r.client.&lt;span style="color:#447fcf">Update&lt;/span>(context.&lt;span style="color:#447fcf">TODO&lt;/span>(), cb)
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> err != &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span> {
reqLogger.&lt;span style="color:#447fcf">WithError&lt;/span>(err).&lt;span style="color:#447fcf">Errorln&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;remove chaosblade finalizer failed at destroyed phase&amp;#34;&lt;/span>)
}
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> forget, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> cb.Status.Phase == v1alpha1.ClusterPhaseDestroying || cb.&lt;span style="color:#447fcf">GetDeletionTimestamp&lt;/span>() != &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span> {
err := r.&lt;span style="color:#447fcf">finalizeChaosBlade&lt;/span>(reqLogger, cb)
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> err != &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span> {
reqLogger.&lt;span style="color:#447fcf">WithError&lt;/span>(err).&lt;span style="color:#447fcf">Errorln&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;finalize chaosblade failed at destroying phase&amp;#34;&lt;/span>)
}
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> forget, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
...
&lt;span style="color:#6ab825;font-weight:bold">return&lt;/span> forget, &lt;span style="color:#6ab825;font-weight:bold">nil&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果 &lt;code>Phase&lt;/code> 状态为 &lt;code>Destroyed&lt;/code>，则从 Finalizers 中移除 &lt;code>finalizer.chaosblade.io&lt;/code>，之后正常删除 CR。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>在实际工作中，像 Finalizers 这样的东西太多了，很多平时挂在嘴边的东西，深究起来我们可能对其并不了解，甚至原本的理解就是错误的。在今后的文章中，除了各种实践干货，笔者还会将更多的精力投注到基本原理、底层实现、源码剖析中，更聚焦于技术本身，在不重复造轮子的基础上，学习和了解更多产品背后的代码设计和实现原理。最后在分享一句&lt;strong>弗兰西斯·培根&lt;/strong>的话：&lt;/p>
&lt;p>&lt;strong>“人生如同道路。最近的捷径通常是最坏的路。”&lt;/strong>&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/zh/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#finalizers">使用 CustomResourceDefinition 扩展 Kubernetes API - kubernetes.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Post: 基于 Flagger 和 Nginx-Ingress 实现金丝雀发布</title><link>https://guoxudong.io/post/flagger-nginx-ingress/</link><pubDate>Thu, 02 Jul 2020 13:51:14 +0800</pubDate><guid>https://guoxudong.io/post/flagger-nginx-ingress/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>很久之前我写过一篇介绍使用 Nginx-Ingress 实现蓝绿部署和金丝雀发布的文章，但那篇文章只是介绍了 nginx-ingress 具备这些能力，真正应用还要很多额外的配置和操作，况且现在能实现这些功能的并不只有 nginx-ingress，Service Mesh 工具如：Istio，App Mesh，Linkerd；Ingress Controller 如：Contour，Gloo，NGINX 都能实现，而我们需要的更多是进行金丝雀发布之后指标的监控，流量的调整以及出现问题后的及时回滚。而 Flagger 就是这样一个帮助我们解决上面这些问题的开源工具。&lt;/p>
&lt;h2 id="flagger">Flagger&lt;/h2>
&lt;p>&lt;a href="https://github.com/weaveworks/flagger">Flagger&lt;/a> 是一种渐进式交付工具，可自动控制 Kubernetes 上应用程序的发布过程。通过指标监控和运行一致性测试，将流量逐渐切换到新版本，降低在生产环境中发布新软件版本导致的风险。&lt;/p>
&lt;p>Flagger 使用 Service Mesh（App Mesh，Istio，Linkerd）或 Ingress Controller（Contour，Gloo，NGINX）来实现多种部署策略（金丝雀发布，A/B 测试，蓝绿发布）。对于发布分析，Flagger 可以查询 Prometheus、Datadog 或 CloudWatch，并使用 Slack、MS Teams、Discord 和 Rocket 来发出告警通知。&lt;/p>
&lt;blockquote>
&lt;p>本文主要介绍 Flagger 使用 Nginx-Ingress 进行金丝雀发布并监控发布状态，更多内容见&lt;a href="https://docs.flagger.app/">官方文档&lt;/a>。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65ly1ggclsv45tqj21ok0skwfb.jpg" alt="Flagger NGINX Ingress Controller">&lt;/p>
&lt;h3 id="前提条件">前提条件&lt;/h3>
&lt;h4 id="版本要求">版本要求&lt;/h4>
&lt;p>安装 Flagger 需要 Kubernetes 版本高于 &lt;strong>v1.14&lt;/strong>，NGINX ingress 版本高于 &lt;strong>0.24&lt;/strong>。&lt;/p>
&lt;h4 id="安装-nginx-ingress">安装 NGINX ingress&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl create ns ingress-nginx
$ helm upgrade -i nginx-ingress stable/nginx-ingress &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--namespace ingress-nginx &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set controller.metrics.enabled=&lt;span style="color:#24909d">true&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set controller.podAnnotations.&lt;span style="color:#ed9d13">&amp;#34;prometheus\.io/scrape&amp;#34;&lt;/span>=&lt;span style="color:#24909d">true&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set controller.podAnnotations.&lt;span style="color:#ed9d13">&amp;#34;prometheus\.io/port&amp;#34;&lt;/span>=&lt;span style="color:#3677a9">10254&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="安装部署">安装部署&lt;/h3>
&lt;h4 id="flagger-安装">Flagger 安装&lt;/h4>
&lt;p>Flagger 提供了 Hlem 和 Kustomize 两种安装方式，这里使用 Helm 3 安装：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helm repo add flagger https://flagger.app
$ helm upgrade -i flagger flagger/flagger &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--namespace ingress-nginx &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set prometheus.install=&lt;span style="color:#24909d">true&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set &lt;span style="color:#40ffff">meshProvider&lt;/span>=nginx &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set slack.url=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set slack.channel=flagger &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set slack.user=flagger
&lt;/code>&lt;/pre>&lt;/div>&lt;p>值得注意的是这里我选择了 Slack 作为通知软件，需要在自己的 &lt;code>#channel&lt;/code> 内新增一个 APP，并将该 APP 的 &lt;code>url&lt;/code>、&lt;code>channel&lt;/code>、&lt;code>user&lt;/code> 填入上面的命令中。这里设置的是全局通知，集群中的 Flagger 被触发后都会进行通知，当然也可以为单个 Flagger 配置专门的通知，这里就不做过多介绍，详情见&lt;a href="https://docs.flagger.app/usage/alerting">官方文档&lt;/a>。&lt;/p>
&lt;h4 id="示例安装">示例安装&lt;/h4>
&lt;p>新建测试 namespace：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl create ns &lt;span style="color:#24909d">test&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署示例 deployment 和 horizontal pod autoscaler：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl apply -k github.com/weaveworks/flagger//kustomize/podinfo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署负载测试器，以便在金丝雀发布时进行流量分析：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helm upgrade -i flagger-loadtester flagger/loadtester --namespace=&lt;span style="color:#24909d">test&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署 ingress，这里的 &lt;code>app.example.com&lt;/code> 需要改成你自己的域名，如果是在本地进行测试，则修改本机和负载测试器所在节点的 &lt;code>/ect/hosts&lt;/code>，将其指向你的 ADDRESS，否则将无法进行流量分析，导致部署失败。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>networking.k8s.io/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Ingress&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kubernetes.io/ingress.class&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;nginx&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">rules&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">host&lt;/span>:&lt;span style="color:#666"> &lt;/span>app.example.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">http&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">paths&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">backend&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">servicePort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>将以上内容另存为 &lt;code>podinfo-ingress.yaml&lt;/code>，然后应用：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl apply -f ./podinfo-ingress.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>创建一个 Canary 资源：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>flagger.app/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Canary&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">provider&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># deployment reference&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># ingress reference&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ingressRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>networking.k8s.io/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Ingress&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># HPA reference (optional)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">autoscalerRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>autoscaling/v2beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>HorizontalPodAutoscaler&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># the maximum time in seconds for the canary deployment&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># to make progress before it is rollback (default 600s)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">progressDeadlineSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">60&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">service&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># ClusterIP port number&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># container port number or name&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">9898&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">analysis&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 时间间隔 (默认 60s)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">interval&lt;/span>:&lt;span style="color:#666"> &lt;/span>10s&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 回滚前的最大失败指标检查次数&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">threshold&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 路由到金丝雀副本的最大流量百分比&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 百分比 (0-100)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">maxWeight&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">50&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 金丝雀每次递增的百分比&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 百分比 (0-100)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">stepWeight&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">5&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># NGINX Prometheus checks&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metrics&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>request-success-rate&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># minimum req success rate (non 5xx responses)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># percentage (0-100)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">thresholdRange&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">min&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">99&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">interval&lt;/span>:&lt;span style="color:#666"> &lt;/span>1m&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># testing (optional)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">webhooks&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>acceptance-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>pre-rollout&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>http://flagger-loadtester.test/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeout&lt;/span>:&lt;span style="color:#666"> &lt;/span>30s&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>bash&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cmd&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;curl -sd &amp;#39;test&amp;#39; http://podinfo-canary/token | grep token&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>load-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>http://flagger-loadtester.test/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeout&lt;/span>:&lt;span style="color:#666"> &lt;/span>5s&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cmd&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;hey -z 1m -q 10 -c 2 http://app.example.com/&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>将以上内容另存为 &lt;code>podinfo-canary.yaml&lt;/code>，然后应用：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl apply -f ./podinfo-canary.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>目前可以看到示例应用 &lt;code>podinfo&lt;/code> 已经安装完毕，并出现了 &lt;code>podinfo&lt;/code> 和 &lt;code>podinfo-primary&lt;/code> 两个版本，并且 &lt;code>http://app.example.com/&lt;/code> 已经可以访问：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get deploy,svc,ing -n &lt;span style="color:#24909d">test&lt;/span>
NAME READY UP-TO-DATE AVAILABLE AGE
deployment.apps/flagger-loadtester 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 29h
deployment.apps/podinfo 0/0 &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">0&lt;/span> 29h
deployment.apps/podinfo-primary 2/2 &lt;span style="color:#3677a9">2&lt;/span> &lt;span style="color:#3677a9">2&lt;/span> 29s
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/flagger-loadtester ClusterIP 10.43.116.74 &amp;lt;none&amp;gt; 80/TCP 29h
service/podinfo ClusterIP 10.43.155.193 &amp;lt;none&amp;gt; 80/TCP 9s
service/podinfo-canary ClusterIP 10.43.194.226 &amp;lt;none&amp;gt; 80/TCP 29s
service/podinfo-primary ClusterIP 10.43.254.13 &amp;lt;none&amp;gt; 80/TCP 29s
NAME HOSTS ADDRESS PORTS AGE
ingress.extensions/podinfo app.example.com 192.168.1.129,192.168.4.210 &lt;span style="color:#3677a9">80&lt;/span> 5h17m
ingress.extensions/podinfo-canary app.example.com &lt;span style="color:#3677a9">80&lt;/span> 9s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个页面会展示 &lt;code>podinfo&lt;/code> 的版本已经其正在访问的 pod 名称：&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65ly1ggcndtuqzsj21ha0q940s.jpg" alt="app.example.com">&lt;/p>
&lt;h3 id="自动金丝雀发布">自动金丝雀发布&lt;/h3>
&lt;p>现在起发布由 Flagger 控制，在部署新版本后，Flagger 自动将流量按照比例切换到新版本上，同时监控性能指标，例如 HTTP 请求的成功率、请求的平均持续时间和 pod 运行状态，经过分析后提升流量或者回滚，并通知到 Slack。&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65ly1ggcng8c8vnj21q40t6q3n.jpg" alt="自动金丝雀发布">&lt;/p>
&lt;p>通过更新镜像版本触发金丝雀部署：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n &lt;span style="color:#24909d">test&lt;/span> &lt;span style="color:#24909d">set&lt;/span> image deployment/podinfo &lt;span style="color:#40ffff">podinfod&lt;/span>=stefanprodan/podinfo:3.1.1
deployment.apps/podinfo image updated
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到初始化完成后已经有 5% 的流量切换到新版本了&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n &lt;span style="color:#24909d">test&lt;/span> describe canary/podinfo
...
Status:
Canary Weight: &lt;span style="color:#3677a9">5&lt;/span>
Conditions:
Last Transition Time: 2020-07-02T07:21:26Z
Last Update Time: 2020-07-02T07:21:26Z
Message: New revision detected, progressing canary analysis.
Reason: Progressing
Status: Unknown
Type: Promoted
Failed Checks: &lt;span style="color:#3677a9">0&lt;/span>
Iterations: &lt;span style="color:#3677a9">0&lt;/span>
Last Applied Spec: c8bdf98d5
Last Transition Time: 2020-07-02T07:22:05Z
Phase: Progressing
Tracked Configs:
Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning Synced 10m flagger podinfo-primary.test not ready: waiting &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> rollout to finish: observed deployment generation less &lt;span style="color:#6ab825;font-weight:bold">then&lt;/span> desired generation
Warning Synced 10m flagger podinfo-primary.test not ready: waiting &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> rollout to finish: &lt;span style="color:#3677a9">0&lt;/span> of &lt;span style="color:#3677a9">2&lt;/span> updated replicas are available
Normal Synced 10m (x3 over 10m) flagger all the metrics providers are available!
Normal Synced 10m flagger Initialization &lt;span style="color:#6ab825;font-weight:bold">done&lt;/span>! podinfo.test
Normal Synced 41s flagger New revision detected! Scaling up podinfo.test
Warning Synced 31s flagger canary deployment podinfo.test not ready: waiting &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> rollout to finish: &lt;span style="color:#3677a9">0&lt;/span> of &lt;span style="color:#3677a9">1&lt;/span> updated replicas are available
Warning Synced 21s flagger canary deployment podinfo.test not ready: waiting &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> rollout to finish: &lt;span style="color:#3677a9">0&lt;/span> of &lt;span style="color:#3677a9">2&lt;/span> updated replicas are available
Warning Synced 11s flagger canary deployment podinfo.test not ready: waiting &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> rollout to finish: &lt;span style="color:#3677a9">1&lt;/span> of &lt;span style="color:#3677a9">2&lt;/span> updated replicas are available
Normal Synced 1s flagger Starting canary analysis &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> podinfo.test
Normal Synced 1s flagger Pre-rollout check acceptance-test passed
Normal Synced 1s flagger Advance podinfo.test canary weight &lt;span style="color:#3677a9">5&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 &lt;code>watch&lt;/code> 也能实时看到部署流量的权重，根据上面的设置，新版本权重大于 50% 就认为部署成功，流量将全部切换到新版本，并完成金丝雀部署：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ watch kubectl get canaries --all-namespaces
Every 2.0s: kubectl get canaries --all-namespaces guoxudongdeMacBook-Pro.local: Thu Jul &lt;span style="color:#3677a9">2&lt;/span> 15:23:35 &lt;span style="color:#3677a9">2020&lt;/span>
NAMESPACE NAME STATUS WEIGHT LASTTRANSITIONTIME
&lt;span style="color:#24909d">test&lt;/span> podinfo Progressing &lt;span style="color:#3677a9">45&lt;/span> 2020-07-02T07:23:25Z
&lt;/code>&lt;/pre>&lt;/div>&lt;p>开始部署时的 Slack 通知：&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65ly1ggcnsojp0kj20kj07kdgc.jpg" alt="Slack 通知">&lt;/p>
&lt;p>页面上也能看出变化，访问到新版本的概率会越来越高，以蓝色和绿色的圆代表新版本和老版本：&lt;/p>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65ly1ggco0nxzdrj21h80q8gnu.jpg" alt="金丝雀发布">&lt;/p>
&lt;p>发布成功后，会收到 Slack 通知：&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65ly1ggco2mdlphj20kq01h0sn.jpg" alt="Slack 通知">&lt;/p>
&lt;h3 id="自动回滚">自动回滚&lt;/h3>
&lt;p>当然，有自动发布就会有自动回滚，下面就通过手动触发状态码 500 异常，演示暂停发布并回滚。&lt;/p>
&lt;p>部署一个新版本：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n &lt;span style="color:#24909d">test&lt;/span> &lt;span style="color:#24909d">set&lt;/span> image deployment/podinfo &lt;span style="color:#40ffff">podinfod&lt;/span>=stefanprodan/podinfo:3.1.2
&lt;/code>&lt;/pre>&lt;/div>&lt;p>触发状态码 500 异常：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ watch curl http://app.example.com/status/500
&lt;/code>&lt;/pre>&lt;/div>&lt;p>等待一会儿，就可以看到部署失败并回滚：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ watch kubectl get canaries --all-namespaces
Every 2.0s: kubectl get canaries --all-namespaces guoxudongdeMacBook-Pro.local: Thu Jul &lt;span style="color:#3677a9">2&lt;/span> 15:45:24 &lt;span style="color:#3677a9">2020&lt;/span>
NAMESPACE NAME STATUS WEIGHT LASTTRANSITIONTIME
&lt;span style="color:#24909d">test&lt;/span> podinfo Failed &lt;span style="color:#3677a9">0&lt;/span> 2020-07-02T07:45:16Z
&lt;/code>&lt;/pre>&lt;/div>&lt;p>发布失败，也会收到 Slack 通知：&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65ly1ggcobt1f0bj20kd01vmx1.jpg" alt="失败 Slack 通知">&lt;/p>
&lt;h3 id="ab-测试">A/B 测试&lt;/h3>
&lt;p>除了加权路由，Flagger 还可以根据 HTTP 匹配条件将流量路由到新版本（当然，这个 Nginx-Ingress 的功能，Flagger 只是简化了操作）。可以根据 HTTP header 和 cookie 来定位用户并细分受众，对于需要关联会话的前端应用十分有用。&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65ly1ggcoglbmnyj217q0q0q3h.jpg" alt="A/B 测试">&lt;/p>
&lt;p>修改 Canary 资源：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>flagger.app/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Canary&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">provider&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># deployment reference&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># ingress reference&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ingressRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>networking.k8s.io/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Ingress&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># HPA reference (optional)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">autoscalerRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>autoscaling/v2beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>HorizontalPodAutoscaler&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>podinfo&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># the maximum time in seconds for the canary deployment&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># to make progress before it is rollback (default 600s)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">progressDeadlineSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">60&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">service&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># ClusterIP port number&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># container port number or name&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">9898&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">analysis&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">interval&lt;/span>:&lt;span style="color:#666"> &lt;/span>1m&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">threshold&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">iterations&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">match&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># curl -H &amp;#39;X-Canary: insider&amp;#39; http://app.example.com&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">headers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">x-canary&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">exact&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;insider&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># curl -b &amp;#39;canary=always&amp;#39; http://app.example.com&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">headers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cookie&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">exact&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;canary&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metrics&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>request-success-rate&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">thresholdRange&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">min&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">99&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">interval&lt;/span>:&lt;span style="color:#666"> &lt;/span>1m&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">webhooks&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>load-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">url&lt;/span>:&lt;span style="color:#666"> &lt;/span>http://flagger-loadtester.test/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeout&lt;/span>:&lt;span style="color:#666"> &lt;/span>5s&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cmd&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;hey -z 1m -q 10 -c 2 -H &amp;#39;Cookie: canary=always&amp;#39; http://app.example.com/&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>从上面的配置可以看到，将 headers 为 &lt;code>X-Canary: insider&lt;/code> 或 cookie 为 &lt;code>canary=always&lt;/code> 的请求路由到新版本。&lt;/p>
&lt;p>部署一个新版本：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n &lt;span style="color:#24909d">test&lt;/span> &lt;span style="color:#24909d">set&lt;/span> image deployment/podinfo &lt;span style="color:#40ffff">podinfod&lt;/span>=stefanprodan/podinfo:3.1.3
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以收到 Slack 通知：&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1ggcorvilrrj20kb07wdgb.jpg" alt="A/B 测试 Slack 通知">&lt;/p>
&lt;p>正常访问，还是访问到老的 &lt;code>v3.1.1&lt;/code> 版：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl http://app.example.com
{
&lt;span style="color:#ed9d13">&amp;#34;hostname&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;podinfo-primary-5dc6b76bd5-8sbh8&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;version&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;3.1.1&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;revision&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;7b6f11780ab1ce8c7399da32ec6966215b8e43aa&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;color&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;#34577c&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;logo&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;https://raw.githubusercontent.com/stefanprodan/podinfo/gh-pages/cuddle_clap.gif&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;message&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;greetings from podinfo v3.1.1&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goos&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;linux&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goarch&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;amd64&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;runtime&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;go1.13.1&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_goroutine&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;11&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_cpu&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;6&amp;#34;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>请求添加指定 header，访问到新的 &lt;code>v3.1.3&lt;/code> 版：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -H &lt;span style="color:#ed9d13">&amp;#39;X-Canary: insider&amp;#39;&lt;/span> http://app.example.com
{
&lt;span style="color:#ed9d13">&amp;#34;hostname&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;podinfo-58bdd78d6f-m9bsc&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;version&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;3.1.3&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;revision&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;7b6f11780ab1ce8c7399da32ec6966215b8e43aa&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;color&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;#34577c&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;logo&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;https://raw.githubusercontent.com/stefanprodan/podinfo/gh-pages/cuddle_clap.gif&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;message&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;greetings from podinfo v3.1.3&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goos&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;linux&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goarch&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;amd64&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;runtime&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;go1.13.1&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_goroutine&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;10&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_cpu&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;6&amp;#34;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>请求添加指定 cookie，访问到新的 &lt;code>v3.1.3&lt;/code> 版：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -b &lt;span style="color:#ed9d13">&amp;#39;canary=always&amp;#39;&lt;/span> http://app.example.com
{
&lt;span style="color:#ed9d13">&amp;#34;hostname&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;podinfo-58bdd78d6f-m9bsc&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;version&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;3.1.3&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;revision&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;7b6f11780ab1ce8c7399da32ec6966215b8e43aa&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;color&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;#34577c&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;logo&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;https://raw.githubusercontent.com/stefanprodan/podinfo/gh-pages/cuddle_clap.gif&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;message&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;greetings from podinfo v3.1.3&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goos&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;linux&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;goarch&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;amd64&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;runtime&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;go1.13.1&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_goroutine&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;10&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;num_cpu&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;6&amp;#34;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在浏览器中访问也能得到相同的结果：&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1ggcoy65l47j20yb0dvq49.jpg" alt="添加 cookie 在浏览器中访问">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>最早了解 Flagger 其实是因为其与 Istio 的关系，Flagger 默认的 meshProvider 就是 Istio。但是在深入了解后，发现其对市面上常见的 Service Mesh 和 Ingress Controller 都有较好的支持，通过与 Prometheus 以及负载测试器的配合可以进行细粒度的分析，从而提高了发布质量，同时还降低了人工操作出错的可能性。&lt;/p>
&lt;p>最近 &lt;a href="https://oam.dev/">OAM 社区&lt;/a>也放出了基于 Flagger 的部署 Trait 的示例，相信之后与 OAM 结合使用可以在持续部署和应用管理领域发挥更大的作用。&lt;/p>
&lt;p>想了解 OAM 可以查看我之前的文章：&lt;a href="../start-oam">《以应用为中心：开放应用模型（OAM）初探》&lt;/a>。&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gfm3j2vo79g20b90b9x6r.gif" alt="">&lt;/p></description></item><item><title>Post: 以应用为中心：开放应用模型（OAM）初探</title><link>https://guoxudong.io/post/start-oam/</link><pubDate>Sun, 28 Jun 2020 14:53:23 +0800</pubDate><guid>https://guoxudong.io/post/start-oam/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>不久前，Kubernetes 也迎来了他 6 岁的生日，在这 6 年中，从孵化之初的三足鼎立，到后来的一统天下，Kubernetes 成为容器编排领域的事实标准已经有段时间了。在这期间，云原生的概念开始深入人心，越来越的公司组织和开发者开始接受、了解、实践云原生。如今，已有无数的应用以容器的形式运行在各种版本 Kubernetes 中了。&lt;/p>
&lt;h2 id="应用管理之惑">应用管理之惑&lt;/h2>
&lt;p>然而我们慢慢发现，随着应用和服务数量、使用场景以及承载业务的增加，Kubernetes 资源越来越难以管理。比如，有时候可能多个运维人员重复为一个 Deployment 配置了多个 Service 或 Ingress，而在一个 namespace 中动辄就有上百个 Service，在这些 Service 中找到那些重复、无效、甚至错误的 Service 可不是一件容易的事情。&lt;/p>
&lt;p>上面描述的只是运维人员内部可能存在的冲突，更多的冲突来自开发与运维人员之间，由于各自关注的角度不同，出现了对 Deployment 配置权的争夺，他们各自关心的字段不尽相同，但同时还要面对同一份 &lt;code>deployment.yaml&lt;/code>，这就是冲突的根源。我们的做法是使用 kustomize 将一份 &lt;code>deployment.yaml&lt;/code> 分成不同的 &lt;a href="https://kubernetes-sigs.github.io/kustomize/api-reference/glossary/#overlay">overlays&lt;/a>，将开发和运维关注的字段分开管理，而这只是缓兵之计，依旧没有一个统一的配置文件来描述整个应用，比如这个应用由几个 Deployment、Service、 Ingress 组成，一个新手如果想要查看一个资源相关的其他资源，只能通过 label 和“相似”的名称去找或者猜。而这样做显然是很危险的，这也是为什么我不敢轻易清理生产环境中无用的 Service 和 ConfigMap 的原因，你永远也想不到有什么地方可能引用了他们。&lt;/p>
&lt;p>相对标准 Kubernetes 资源，Operator 的管理难度就更大了，各式各样的 Operator 存在于我的 Kubernetes 集群中，&lt;code>kubectl get crd&lt;/code> 命令输出的结果更是长的可怕。&lt;/p>
&lt;p>而开放应用模型（OAM）可能是助我脱离苦海的一味良药。&lt;/p>
&lt;h2 id="开放应用模型oam">开放应用模型（OAM）&lt;/h2>
&lt;p>OAM 是阿里云与 Azure 在 2019 年末联合推出的标准化云原生应用管理模型。相比于传统 PaaS 封闭、不能同“以 Operator 为基础的云原生生态”衔接的现状，基于 OAM 和 Kubernetes 构建的现代云原生应用管理平台，本质上是一个 &lt;strong>“以应用为中心”&lt;/strong> 的 Kubernetes ，保证了这个应用平台在能够无缝接入整个云原生生态。同时，OAM 可以进一步屏蔽掉容器基础设施的复杂性和差异性，为平台的使用者带来低心智负担的、标准化的、一致的应用管理与交付体验。&lt;/p>
&lt;p>所谓 “应用模型”，其实是一个专门用来对云原生应用本身和它所需运维能力进行定义与描述的标准开源规范。所以对于 Kubernetes 来说，OAM 即是一个标准的“应用定义”项目（类比已经不再活跃的 Kubernetes Application CRD 项目），同时也是一个专注于封装、组织和管理 Kubernetes 中各种 “运维能力”、以及连接 “运维能力” 与 “应用” 的平台层项目。而通过 “定义应用” 和 “组织管理应用的运维能力” 这两大核心功能，我们可以构建一个更容易管理、维护和发展的云原生平台。&lt;/p>
&lt;p>以下是 OAM 的一些基本概念：&lt;/p>
&lt;h3 id="component">Component&lt;/h3>
&lt;p>在 OAM 中，&lt;strong>Component（组件）&lt;/strong> 就是一个完全面向业务研发人员设计的、用于定义应用程序而不必考虑其运维详细信息的载体。一个应用程序包含一个或多个 Component 。例如，一个网站应用可以由一个 Java web 组件和一个数据库组件组成。&lt;/p>
&lt;p>OAM 中的 Component 包含两个部分：&lt;/p>
&lt;ul>
&lt;li>工作负载描述 —— 如何运行此 Component，以及它的运行内容，实际上就是一个完整的 K8s CR；&lt;/li>
&lt;li>可重写参数列表 —— 研发通过这个字段表示该 Component 的哪些字段后续可以被运维或者系统覆盖。&lt;/li>
&lt;/ul>
&lt;h3 id="trait">Trait&lt;/h3>
&lt;p>在 OAM 中，我们通过 &lt;strong>Trait（运维特征）&lt;/strong> 来描述和构建具备可发现性和可管理性的平台层能力。&lt;/p>
&lt;p>Trait 是与 Component 绑定的，一个 Component 可以绑定多个 Trait，从而把运维能力也加入到应用描述中，方便底层基础设施统一管理。&lt;/p>
&lt;h3 id="application-configuration">Application Configuration&lt;/h3>
&lt;p>最终，通过引用 Component 名称并对它绑定 Trait ，运维人员就可以使用 &lt;strong>ApplicationConfiguration（应用配置）&lt;/strong> 来实例化应用程序。ApplicationConfiguration 的主要功能，就是让应用运维人员（或系统）了解和使用业务研发人员传达的信息，然后自由的为 Component 组合绑定不同的运维能力以相应实现其最终的运维目的。&lt;/p>
&lt;p>下面这张图很好的描述了 OAM 架构的使用场景，开发与运维的&lt;strong>关注点分离&lt;/strong>，而最终都由一份 &lt;code>ApplicationConfiguration&lt;/code> 来描述整个应用：&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65ly1gg82h3v1o1j20jg0bg77i.jpg" alt="image">&lt;/p>
&lt;h2 id="上手实践">上手实践&lt;/h2>
&lt;p>上面只是对 OAM 进行了简单的介绍，由于篇幅有限，如 Scope 这样的概念并没有进行介绍，更多内容欢迎加入 &lt;a href="https://oam.dev/">OAM 社区&lt;/a>。&lt;/p>
&lt;p>下面就以一个简单的示例，开启我们的 OAM 之旅：&lt;/p>
&lt;h3 id="前提条件">前提条件&lt;/h3>
&lt;p>本示例为官方示例，使用 OAM 部署一个 &lt;code>nginx&lt;/code> 应用，该应用包含 Deployment、Service 和 Ingress。&lt;/p>
&lt;ul>
&lt;li>Kubernetes 集群&lt;/li>
&lt;li>&lt;a href="https://helm.sh/docs/intro/">Helm 3&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="安装控制端">安装控制端&lt;/h3>
&lt;h4 id="安装-crossplane-和-oam">安装 Crossplane 和 OAM&lt;/h4>
&lt;p>注意，这里的 &lt;code>crossplane-oam-sample&lt;/code> 是官方维护的一个 crossplane 示例，只是用作开发和演示，并不是生产可用，关于 crossplane 的更多内容，请见&lt;a href="https://crossplane.io/">项目官网&lt;/a>。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helm repo add oam https://oam-dev.github.io/crossplane-oam-sample/archives/
$ kubectl create namespace oam-system
$ helm install crossplane --namespace oam-system oam/crossplane-oam
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里如果由于墙的原因无法拉取 &lt;code>gcr.io/kubebuilder/kube-rbac-proxy:v0.4.1&lt;/code> 镜像，导致 &lt;code>crossplane-oam-localstack&lt;/code> 无法启动的话，可以使用我提供的替代镜像 &lt;code>guoxudongdocker/kube-rbac-proxy:v0.4.1&lt;/code>。&lt;/p>
&lt;h4 id="拉取示例仓库">拉取示例仓库&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ git clone https://github.com/oam-dev/catalog.git
&lt;span style="color:#999;font-style:italic"># 进入示例&lt;/span>
$ &lt;span style="color:#24909d">cd&lt;/span> catalog/traits/ingresstrait
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="部署-crd-并启动-controller">部署 CRD 并启动 controller&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 部署 CRD&lt;/span>
$ make install
~/go/bin/controller-gen &lt;span style="color:#ed9d13">&amp;#34;crd:trivialVersions=true&amp;#34;&lt;/span> rbac:roleName=manager-role webhook &lt;span style="color:#40ffff">paths&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;./...&amp;#34;&lt;/span> output:crd:artifacts:config=config/crd/bases
kustomize build config/crd | kubectl apply -f -
customresourcedefinition.apiextensions.k8s.io/ingresstraits.core.oam.dev created
&lt;span style="color:#999;font-style:italic"># 启动 IngressTrait controller&lt;/span>
$ go run main.go
I0629 11:15:22.035708 &lt;span style="color:#3677a9">802&lt;/span> request.go:621] Throttling request took 1.000526734s, request: GET:https://192.168.4.210:6443/apis/apiregistration.k8s.io/v1?timeout=32s
2020-06-29T11:15:22.088+0800 INFO controller-runtime.metrics metrics server is starting to listen {&lt;span style="color:#ed9d13">&amp;#34;addr&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;:8080&amp;#34;&lt;/span>}
2020-06-29T11:15:22.089+0800 INFO setup starting manager
2020-06-29T11:15:22.089+0800 INFO controller-runtime.manager starting metrics server {&lt;span style="color:#ed9d13">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;/metrics&amp;#34;&lt;/span>}
2020-06-29T11:15:22.089+0800 INFO controller-runtime.controller Starting EventSource {&lt;span style="color:#ed9d13">&amp;#34;controller&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;ingresstrait&amp;#34;&lt;/span>, &lt;span style="color:#ed9d13">&amp;#34;source&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;kind source: /, Kind=&amp;#34;&lt;/span>}
2020-06-29T11:15:22.193+0800 INFO controller-runtime.controller Starting Controller {&lt;span style="color:#ed9d13">&amp;#34;controller&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;ingresstrait&amp;#34;&lt;/span>}
2020-06-29T11:15:22.193+0800 INFO controller-runtime.controller Starting workers {&lt;span style="color:#ed9d13">&amp;#34;controller&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;ingresstrait&amp;#34;&lt;/span>, &lt;span style="color:#ed9d13">&amp;#34;worker count&amp;#34;&lt;/span>: 1}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>由于这里只是简单演示，没有将 IngressTrait controller 打包成镜像，而是在本地运行 controller，所以需要 go 环境。&lt;/p>
&lt;h3 id="部署应用">部署应用&lt;/h3>
&lt;h4 id="配置-rbac">配置 RBAC&lt;/h4>
&lt;p>使用命令：&lt;code>kubectl apply -f rbac.yaml&lt;/code>，配置 RBAC。这里需要注意的是官方 IngressTrait 的 sample 示例中并没有 &lt;code>rbac.yaml&lt;/code>，需要我们自己配置，否则的话会在部署时由于权限原因无法拉起 Deployment。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>rbac.authorization.k8s.io/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ClusterRole&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>deployment-clusterrole-poc&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">rules&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">apiGroups&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- apps&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- deployments&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">verbs&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#ed9d13">&amp;#34;*&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>rbac.authorization.k8s.io/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ClusterRoleBinding&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>component-deployment-workload-poc&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">roleRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiGroup&lt;/span>:&lt;span style="color:#666"> &lt;/span>rbac.authorization.k8s.io&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ClusterRole&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>deployment-clusterrole-poc&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">subjects&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ServiceAccount&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>crossplane-oam &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Remember to use the actual ServiceAccount name&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>oam-system &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Remember to use the actual ServiceAccount namespace&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="部署-component">部署 Component&lt;/h4>
&lt;p>使用 &lt;code>kubectl apply -f sample_component.yaml &lt;/code> 命令部署 Component，该 Component 中的 workload 为 Deployment。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>core.oam.dev/v1alpha2&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Component&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>example-deploy&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">workload&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>web&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">template&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx:1.17&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>web&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="部署-applicationconfiguration">部署 ApplicationConfiguration&lt;/h4>
&lt;p>可以看到这个 ApplicationConfiguration 中包含一个 Component，而 Component 中又绑定了 一个 IngressTrait 类型的 Trait，由于这只是一个简单示例，所有只有一个 Component 和一个 Trait，在实际的生产环境中，一个 ApplicationConfiguration 可由多个 Component 组成，一个 Component 又可绑定多个 Trait 为其提供诸如流量管控、弹性伸缩等运维特性。&lt;/p>
&lt;p>使用命令：&lt;code>kubectl apply -f sample_application_config.yaml&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>core.oam.dev/v1alpha2&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ApplicationConfiguration&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>example-appconfig&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">components&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">componentName&lt;/span>:&lt;span style="color:#666"> &lt;/span>example-deploy&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">traits&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">trait&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>core.oam.dev/v1alpha2&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>IngressTrait&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>example-ingress-trait&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">rules&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">host&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx.oam.com&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">paths&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">backend&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#666"> &lt;/span>deploy-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">servicePort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">8080&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="检查结果">检查结果&lt;/h4>
&lt;p>可以看到 Deployment、Service 和 Ingress 已经部署成功：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get deploy,svc,ing
NAME READY UP-TO-DATE AVAILABLE AGE
deployment.apps/web 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 8m29s
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/deploy-test ClusterIP 10.43.170.228 &amp;lt;none&amp;gt; 8080/TCP 8m29s
NAME HOSTS ADDRESS PORTS AGE
ingress.extensions/example-ingress-trait nginx.oam.com 192.168.1.129,192.168.4.210 &lt;span style="color:#3677a9">80&lt;/span> 8m29s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>访问服务：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -H &lt;span style="color:#ed9d13">&amp;#34;Host: nginx.oam.com&amp;#34;&lt;/span> http://192.168.1.129
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&amp;lt;style&amp;gt;
body {
width: 35em;
margin: &lt;span style="color:#3677a9">0&lt;/span> auto;
font-family: Tahoma, Verdana, Arial, sans-serif;
}
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;For online documentation and support please refer to
&amp;lt;a &lt;span style="color:#40ffff">href&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;http://nginx.org/&amp;#34;&lt;/span>&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;
Commercial support is available at
&amp;lt;a &lt;span style="color:#40ffff">href&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;http://nginx.com/&amp;#34;&lt;/span>&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>应用的整体结构如下图所示：&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gg94rq5fyij20ef0drdgg.jpg" alt="OMA">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>通过上面这个简单的示例，可以看出如果遵循 OAM 模型来划分应用，我们可以从 ApplicationConfiguration 入手，看到应用中都包含哪些组件（Component），同时又可以看到每个组件都有哪些运维特性（Trait）来支持这个组件，逐层的查看每个模块的描述和配置，最终全面了解这个应用，而不用像现在这样使用 label 和 name，漫无目的的靠运气来理清整个架构，真正的做到&lt;strong>以应用为中心&lt;/strong>。&lt;/p>
&lt;p>OAM 的本质是将云原生应用定义中的研发、运维关注点分离，资源对象进行进一步抽象，化繁为简，包罗万象。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/rRaHl5a5PU9Xg5psMservA?from=timeline&amp;amp;isappinstalled=0&amp;amp;scene=2&amp;amp;clicktime=1588769747&amp;amp;enterid=1588769747">深度解读！阿里统一应用管理架构升级的教训与实践 - CSDN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/oam-dev/catalog">oam-dev/catalog - github.com&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Post: 可视化 Tekton 组件 Tekton Dashboard</title><link>https://guoxudong.io/post/tekton-dashboard/</link><pubDate>Wed, 13 May 2020 09:55:51 +0800</pubDate><guid>https://guoxudong.io/post/tekton-dashboard/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Tekton 作为一款开源的云原生 CI/CD 框架，前身是 Knative 的 build-pipeline 项目。作为 CI/CD 框架，其本身并不是一个 CI/CD 产品，所以不应拿 Tekton 与 Jenkins 或者 Drone 这样的 CI/CD 产品进行比较，Tekton 本质是一个强大而灵活的 CI/CD 框架，开发者可以基于它开发自己的 CI/CD 工具或产品，一些有能力的团队可以使用 Tekton 做为底座开发出更适合自己团队使用的 CI/CD 工具。&lt;/p>
&lt;p>而 Tekton 的可视化组件 Tekton Dashboard 则为用户提供了可视化界面，使 Tekton 的体验更接近与 Jenkins 这样的 CI/CD 产品，同时开发者可以在使用 Tekton Dashboard 时也会对 Tekton 的一些概念进行更深入的了解。&lt;/p>
&lt;p>本文将会使用 Tekton Dashboard，通过 UI 界面在 K8S 集群中部署一个 Java 项目：&lt;a href="https://github.com/sunny0826/pipeline-example-maven">pipeline-example-maven&lt;/a>&lt;/p>
&lt;h2 id="交互式学习">交互式学习&lt;/h2>
&lt;p>本文还提供 &lt;a href="https://katacoda.com">katacoda&lt;/a> 交互式学习版本，用户可以直接访问 katacoda 页面：https://katacoda.com/guoxudong/scenarios/tekton-dashboard ，使用 &lt;a href="https://katacoda.com">katacoda&lt;/a> 在浏览器端学习使用 Tekton Dashboard。&lt;/p>
&lt;p>该教程属于官方教程的汉化版，并得到了&lt;a href="https://github.com/ncskier/katacoda/issues/2">许可&lt;/a>。&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1geqt0wmbtvj21hb0q779v.jpg" alt="image">&lt;/p>
&lt;h2 id="tekton-dashboard">Tekton Dashboard&lt;/h2>
&lt;h3 id="安装">安装&lt;/h3>
&lt;p>这是所有步骤中最麻烦的一步，由于官方提供的 Tekton 镜像都在 &lt;code>gcr.io&lt;/code> 上，在国内并不能直接拉取，所以在测试的时候着实花费了不少时间。&lt;/p>
&lt;p>我特意将这些镜像转储到 dockerhub 上，如果官方版无法使用，可以使用克隆版：&lt;/p>
&lt;p>&lt;strong>安装 &lt;a href="https://github.com/tektoncd/pipeline/blob/master/docs/install.md">Tekton Pipelines&lt;/a>&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#999;font-style:italic"># 官方&lt;/span>
$ kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.10.1/release.yaml
&lt;span style="color:#999;font-style:italic"># 克隆版&lt;/span>
$ kubectl apply -f https://raw.githubusercontent.com/sunny0826/tekton-local/v0.10.1/tekton-pipeline.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>安装 &lt;a href="https://github.com/tektoncd/dashboard#install-dashboard">Tekton Dashboard&lt;/a>&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#999;font-style:italic"># 官方&lt;/span>
$ kubectl apply --filename https://storage.googleapis.com/tekton-releases/dashboard/previous/v0.5.3/tekton-dashboard-release.yaml
&lt;span style="color:#999;font-style:italic"># 克隆版&lt;/span>
$ kubectl apply -f https://raw.githubusercontent.com/sunny0826/tekton-local/v0.10.1/tekton-dashboard.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装成功之后需要配置 Tekton Dashboard 的访问地址，可以使用 ingress 或 Nodeport 暴露端口，这里采用 &lt;code>port-forward&lt;/code> 的形式将端口映射到本地：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl port-forward svc/tekton-dashboard 8097:9097 -n tekton-pipelines
Forwarding from 127.0.0.1:8097 -&amp;gt; &lt;span style="color:#3677a9">9097&lt;/span>
Forwarding from [::1]:8097 -&amp;gt; &lt;span style="color:#3677a9">9097&lt;/span>
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>访问 Tekton Dashboard&lt;/strong>&lt;/p>
&lt;p>打开浏览器访问访问 http://localhost:8097&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1geqnhem9i9j21mk0tu425.jpg" alt="">&lt;/p>
&lt;h3 id="导入资源">导入资源&lt;/h3>
&lt;p>点击 &lt;code>Import Tekton resources&lt;/code> 进入资源导入页面，导入资源：&lt;/p>
&lt;ul>
&lt;li>Repository URL: &lt;code>https://github.com/sunny0826/pipeline-example-maven&lt;/code>&lt;/li>
&lt;li>Namespace: &lt;code>default&lt;/code>&lt;/li>
&lt;li>Repository directory: &lt;code>tekton/&lt;/code>&lt;/li>
&lt;li>Service Account &lt;code>tekton-dashboard&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>输入内容如下：&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1geqnp36mk0j20yu0memze.jpg" alt="image">&lt;/p>
&lt;p>点击 &lt;code>Import and Apply&lt;/code> 按钮，之后 Dashboard 会创建一个 PipelineRun 来导入指定的 Tekton 资源。&lt;/p>
&lt;p>点击页面底部的 &lt;code>View status of this run&lt;/code> 链接，查看 MyApp 导入 Tekton 资源的状态。&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1geqnqyx5g2j20a403et8q.jpg" alt="">&lt;/p>
&lt;p>PipelineRun 完成后，Tekton 资源已导入成功。&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1geqns0gqi8j21go0ozwhl.jpg" alt="image">&lt;/p>
&lt;h3 id="创建-pipelineresource">创建 PipelineResource&lt;/h3>
&lt;p>选择 &lt;code>default&lt;/code> 命名空间，并点击 &lt;code>PipelineResource&lt;/code> 按钮。&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1geqnukrb3aj20yb0enmyg.jpg" alt="">&lt;/p>
&lt;p>点击页面右上方的 &lt;code>Create +&lt;/code> 按钮，将弹出一个创建 PipelineResource 的表单。&lt;/p>
&lt;p>我们要在 &lt;code>default&lt;/code> 命名空间中为 pipeline-example-maven 的 &lt;code>master&lt;/code> 分支创建一个 git PipelineResource，故在弹出的表单中填写以下信息：&lt;/p>
&lt;ul>
&lt;li>Name: &lt;code>pipeline-example-maven&lt;/code>&lt;/li>
&lt;li>Namespace: &lt;code>default&lt;/code>&lt;/li>
&lt;li>Type: &lt;code>Git&lt;/code>&lt;/li>
&lt;li>URL: &lt;code>https://github.com/sunny0826/pipeline-example-maven&lt;/code>&lt;/li>
&lt;li>Revision: &lt;code>master&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>该表单内容应如下：&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1geqnxalh2pj20pl0dbq3h.jpg" alt="image">&lt;/p>
&lt;p>点击 &lt;code>Create&lt;/code> 按钮，创建 PipelineResource。&lt;/p>
&lt;h3 id="创建-pipelinerun">创建 PipelineRun&lt;/h3>
&lt;p>选择 &lt;code>default&lt;/code> 命名空间，并点击 &lt;code>PipelineRuns&lt;/code> 按钮。&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1geqo2iatnhj20yb0ewjso.jpg" alt="">&lt;/p>
&lt;p>点击页面右上方的 &lt;code>Create +&lt;/code> 按钮，将弹出一个创建 PipelineRun 的表单。该表单是动态的，会根据所选的 Pipeline 提供 PipelineResource 和 Param 字段。&lt;/p>
&lt;p>我们需要 &lt;code>default&lt;/code> 命名空间中使用 &lt;code>pipeline-example-maven&lt;/code> 的 Pipeline 和 PipelineResource，创建一个 PipelineRun，故在弹出的表单中填写以下信息：&lt;/p>
&lt;ul>
&lt;li>Namespace: &lt;code>default&lt;/code>&lt;/li>
&lt;li>Pipeline: &lt;code>pipeline-example-maven&lt;/code>&lt;/li>
&lt;li>PipelineResources source: &lt;code>pipeline-example-maven&lt;/code>&lt;/li>
&lt;li>其余字段保留默认值。&lt;/li>
&lt;/ul>
&lt;p>该表单内容应如下：&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1geqrdvoaquj20pi0lzt9o.jpg" alt="image">&lt;/p>
&lt;p>点击 &lt;code>Create&lt;/code> 按钮，创建 PipelineRun。&lt;/p>
&lt;h3 id="查看-pipelinerun-日志">查看 PipelineRun 日志&lt;/h3>
&lt;p>点击页面顶部创建通知中的链接或在 PipelineRun 列表中对应的 PipelineRun，查看 pipeline-example-maven PipelineRun 的日志。&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1geqrhrwspcj217x0i7425.jpg" alt="image">&lt;/p>
&lt;blockquote>
&lt;p>deploy 步骤中，有时会出现权限错误，需要给 default:default 绑定上 admin 的 clusterrole 权限：&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl create rolebinding default-admin --clusterrole=admin --serviceaccount=default:default
&lt;/code>&lt;/pre>&lt;/div>&lt;p>确认 &lt;code>build&lt;/code> 和 &lt;code>deploy&lt;/code> 任务均已成功。&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1geqrmy2mc9j218w0jo0uj.jpg" alt="image">&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;strong>注意&lt;/strong>：这里为了方便，使用的是单节点的 Kubernetes，构建完并没有推送到镜像仓库，镜像拉取策略为 &lt;code>imagePullPolicy: Never&lt;/code> ，所以启动时候也没有从远程仓库拉取镜像，而是启动的本地镜像。
&lt;/div>
&lt;h3 id="查看构建结果">查看构建结果&lt;/h3>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">$ kubectl get deploy
NAME READY UP-TO-DATE AVAILABLE AGE
example-greenhouse 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 5h2m
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Tekton Dashboard 将 Tekton 的资源进行了可视化展示，指导用户快速理解 Tekton pipeline 流程以及配置方式，快速上手 Tekton。但是由于镜像的原因，导致新手体验不佳，所幸官方还提供了 &lt;a href="https://katacoda.com">katacoda&lt;/a> 交互式教程，该教程我已汉化完成并获得了官方的许可，可以在浏览器端快速体验从安装 Tekton 到部署应用的整个过程。&lt;/p></description></item><item><title>Post: 告别手写 Helm Chart README</title><link>https://guoxudong.io/post/helm-docs/</link><pubDate>Fri, 08 May 2020 11:20:01 +0800</pubDate><guid>https://guoxudong.io/post/helm-docs/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>随着云原生应用的普及，Helm 的作用也日益凸显，越来越多的云原生应用以 Helm Chart 的形式发布，可以说现在如果没有一个 Helm Chart 都不好意思说自己是云原生应用。&lt;/p>
&lt;p>一个好的应用必定有一套好的文档，文档的质量往往和代码的质量成正比。而 Helm Chart 中的 &lt;code>README.md&lt;/code> 文件就承担了文档的作用，该文件会介绍这个 Helm Chart 的基本信息、使用方式以及参数配置等，用户可以通过该文档的指引，配置符合自己需求的参数，最终完成云原生应用的部署。&lt;/p>
&lt;p>但这也给云原生应用的开发者提出了挑战，开发者不但需要把 &lt;code>value.yaml&lt;/code> 和 &lt;code>Chart.yaml&lt;/code> 等文件的参数以 Markdown 的形式搬运到 &lt;code>README.md&lt;/code> 文件中，同时还要将参数的默认值，以及介绍填入表格中。但如果参数出现了变动，往往无法及时更新文档。这就导致了用户明明根据文档配置了参数，但是部署的效果就是无法达到预期。&lt;/p>
&lt;h2 id="helm-docs">Helm-docs&lt;/h2>
&lt;p>helm-docs 可以根据 charts 内容自动生成 markdown 文件。该文件会包含有关 charts 的元数据，以及 &lt;code>value.yaml&lt;/code> 中的参数，同时还可以引用子模板（默认为 &lt;code>README.md.gotmpl&lt;/code>），进一步定制生成的内容。&lt;/p>
&lt;h3 id="安装">安装&lt;/h3>
&lt;p>&lt;a href="https://github.com/norwoodj/helm-docs">helm-docs&lt;/a> 使用 golang 开发，支持多平台：&lt;/p>
&lt;p>&lt;strong>MacOS&lt;/strong>&lt;/p>
&lt;p>可以使用 homebrew 安装：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">brew install norwoodj/tap/helm-docs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>下载可执行文件&lt;/strong>&lt;/p>
&lt;p>到 &lt;a href="https://github.com/norwoodj/helm-docs/releases">release&lt;/a> 页面下载对应平台的可执行文件。&lt;/p>
&lt;h3 id="快速开始">快速开始&lt;/h3>
&lt;p>&lt;strong>直接使用可执行文件&lt;/strong>&lt;/p>
&lt;p>使用方法也很简单，直接进入到 Chart 所在目录，执行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm-docs
&lt;span style="color:#999;font-style:italic"># 或者&lt;/span>
helm-docs --dry-run &lt;span style="color:#999;font-style:italic"># 不生成 README.md 文件，而是将生成的内容打印到控制台&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>使用 docker&lt;/strong>&lt;/p>
&lt;p>如果不想安装可执行文件，也可以使用 docker，将 Chart 目录挂载到 docker 镜像中，实现相同的效果：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker run -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>&lt;span style="color:#24909d">pwd&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span>&lt;span style="color:#ed9d13">:/helm-docs&amp;#34;&lt;/span> jnorwood/helm-docs:latest
&lt;span style="color:#999;font-style:italic"># 或者&lt;/span>
docker run -v &lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>&lt;span style="color:#24909d">pwd&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span>&lt;span style="color:#ed9d13">:/helm-docs&amp;#34;&lt;/span> jnorwood/helm-docs:latest --dry-run
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="进阶实践">进阶实践&lt;/h3>
&lt;p>下面就以我的开源项目 &lt;a href="https://github.com/sunny0826/cms-grafana-builder">cms-grafana-builder&lt;/a> 为例，讲解 helm-docs 的一些进阶使用。&lt;/p>
&lt;p>&lt;strong>添加参数说明&lt;/strong>&lt;/p>
&lt;p>helm-docs 可以通过 &lt;code>value.yaml&lt;/code> 中的注释生成参数说明，注释格式如下所示，&lt;code>--&lt;/code> 后的内容会自动填充到 Chart Values 的 Description 中：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># access_key_id -- Aliyun Access Key Id.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">access_key_id&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># access_secret -- Aliyun Access Secret.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">access_secret&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># region_id -- Aliyun Region Id.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">region_id&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;cn-shanghai&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># password -- Grafana admin password.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">password&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;admin&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># image.repository -- Image source repository name.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">repository&lt;/span>:&lt;span style="color:#666"> &lt;/span>grafana/grafana&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># image.pullPolicy -- Image pull policy.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">pullPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>IfNotPresent&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>自定义模板&lt;/strong>&lt;/p>
&lt;p>可以新建 &lt;code>README.md.gotmpl&lt;/code> 模板来进一步定制 &lt;code>README.md&lt;/code> 的输出样式。&lt;/p>
&lt;p>&lt;code>README.md.gotmpl&lt;/code> 文件的内容如下，可以在模板中插入 Markdown 来充实 &lt;code>README.md&lt;/code> 的内容，以及改变展示内容的顺序：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-golang" data-lang="golang">{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.header&amp;#34;&lt;/span> . }}
{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.description&amp;#34;&lt;/span> . }}
{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.versionLine&amp;#34;&lt;/span> . }}
{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.sourceLinkLine&amp;#34;&lt;/span> . }}
&lt;span style="color:#a61717;background-color:#e3d2d2">##&lt;/span> Introduction
This chart helps you run a grafana server that include aliyun cms dashboard.
{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.requirementsSection&amp;#34;&lt;/span> . }}
{{ template &lt;span style="color:#ed9d13">&amp;#34;chart.valuesSection&amp;#34;&lt;/span> . }}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>更多内容和示例，详见 &lt;a href="https://github.com/norwoodj/helm-docs">https://github.com/norwoodj/helm-docs&lt;/a>&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>helm-docs 可以帮助很多像我这样需要维护多个 Helm Chart 的开发者，在更新完或新建 Chart 以后，使用 &lt;code>helm-docs&lt;/code> 来自动生成 &lt;code>README.md&lt;/code> 文件，无需逐个寻找和修改，甚至将其集成到 CI 流水线中，自动生成最新的 &lt;code>README.md&lt;/code>，保证文档和代码的一致。&lt;/p></description></item><item><title>Post: 去指挥你的舰队吧！体验使用 Fleet 批量管理 K8S 集群</title><link>https://guoxudong.io/post/rancher-fleet/</link><pubDate>Thu, 23 Apr 2020 14:03:53 +0800</pubDate><guid>https://guoxudong.io/post/rancher-fleet/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
2020年4月3日，Rancher Labs 宣布推出全新开源项目 Fleet，致力于为用户提供海量 Kubernetes 集群的集中管理体验。
&lt;/div>
&lt;p>最早听说到这个消息时，我还是很疑惑的，Fleet 不是 CoreOS 早已经停止维护的一个项目吗？怎么又和 Rancher Labs 扯上了关系？&lt;/p>
&lt;p>**“为用户提供海量 Kubernetes 集群的集中管理体验”**这句话是否言过其实：&lt;/p>
&lt;ul>
&lt;li>“海量”这个量到底有多大？&lt;/li>
&lt;li>又有多少公司或团队有管理海量的 Kubernetes 集群的需求？&lt;/li>
&lt;li>又是怎么一个&lt;strong>集中管理&lt;/strong>法？&lt;/li>
&lt;/ul>
&lt;p>带着这些疑问，我仔细了解了一下 Fleet 这个开源项目。&lt;/p>
&lt;h2 id="fleet">Fleet&lt;/h2>
&lt;p>首先，这里的 Fleet 是一个新项目，起这个名字应该算是一种致敬，经过了解后我个人觉得这个名字起的还是挺贴切的，比一大波 KubeXXX 有创意多了。&lt;/p>
&lt;blockquote>
&lt;p>“我一直是它的忠实粉丝，将这一项目命名为 Fleet 也包含了我的私心。”Darren Shepherd 解释道：“所以我希望重新使用 Fleet 这一名字，这是对这个非常出色的容器领域早期项目的致敬。同时，对于推动 Kubernetes 集群管理的演进，我们感到十分兴奋及万分期待。”&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&amp;mdash; 摘自 RancherLabs 官方微信公众号《Rancher开源Fleet：业界首个海量K8S集群管理项目》&lt;/p>
&lt;/blockquote>
&lt;p>顾名思义 Fleet 是“舰队”的意思，而 Kubernetes 在希腊语意为 “舵手”。从名称上看，Fleet 的目标就是管理或是指挥众多 Kubernetes 集群。而在了解这个项目时，我发现了这个项目和 Rancher Labs 另一个受欢迎项目 &lt;a href="https://k3s.io/">k3s&lt;/a> 有个千丝万缕的联系，甚至在我看来 Fleet 可能就是就是为了管理众多 k3s 集群而生的，是 Rancher Labs 布局边缘计算和 IoT 领域的重要组成部分。&lt;/p>
&lt;p>k3s 是一款轻量级的 Kubernetes 集群，主要面向边缘计算和 IOT 领域，相比原生 Kubernetes，k3s 体量更轻、部署简单且快速，同时还具有完整的 Kubernetes 体验。可以说只要是 Linux 系统（配合周边工具甚至可以运行在 Mac 和 Windows 系统），无论是树莓派、各种开发板还是 PC 机，都可以独立运行起 k3s，&lt;strong>这也为运行海量 Kubernetes 集群&lt;/strong>提供了可能。以汽车为例，我们可以为每一辆汽车都部署一个 k3s 集群，所有汽车相关的软件（导航、广播甚至是无人驾驶程序）都部署在 k3s 集群中，每次这些软件发布新版本，只需使用 Fleet 进行批量操作该种车型的所有 k3s 集群即可，无需将车开回 4S 店进行手动更新。&lt;/p>
&lt;div class="alert alert-primary" role="alert">
联系美国空军是 Kubernetes 与 Istio 项目的重要用户，这种实践可能早就开始了。
&lt;/div>
&lt;p>解释了海量 Kubernetes 集群的疑问，下面就从 Fleet 的架构入手，讲讲如何&lt;strong>集中管理&lt;/strong>。&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65ly1ge3o40xe41j20qx0ljdm7.jpg" alt="">&lt;/p>
&lt;p>Fleet 包含&lt;code>Manager&lt;/code>和&lt;code>agent&lt;/code>，&lt;code>Manager&lt;/code>所在集群作为控制平面管理所有&lt;code>agent&lt;/code>集群，同时 Fleet 根据 Kubernetes 部署 Pod 的模型，定义了一个 Bundles 对象，并且提供了一种内置机制，可以使用诸如&lt;code>Helm&lt;/code>和&lt;code>Kustomize&lt;/code>等行业标准工具为每个目标集群定制 Bundles，在我看来这种模式以及&lt;code>bundle.yaml&lt;/code>的写法都和&lt;code>Kustomize&lt;/code>很像(套娃行为？)&amp;hellip;一旦用户在集群之间部署了 Bundles，Fleet 就会主动监视资源是否已就绪，以及是否被更改过。总的来说就是通过部署 Bundles，就可以将部署内容批量分发到所有目标集群，从而达到&lt;strong>集中管理&lt;/strong>的目的。&lt;/p>
&lt;h2 id="尝鲜体验">尝鲜体验&lt;/h2>
&lt;p>说那么多其实意义不大，好不好用，只有试过才知道。这里使用的 Fleet 版本为&lt;code>v0.2.0&lt;/code>，是目前的最新版本。&lt;/p>
&lt;p>&lt;strong>下载 CLI 工具&lt;/strong>&lt;/p>
&lt;p>首先需要下载&lt;code>fleet&lt;/code>的 CLI 工具，这里的体验和 k3s 类似，都是直接&lt;code>curl&lt;/code> GitHub 上的安装脚本并执行：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -sfL https://raw.githubusercontent.com/rancher/fleet/master/install.sh | sh -
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>部署控制平面&lt;/strong>&lt;/p>
&lt;p>使用 CLI 工具将&lt;code>Fleet Manager&lt;/code>部署到 Kubernetes 集群上：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># Kubeconfig should point to Manager cluster&lt;/span>
$ fleet install manager | kubectl apply -f -
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>生成 Cluster group token&lt;/strong>&lt;/p>
&lt;p>到这控制平面就部署好了，接下来部署&lt;code>agent&lt;/code>目标集群。这里生成的其实是一个 yaml 文件，内容包含 fleet 需要的 RBAC 权限和 fleet-agent 的 Deployment：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># Kubeconfig should point to Manager cluster&lt;/span>
$ fleet install agent-token &amp;gt; token
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>目标集群注册&lt;/strong>&lt;/p>
&lt;p>将需要纳管的目标集群加入到 fleet 中，&lt;strong>注意&lt;/strong>：这里需要将 kubeconfig 切换到目标集群，也就是需要部署&lt;code>agent&lt;/code>的集，每个需要注册的集群都要部署&lt;code>agent&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># Kubeconfig should point to AGENT cluster&lt;/span>
$ kubectl apply -f token
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>部署 bundles&lt;/strong>&lt;/p>
&lt;p>这里就是向多个集群同时部署 bundles，使用方法也和&lt;code>Kustomize&lt;/code>类似（&lt;code>example&lt;/code> 目录是 fleet 官方仓库中的示例目录）：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># Kubeconfig should point to Manager cluster&lt;/span>
$ fleet apply ./examples/helm-kustomize
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>查看状态&lt;/strong>&lt;/p>
&lt;p>现在就可以查看所有集群 bundles 的状态了，这里可以看到 bundles 在多个集群都部署成功了（这里是我起的两个 k3s 集群做的测试）：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get fleet
NAME CLUSTER-COUNT BUNDLES-READY BUNDLES-DESIRED STATUS
clustergroup.fleet.cattle.io/default &lt;span style="color:#3677a9">2&lt;/span> &lt;span style="color:#3677a9">3&lt;/span> &lt;span style="color:#3677a9">4&lt;/span> Modified: &lt;span style="color:#3677a9">1&lt;/span> (helm-kustomize )
NAME CLUSTERS-READY CLUSTERS-DESIRED STATUS
bundle.fleet.cattle.io/fleet-agent &lt;span style="color:#3677a9">2&lt;/span> &lt;span style="color:#3677a9">2&lt;/span>
bundle.fleet.cattle.io/helm-kustomize &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">2&lt;/span> Modified: &lt;span style="color:#3677a9">1&lt;/span> (default-default-group/cluster-5a186072-acbd-4f54-8f22-fb1651ce902f )
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="总结">总结&lt;/h2>
&lt;p>总的来说，Fleet 的架构简洁且十分轻量，部署方式简单，使用&lt;code>YAML&lt;/code>、&lt;code>Helm&lt;/code>、&lt;code>Kustomez&lt;/code>都可以进行资源的描述和配置，甚至可以使用&lt;code>Helm&lt;/code>+&lt;code>Kustomeze&lt;/code>的模式，部署体验不错。&lt;/p>
&lt;p>但遗憾的是，目前 Fleet 还处于项目早期，实践也仅限于尝鲜体验，并不能用于生产环境，项目 README 中还专门提到了&lt;strong>目前 Fleet 仅适用于 10 个集群以下的小规模部署&lt;/strong>。目前文档不足且项目维护人员并不积极，文档勘误的 &lt;a href="https://github.com/rancher/fleet/pull/32">RP&lt;/a> 和相关 ISSUE 也没有得到相关的反馈。项目是做到了业界首个，但是要真正生产可用甚至做到业界第一还有很长的一段路要走。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/rancher/fleet">Fleet - Github&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/byErGqVBtm4kdv58OZFt_w">Rancher开源Fleet：业界首个海量K8S集群管理项目 - RancherLabs&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Post: Katacoda：免费学习 Kubernetes 利器</title><link>https://guoxudong.io/post/katacoda-k8s/</link><pubDate>Fri, 27 Mar 2020 15:57:11 +0800</pubDate><guid>https://guoxudong.io/post/katacoda-k8s/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近 ServiceMesher 社区重启了&lt;a href="https://github.com/servicemesher/istio-handbook">《Istio 服务网格进阶实战》&lt;/a> 的编写，我也作为编委会成员参与其中。该书的实践项目都基于 Istio 1.5 版本以及 Katacoda 提供的 Kubernetes 环境完成。由于实践部分都要使用 Katacoda，介绍 Katacoda 这章需要先完成，为其他参与编写实践篇的作者提供参考。&lt;/p>
&lt;h2 id="katacoda">Katacoda&lt;/h2>
&lt;p>Katacoda 是一个面向软件工程师的交互式学习和培训平台，可在浏览器中使用真实环境学习和测试新技术，帮助开发人员学习，并掌握最佳实践。该平台于 2019 年 11 月被 O&amp;rsquo;Reilly 收购。&lt;/p>
&lt;p>Katacoda 可以快速的提供一套完整的临时环境，并在使用后将其回收。用户可以根据设计好的引导步骤，通过浏览器上的终端界面操作一套完整的环境，一步步的学习和实践。尤其是在学习 Kubernetes 这种复杂的应用时，单单是创建一个集群就要花去不少时间，同时消耗的资源也令一些初学者望而生畏，Katacoda 的出现很好的解决了这些问题。课程设计者可以定制应用程序所需环境，并设计循序渐进的指导路径，旨在确保用户以最佳方式学习。&lt;/p>
&lt;p>在 Katacoda 每个用户都可以免费的学习和创建课程，其中：&lt;/p>
&lt;ul>
&lt;li>Course：课程，可包含一系列的 scenarios。
&lt;ul>
&lt;li>官方教程入口：&lt;a href="https://katacoda.com/scenario-examples/scenarios/create-course">https://katacoda.com/scenario-examples/scenarios/create-course&lt;/a>&lt;/li>
&lt;li>汉化教程入口：&lt;a href="https://katacoda.com/guoxudong/courses/katacoda-example/create-course">https://katacoda.com/guoxudong/courses/katacoda-example/create-course&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Scenarios：场景、方案。
&lt;ul>
&lt;li>官方教程入口：&lt;a href="https://katacoda.com/scenario-examples/scenarios/create-scenario-101">https://katacoda.com/scenario-examples/scenarios/create-scenario-101&lt;/a>&lt;/li>
&lt;li>汉化教程入口：&lt;a href="https://katacoda.com/guoxudong/courses/katacoda-example/katacoda-create-scenarios">https://katacoda.com/guoxudong/courses/katacoda-example/katacoda-create-scenarios&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="使用-katacoda-学习">使用 Katacoda 学习&lt;/h2>
&lt;p>Katacoda 提供了非常便利的学习方式，用户只需要打开相应课程，就可以跟着课程设计者的说明，按照设计好的步骤一步步完成学习。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>介绍会标明课程的难度和需要的时间，帮助用户了解该课程的基本信息：
&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gd8k9b4jwoj21ha0q7wha.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>进入课程，左侧是该步骤说明，右侧是一个已经准备好的终端，直接可以使用：
&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1gd8kdmfr3ej21h90qeq8s.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>之后就是跟着步骤说明，一步步的完成学习即可：
&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gd8kh1jcs1j21hb0q5do7.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="创建课程">创建课程&lt;/h2>
&lt;p>既然可以学习别人设计好的课程，那么也可以自己设计课程，以供用户学习。&lt;/p>
&lt;h3 id="新建仓库">新建仓库&lt;/h3>
&lt;p>Katacoda 需要注册账号登录，这里直接使用 GitHub 账号登录即可，毕竟之后创建的方案都是存放在 GitHub 上的。&lt;/p>
&lt;p>这里推荐在页面新建仓库，访问 &lt;a href="https://www.katacoda.com/teach/git-hosted-scenarios">https://www.katacoda.com/teach/git-hosted-scenarios&lt;/a> ，点击 &lt;code>Automatically Create and Configure Github Repository&lt;/code> 按钮，Katacoda 会自动在您的 Github 中创建一个名为 &lt;code>katacoda-scenarios&lt;/code> 的仓库，并自动为您配置 Webhook，每次更新该仓库时，都会自动更新您 Katacoda 中课程的内容。&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1gd73rov21ij219q0pl42u.jpg" alt="katacoda 新建仓库页面">&lt;/p>
&lt;p>创建完成后，就可以在您的 Github 上找到名为 &lt;code>katacoda-scenarios&lt;/code> 的代码仓库。&lt;/p>
&lt;h3 id="scenarios">Scenarios&lt;/h3>
&lt;p>Scenarios 即为方案、场景，由一组 Markdown、bash 脚本和一个 JSON 文件组成，这些文件保存了该 Scenarios 的所有配置。&lt;/p>
&lt;p>Katacoda 官方提供了 CLI 工具，帮助您创建 Scenarios。&lt;/p>
&lt;h4 id="安装-cli">安装 CLI&lt;/h4>
&lt;p>通过 npm 命令安装 &lt;code>npm i katacoda-cli --global&lt;/code>。&lt;/p>
&lt;p>命令遵循语法的是 &lt;code>$ katacoda COMMAND&lt;/code>&lt;/p>
&lt;p>安装完成后，可以通过运行命令 &lt;code>katacoda --help&lt;/code> 查看帮助信息。&lt;/p>
&lt;h4 id="创建-scenarios-目录">创建 Scenarios 目录&lt;/h4>
&lt;p>例如，要创建新的方案，可以通过运行命令 &lt;code>katacoda scenarios:create&lt;/code>，CLI 将会提示一些信息，帮助您创建方案：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Friendly URL:&lt;/strong> 此处可输入 &lt;code>test-scenario&lt;/code>，该属性将确定 scenarios 文件夹的名称，以及用来访问他的 URL。因此，该属性不能包括空格，需要是小写字母等。例如，如果您的用户名是 test-username 并且您的方案称为 test-scenario（如建议的那样），用于在平台中指向该方案的URL将为 &lt;a href="https://katacoda.com/test-username/scenarios/test-scenario/">https://katacoda.com/test-username/scenarios/test-scenario/&lt;/a>&lt;/li>
&lt;li>&lt;strong>Title:&lt;/strong> 方案的标题，将会显示在简介上&lt;/li>
&lt;li>&lt;strong>Description:&lt;/strong> 方案的描述，将会显示在简介上&lt;/li>
&lt;li>&lt;strong>Difficulty level:&lt;/strong> 难度级别，将会显示在简介上&lt;/li>
&lt;li>&lt;strong>Estimated time:&lt;/strong> 估计完成的时间，将会显示在简介上&lt;/li>
&lt;li>&lt;strong>Number of steps:&lt;/strong> 方案的步骤数。CLI 将会为您的所有步骤创建文件&lt;/li>
&lt;li>&lt;strong>Image:&lt;/strong> 确定适用于您的方案的基本软件。例如，如果您需要 docker，java，go 等作为前提条件。更多相关信息，请阅读 &lt;a href="https://katacoda.com/docs/scenarios/environments">https://katacoda.com/docs/scenarios/environments&lt;/a>&lt;/li>
&lt;li>&lt;strong>Layout:&lt;/strong> 它将确定方案界面元素的配置。例如，如果您只想显示终端，或编辑器+终端等形式，更多相关信息，请阅读 &lt;a href="https://katacoda.com/docs/scenarios/layouts">https://katacoda.com/docs/scenarios/layouts&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>输入这些信息，CLI 将帮您创建一个文件夹，其中引入了 &lt;em>&lt;strong>friendly URL&lt;/strong>&lt;/em> 的名称，并将在该文件夹内创建方案所需的文件。&lt;/p>
&lt;h4 id="编辑-scenarios">编辑 Scenarios&lt;/h4>
&lt;p>Scenarios 目录创建好之后，可以看到目录的结构：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">.
├── finish.md
├── index.json
├── intro.md
├── step1.md
├── step2.md
├── step3.md
├── step4.md
└── step5.md
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>index.json&lt;/code> ：文件中定义了标题、描述、步骤顺序、UI 布局以及所需环境，内容与您使用 CLI 工具创建时输入的是一致的，如果想对输入的内容进行修改，也可以在这里修改&lt;/li>
&lt;li>&lt;code>intro.md&lt;/code>：介绍页，用来介绍您这个 Scenarios&lt;/li>
&lt;li>&lt;code>finish.md&lt;/code> ：结束页&lt;/li>
&lt;li>&lt;code>step1-setpN.md&lt;/code>：步骤介绍，数目与您使用 CLI 工具创建 Scenarios 时输入的数目相同&lt;/li>
&lt;/ul>
&lt;h3 id="上传">上传&lt;/h3>
&lt;p>将创建的 Scenarios 移动到之前创建的 git 项目中。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ git add .
$ git commit -m &lt;span style="color:#ed9d13">&amp;#34;New Scenarios&amp;#34;&lt;/span>
$ git push origin master
&lt;/code>&lt;/pre>&lt;/div>&lt;p>上传成功后，在 &lt;strong>Your Profile&lt;/strong> 页面就可以看到您上传的课程。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Katacoda 是一个面向软件工程师的交互式学习和培训平台，开发人员根据产品特色设计学习流程，方便用户的学习；学习者则无需关心环境的搭建与依赖的安装，通过开发人员设计的最佳实践来进行学习，快速又高效。&lt;strong>最重要的是，它是免费的！白嫖的东西又有谁不喜欢呢？&lt;/strong>&lt;/p>
&lt;p>同时也欢迎各位朋友一起参与到&lt;a href="https://github.com/servicemesher/istio-handbook">《Istio 服务网格进阶实战》&lt;/a> 的编撰中，和 ServiceMesher 社区的朋友一起完成这部开源书籍。&lt;/p></description></item><item><title>Post: Kt Connect：研发侧利器，本地连通 Kubernetes 集群内网</title><link>https://guoxudong.io/post/alibaba-kt-connect/</link><pubDate>Tue, 24 Mar 2020 09:14:06 +0800</pubDate><guid>https://guoxudong.io/post/alibaba-kt-connect/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>随着 Kubernetes 的普及，越来越多的应用被容器化，并部署到 Kubernetes 上。随之而来的问题是当容器中发生错误时，对错误的定位和调试也变得很复杂。当一个工具给你带来便利时，它也可能给你带来另一些麻烦。&lt;/p>
&lt;p>那么有没有工具可以在本地联通 Kubernetes 集群并进行调试呢？当然是有的，这里就介绍一款研发侧利器：&lt;code>Kt Connect&lt;/code>&lt;/p>
&lt;h2 id="kt-connect">Kt Connect&lt;/h2>
&lt;p>&lt;code>Kt Connect&lt;/code> 是阿里巴巴开源的一款云原生协同开发测试解决方案，目前的功能包括：&lt;/p>
&lt;ul>
&lt;li>直接访问 Kubernetes 集群&lt;/li>
&lt;li>转发集群流量到本地&lt;/li>
&lt;li>Service Mesh 支持&lt;/li>
&lt;li>基于 SSH 的轻量级 VPN 网络&lt;/li>
&lt;li>作为 kubectl 插件，集成到 Kubectl&lt;/li>
&lt;/ul>
&lt;p>（以上内容来自&lt;a href="https://alibaba.github.io/kt-connect/#/zh-cn/">官方文档&lt;/a>）&lt;/p>
&lt;p>目前使用下来最实用的功能就是&lt;strong>直接连接 Kubernetes 网络&lt;/strong>实现在本地使用 k8s 内网域名调用 Kubernetes 集群内的服务以及&lt;strong>将 Kubernetes 集群中的流量转发到本地&lt;/strong>，作用类似于一个 VPN，将本地网络与 Kubernetes 集群网络连接。
&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gd4wu5p3rmj20pb0dl75m.jpg" alt="">&lt;/p>
&lt;h2 id="安装">安装&lt;/h2>
&lt;p>&lt;code>Kt Connect&lt;/code> 使用 Go 开发，支持 Mac、Linux 和 Windows，安装方式也很简单&lt;/p>
&lt;p>前往&lt;a href="https://github.com/alibaba/kt-connect/releases">Github Releases&lt;/a> 下载可执行文件&lt;/p>
&lt;h3 id="mac">Mac&lt;/h3>
&lt;p>安装sshuttle&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">brew install sshuttle
&lt;/code>&lt;/pre>&lt;/div>&lt;p>下载并安装KT&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -OL https://rdc-incubators.oss-cn-beijing.aliyuncs.com/stable/ktctl_darwin_amd64.tar.gz
$ tar -xzvf ktctl_darwin_amd64.tar.gz
$ mv ktctl_darwin_amd64 /usr/local/bin/ktctl
$ ktctl -h
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="linux">Linux&lt;/h3>
&lt;p>安装sshuttle&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">pip install sshuttle
&lt;/code>&lt;/pre>&lt;/div>&lt;p>下载并安装KT&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl -OL https://rdc-incubators.oss-cn-beijing.aliyuncs.com/stable/ktctl_linux_amd64.tar.gz
$ tar -xzvf ktctl_linux_amd64.tar.gz
$ mv ktctl_linux_amd64 /usr/local/bin/ktctl
$ ktctl -h
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="windows">Windows&lt;/h3>
&lt;p>下载并解压可执行文件，并确保ktctl在PATH路径下&lt;/p>
&lt;h2 id="本地连接集群">本地连接集群&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
以MacOS为例
&lt;/div>
&lt;p>使用 &lt;code>ktctl connect&lt;/code> 命令，启动的时候需要 admin 权限，需要输入密码&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ ktctl --namespace=default connect
1:51PM INF Connect Start At &lt;span style="color:#3677a9">69444&lt;/span>
1:51PM INF Client address 192.168.7.121
1:51PM INF deploy shadow deployment kt-connect-daemon-rcacy in namespace default
1:51PM INF pod label: &lt;span style="color:#40ffff">kt&lt;/span>=kt-connect-daemon-rcacy
1:51PM INF pod: kt-connect-daemon-rcacy-fd4c587f-zmn4z is running,but not ready
1:51PM INF pod: kt-connect-daemon-rcacy-fd4c587f-zmn4z is running,but not ready
1:51PM INF Shadow pod: kt-connect-daemon-rcacy-fd4c587f-zmn4z is ready.
Forwarding from 127.0.0.1:2222 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
Forwarding from [::1]:2222 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
1:51PM INF port-forward start at pid: &lt;span style="color:#3677a9">69445&lt;/span>
[&lt;span style="color:#24909d">local&lt;/span> sudo] Password: 1:51PM INF vpn(sshuttle) start at pid: &lt;span style="color:#3677a9">69449&lt;/span>
1:51PM INF KT proxy start successful
&lt;span style="color:#999;font-style:italic"># 这里需要输入密码&lt;/span>
Handling connection &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> &lt;span style="color:#3677a9">2222&lt;/span>
Warning: Permanently added &lt;span style="color:#ed9d13">&amp;#39;[127.0.0.1]:2222&amp;#39;&lt;/span> (ECDSA) to the list of known hosts.
bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
client: Connected.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里可以看到在 &lt;code>namespace:default&lt;/code> 中部署了一个 &lt;code>kt-connect-daemon-*&lt;/code> 的 &lt;code>Deployment&lt;/code>，如果这个 &lt;code>Deployment&lt;/code> 启动正常，就可以直接在本地访问 Kubernetes 集群内的服务了。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get deploy | grep kt
kt-connect-daemon-rcacy 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 5m35s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>访问集群服务，可以使用 &lt;code>curl&lt;/code> 或者直接在浏览器访问。（这里使用之前文章&lt;a href="../feiyan-grafana">《使用 Grafana 展示肺炎疫情动态》&lt;/a>中部署的服务）&lt;/p>
&lt;h3 id="使用-curl">使用 &lt;code>curl&lt;/code>&lt;/h3>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl kk-feiyan
UP
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="直接使用浏览器">直接使用浏览器&lt;/h3>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65ly1gd4zc1ddfij20fq03zglp.jpg" alt="image">&lt;/p>
&lt;h2 id="转发集群流量到本地">转发集群流量到本地&lt;/h2>
&lt;p>使用 &lt;code>ktctl exchange&lt;/code> 命令，这个命令的前提条件是 Kubernetes 集群中必须有已经已经存在的 &lt;code>Deployment&lt;/code>，在运行该命令时，将会起一个 shadow 容器，来代替已存在的 Deployment，调用该容器的流量，都会被转发到本地的指定端口。&lt;/p>
&lt;div class="alert alert-primary" role="alert">
要注意的是：该命令会将其代替的 Deployment 的 replicas 设置为0，可能会导致业务的暂停，请勿在生产环境中使用！
&lt;/div>
&lt;p>本地启动一个服务&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65ly1gd4zsl7r14j20eq03r76o.jpg" alt="image">&lt;/p>
&lt;p>运行命令&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ ktctl exchange kk-feiyan --expose &lt;span style="color:#3677a9">8088&lt;/span>
2:13PM INF &lt;span style="color:#ed9d13">&amp;#39;KT Connect&amp;#39;&lt;/span> is runing, you can access &lt;span style="color:#24909d">local&lt;/span> app from cluster and localhost
2:13PM INF Client address 192.168.7.121
2:13PM INF deploy shadow deployment kk-feiyan-kt-yssnq in namespace default
2:13PM INF pod label: &lt;span style="color:#40ffff">kt&lt;/span>=kk-feiyan-kt-yssnq
2:13PM INF pod: kk-feiyan-kt-yssnq-6464bbf74d-smvhc is running,but not ready
2:13PM INF pod: kk-feiyan-kt-yssnq-6464bbf74d-smvhc is running,but not ready
2:13PM INF Shadow pod: kk-feiyan-kt-yssnq-6464bbf74d-smvhc is ready.
2:13PM INF create exchange shadow kk-feiyan-kt-yssnq in namespace default
2:13PM INF scale deployment kk-feiyan to &lt;span style="color:#3677a9">0&lt;/span>
2:13PM INF * kk-feiyan (&lt;span style="color:#3677a9">0&lt;/span> replicas) success
2:13PM INF remote 172.22.1.166 forward to &lt;span style="color:#24909d">local&lt;/span> &lt;span style="color:#3677a9">8088&lt;/span>
Forwarding from 127.0.0.1:2266 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
Forwarding from [::1]:2266 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
2:13PM INF exchange port forward to &lt;span style="color:#24909d">local&lt;/span> start at pid: &lt;span style="color:#3677a9">70269&lt;/span>
2:13PM INF redirect request from pod 172.22.1.166 &lt;span style="color:#3677a9">22&lt;/span> to 127.0.0.1:2266 starting
Handling connection &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> &lt;span style="color:#3677a9">2266&lt;/span>
Warning: Permanently added &lt;span style="color:#ed9d13">&amp;#39;[127.0.0.1]:2266&amp;#39;&lt;/span> (ECDSA) to the list of known hosts.
bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2:13PM INF ssh remote port-forward start at pid: &lt;span style="color:#3677a9">70270&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看 Deployment&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get deploy | grep kk-feiyan
kk-feiyan 0/0 &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">0&lt;/span> 39d &lt;span style="color:#999;font-style:italic"># 原服务&lt;/span>
kk-feiyan-kt-eclcc 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 89s &lt;span style="color:#999;font-style:italic"># 转发流量服务&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样的话，集群内调用 &lt;code>kk-feiyan&lt;/code> 这个服务的流量都会被转发到本地&lt;/p>
&lt;p>&lt;strong>集群内调用：&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl kk-feiyan
UP
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>可以看到流量被抓发到了本地&lt;/strong>
&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65ly1gd4zuym6ofj20eq052n0d.jpg" alt="image">&lt;/p>
&lt;h2 id="将本地服务暴露到-kubernetes-集群">将本地服务暴露到 Kubernetes 集群&lt;/h2>
&lt;p>有些时候，我们并不想使用 &lt;code>exchange&lt;/code> 来代替已经存在的 Deployment，只想在集群内新建一个服务来将流量转发到本，以完成调试。&lt;/p>
&lt;p>这个时候使用 &lt;code>ktctl run&lt;/code>，就可以满足需求，该命令会在 Kubernetes 集群中新建一个服务，并将访问该服务的流量被转发到本地的指定端口。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ ktctl run localservice --port &lt;span style="color:#3677a9">8088&lt;/span> --expose
2:33PM INF Client address 192.168.7.121
2:33PM INF deploy shadow deployment localservice in namespace default
2:33PM INF pod label: &lt;span style="color:#40ffff">kt&lt;/span>=localservice
2:33PM INF pod: localservice-77d565c488-64hpp is running,but not ready
2:33PM INF pod: localservice-77d565c488-64hpp is running,but not ready
2:33PM INF Shadow pod: localservice-77d565c488-64hpp is ready.
2:33PM INF create shadow pod localservice-77d565c488-64hpp ip 172.22.1.74
2:33PM INF expose deployment localservice to localservice:8088
2:33PM INF remote 172.22.1.74 forward to &lt;span style="color:#24909d">local&lt;/span> &lt;span style="color:#3677a9">8088&lt;/span>
Forwarding from 127.0.0.1:2274 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
Forwarding from [::1]:2274 -&amp;gt; &lt;span style="color:#3677a9">22&lt;/span>
2:33PM INF exchange port forward to &lt;span style="color:#24909d">local&lt;/span> start at pid: &lt;span style="color:#3677a9">70899&lt;/span>
2:33PM INF redirect request from pod 172.22.1.74 &lt;span style="color:#3677a9">22&lt;/span> to 127.0.0.1:2274 starting
Handling connection &lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> &lt;span style="color:#3677a9">2274&lt;/span>
Warning: Permanently added &lt;span style="color:#ed9d13">&amp;#39;[127.0.0.1]:2274&amp;#39;&lt;/span> (ECDSA) to the list of known hosts.
bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2:33PM INF ssh remote port-forward start at pid: &lt;span style="color:#3677a9">70903&lt;/span>
2:33PM INF forward remote 172.22.1.74:8088 -&amp;gt; 127.0.0.1:8088
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到该服务已经被拉起了&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get deploy localservice
NAME READY UP-TO-DATE AVAILABLE AGE
localservice 1/1 &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> 86s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>访问该服务&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ curl localservice:8088
UP
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到流量被转发到了本地
&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65ly1gd50e6lkquj20ff05z782.jpg" alt="image">&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>本地访问 k8s 内网，将 k8s 流量转发到本地，靠着这两大功能 &lt;code>Kt Connect&lt;/code> 可以称之为研发侧的利器，我们可以轻松的在本地调用集群服务，或者让集群调用本地的服务，这就让开发/测试 k8s 集群中发起调用的服务，在本地断点 debug 成为了现实，非常好用。同时还有其他一些没有介绍的功能，比如：&lt;/p>
&lt;ul>
&lt;li>Service Mesh 支持，可以支持用户可以基于Service Mesh的能力做更多自定义的流量规则定义&lt;/li>
&lt;li>Dashboard 功能，管理所以使用 kt 连入集群的用户等等&lt;/li>
&lt;/ul>
&lt;p>值得一提的是，&lt;code>ktctl run&lt;/code> 功能是我提出该场景并希望能实现，该 &lt;a href="https://github.com/alibaba/kt-connect/issues/89">issue&lt;/a> 提出仅一天就通过并完成了开发。给高效的开发人员点赞。&lt;/p></description></item><item><title>Post: Kubernetes 中优化流量和安全性需要注意的7点要求</title><link>https://guoxudong.io/post/7-requirements-for-optimized-traffic-flow-and-security-in-kubernetes/</link><pubDate>Tue, 18 Feb 2020 14:15:42 +0800</pubDate><guid>https://guoxudong.io/post/7-requirements-for-optimized-traffic-flow-and-security-in-kubernetes/</guid><description>
&lt;p>根据 &lt;a href="https://portworx.com/wp-content/uploads/2018/12/Portworx-Container-Adoption-Survey-Report-2018.pdf">Portworx 在2018年进行的一项调查&lt;/a>，五分之四的企业现在正在使用容器，其中83％的企业正在生产环境中使用。而这个数字在2017年只有67％，很明显，容器不仅仅是一种时尚。&lt;/p>
&lt;p>但是，随着容器的流行，一些公司开始在 Kubernetes 内建立有效的流量控制和安全策略。&lt;/p>
&lt;p>作为容器调度和集群管理平台，Kubernetes 致力于提供出色的基础架构，因此被无数公司采用。它刚刚开源五周年，最近在福布斯发表的一篇名为&lt;a href="https://www.forbes.com/sites/janakirammsv/2019/05/25/5-exciting-facts-about-kubernetes-on-the-eve-of-its-5th-anniversary/#87a930c3e736">《Kubernetes “the most popular open source project of our times”》&lt;/a>的文章表示，Kubernetes 已被 Capital One，ING Group，Philips，VMware 和 Huawei 等公司使用。&lt;/p>
&lt;p>对于使用微服务架构（MSA）开发来应用程序的公司来说，Kubernetes 具有许多优势，特别是在应用程序部署方面。&lt;/p>
&lt;p>出于上面这些原因，研发团队有必要了解 Kubernetes 独有的流量和安全情况。在本文中，我们将介绍：&lt;/p>
&lt;ul>
&lt;li>Kubernetes 是什么。&lt;/li>
&lt;li>Kubernetes 面临的挑战。&lt;/li>
&lt;li>Kubernetes 中的七个最重要的流量和安全要求。&lt;/li>
&lt;li>关于开发和操作简便性的注意事项。&lt;/li>
&lt;/ul>
&lt;p>让我们开始吧。&lt;/p>
&lt;h2 id="kubernetes-是什么">Kubernetes 是什么&lt;/h2>
&lt;p>Kubernetes 是一个开源的容器编排系统。根据 &lt;a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">Kubernetes’ own definition&lt;/a>，它是一个可移植且可扩展的程序，用于管理容器化的工作负载和服务，并提供以容器为中心的管理环境。&lt;/p>
&lt;p>下图描述了 Kubernetes 的基本工作方式。图中可以看到一个主节点和两个工作节点。主节点用来告诉工作程序节点需要做什么工作，而工作程序节点则执行主节点提供给它们的指令。同时可以添加其他 Kubernetes 工作节点以扩展基础架构。&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gc0k2knw9zj20r30czq6p.jpg" alt="">&lt;/p>
&lt;p>如果仔细观察，您会发现在每个部分中都出现了 “Docker” 一词。Docker 是一个容器平台，非常适合在单个物理机或虚拟机（VM）上运行容器。&lt;/p>
&lt;p>但是，如果您要在多个不同的应用程序中使用数百个容器，且您不希望将它们全部放在一台计算机上。这是催生 Kubernetes 的挑战之一。&lt;/p>
&lt;p>使用 overlay 网络（如上图中的红色条所示），主节点中的容器不必知道它需要与之通信的容器位于哪个节点，就可以直接与之通信。&lt;/p>
&lt;p>Kubernetes 的另一个主要功能是将信息打包到 “pod” 中，如果应用程序由多个容器组成，则可以将这些容器组成一个 pod ，并共享整个生命周期。&lt;/p>
&lt;h2 id="kubernetes-面临的挑战">Kubernetes 面临的挑战&lt;/h2>
&lt;p>像所有其他容器编排系统一样，Kubernetes 也面临的诸多挑战，其中包括：&lt;/p>
&lt;ul>
&lt;li>内部和外部网络是隔离的。&lt;/li>
&lt;li>容器和容器的 IP 地址会发生变化。&lt;/li>
&lt;li>微服务之间没有访问控制。&lt;/li>
&lt;li>没有应用程序层的可见性。&lt;/li>
&lt;/ul>
&lt;p>让我们更深入地探讨这些挑战。Kubernetes 的网络不是常规的网络，因为尽管使用了 overlay 网络，但内部和外部网络却是彼此不通的。&lt;/p>
&lt;p>另外，Kubernetes 会隔离发生故障的节点或 Pod，以防止它们关闭整个应用程序。这可能导致节点之间的IP地址频繁更改。想要发现容器或容器的IP地址的服务就必须弄清楚新的IP地址是什么。&lt;/p>
&lt;p>当涉及微服务之间的访问控制时，对于企业而言，重要的是要认识到 Kubernetes 节点之间的流量也能够流入外部物理设备或 VM。这可能会消耗资源并削弱安全性。&lt;/p>
&lt;p>最后，无法在应用程序层检查信息是一个大问题。没有这种可见性，企业可能会错过收集详细分析信息的关键机会。&lt;/p>
&lt;h2 id="kubernetes-和云安全要求">Kubernetes 和云安全要求&lt;/h2>
&lt;p>到目前为止，我们已经讨论了 Kubernetes 的基本功能以及它所带来的挑战。现在，基于 &lt;a href="https://www.a10networks.com/">A10 Networks&lt;/a> 15年的经验，我们将继续讨论 Kubernetes 和云安全性的要求。&lt;/p>
&lt;p>我们将讨论如下七点要求：&lt;/p>
&lt;ol>
&lt;li>高级应用程序交付控制器（ADC）&lt;/li>
&lt;li>使负载均衡器（LB）配置与基础架构保持同步&lt;/li>
&lt;li>南北向流量的安全&lt;/li>
&lt;li>为大规模部署准备的中央控制器&lt;/li>
&lt;li>微服务之间的访问控制&lt;/li>
&lt;li>东西向流量加密&lt;/li>
&lt;li>应用流量分析&lt;/li>
&lt;/ol>
&lt;h3 id="1-高级应用程序交付控制器adc">1. 高级应用程序交付控制器（ADC）&lt;/h3>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gc0ldvmd2ij20r30bjad0.jpg" alt="">&lt;/p>
&lt;p>虽然企业可能已经在其基础架构的其他区域使用了高级应用程序交付控制器，但也有必要为 Kubernetes 部署一个。默认情况下，这将允许管理员操作在 Kubernetes 前的高级负载均衡器。&lt;/p>
&lt;p>Kubernetes 已经配备了名为 &lt;em>kube-proxy&lt;/em> 的网络代理。它提供了简单的用法：通过在三层中调整 iptables 规则来工作。但这是非常基本的，并与大多数企业操作习惯的有所不同。&lt;/p>
&lt;p>许多人会将 ADC 或负载均衡器放在他们的 Kubernetes 前。这样就可以创建一个静态的虚拟 IP，所有人都可以使用它，并动态配置所有内容。&lt;/p>
&lt;p>随着 Pod 和容器的启动，可以动态配置 ADC，以提供对新应用程序的访问，同时实现网络安全策略，并在某些情况下实施业务数据规则。通常，这是通过使用 “Ingress controller” 来实现的，其可以监控到新的容器和容器的启动，并且可以配置 ADC 以提供对新应用程序的访问权限，或者将更改通知给另一个 “Kubernetes controller” 节点。&lt;/p>
&lt;h3 id="2-使负载均衡器lb配置与基础架构保持同步">2. 使负载均衡器（LB）配置与基础架构保持同步&lt;/h3>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gc0ll8lr83j20r30aytbc.jpg" alt="">&lt;/p>
&lt;p>由于在 Kubernetes 中一切都是可以不断变化的，因此位于集群前的负载均衡器是无法追踪所有事情的。除非您有类似上图紫色框所示的东西。&lt;/p>
&lt;p>该紫色框为 Ingress Controller，当容器启动或停止时，会在 Kubernetes 中创建一个事件。然后，Ingress Controller 会识别该事件并做出相应的响应。&lt;/p>
&lt;p>如上图所示，Ingress Controlle 识别到容器已启动，并将其放入负载均衡池。这样，应用程序控制器（无论是在云之上还是内部）都可以保持最新状态。&lt;/p>
&lt;p>这减轻了管理员的负担，并且比手动管理效率更高。&lt;/p>
&lt;h3 id="3-南北向流量的安全">3. 南北向流量的安全&lt;/h3>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1gc1hnwxcqlj20r30bpgon.jpg" alt="">&lt;/p>
&lt;p>南北和东西方都是用来描述流量流向的通用术语。南北流量是指流量流入和流出 Kubernetes。&lt;/p>
&lt;p>如前所述，企业需要在 Kubernetes 前放置一些设备来监视流量。例如，防火墙，DDoS 防护或任何其他可捕获恶意流量的设备。&lt;/p>
&lt;p>这些设备在流量管理方面也很有用。因此，如果流量需要流向特定的区域，这是理想的选择。Ingress Controller 在这方面也可以提供很多帮助。&lt;/p>
&lt;p>如果企业可以通过统一的解决方案使这种功能自动化，那么他们可以得到：&lt;/p>
&lt;ul>
&lt;li>更简化操作&lt;/li>
&lt;li>更好的应用程序性能&lt;/li>
&lt;li>可在不中断前端的情况下进行后端更改&lt;/li>
&lt;li>自动化的安全策略&lt;/li>
&lt;/ul>
&lt;h3 id="4-为大规模部署准备的中央控制器">4. 为大规模部署准备的中央控制器&lt;/h3>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gc1i8wydpyj20r30bamzf.jpg" alt="">&lt;/p>
&lt;p>企业还需要考虑到横向扩展，特别是在安全性方面。&lt;/p>
&lt;p>如上图所示，Ingress Controller（由紫色框表示）仍然存在，但是这次它正在处理来自多个 Kubernetes 节点的请求，并且正在观测整个 Kubernetes 集群。&lt;/p>
&lt;p>Ingress Controller 前方的蓝色圆圈是 &lt;a href="https://www.a10networks.com/products/harmony-controller/">A10 Networks Harmony Controller&lt;/a>。这种控制器可以实现高效的负载分配，并且可以将信息快速发送到适当的位置。&lt;/p>
&lt;p>使用这样的中央控制器，必须选择一种在现有解决方案上进行少量额外配置，就可进行扩容和缩容的解决方案。&lt;/p>
&lt;h3 id="5-微服务之间的访问控制">5. 微服务之间的访问控制&lt;/h3>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gc1ikekni3j20r30ckjuz.jpg" alt="">&lt;/p>
&lt;p>与流入和流出 Kubernetes 的南北流量相反，东西向流量在 Kubernetes 节点之间流动。在上图中，您可以看到东西向流量是如何运作的。&lt;/p>
&lt;p>当流量在 Kubernetes 节点之间流动时，可以通过物理网络，虚拟网络或 overlay 网络来发送该流量。如果不通过某种方式来监控那些东西向的流量，那么对流量如何从一个 pod 或容器流向另一个 pod 或容器的了解就变得非常困难。&lt;/p>
&lt;p>另外，它还可能带来严重的安全风险：&lt;strong>获得对一个容器的访问权限的攻击者可以访问整个内部网络&lt;/strong>。&lt;/p>
&lt;p>幸运的是，企业可以通过“服务网格”（例如 A10 Secure Service Mesh）来解决这个问题。通过充当容器之间的代理以实现安全规则，这可以确保东西向的流量安全，并且还可以帮助扩展，负载均衡，服务监视等。&lt;/p>
&lt;p>此外，服务网格可以在 Kubernetes 内部运行，而无需将流量发送到物理设备或 VM。使用服务网格，东西向的流量状况如下所示：&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gc1ikyysvtj20r30bcn0n.jpg" alt="">&lt;/p>
&lt;p>通过这种解决方案，像金融机构这样的企业可以轻松地将信息保留在应有的位置，而不用担心影响安全性。&lt;/p>
&lt;h3 id="6-东西向流量加密">6. 东西向流量加密&lt;/h3>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1gc1ivrlln4j20r309ojtt.jpg" alt="">&lt;/p>
&lt;p>如果没有适当的加密，未加密的信息可能会从一个物理 Kubernetes 节点流到另一个。这是一个严重的问题，特别是对于需要处理特别敏感信息的金融机构和其他企业。&lt;/p>
&lt;p>这就是为什么对于企业而言，在评估云安全产品时，重要的是选择一种可以在离开节点时对流量进行加密，并在进入节点时对其进行解密的方法。&lt;/p>
&lt;p>供应商可以通过两种方式提供这种类型的保护：&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1gc1ixe7n4xj20r30b0aci.jpg" alt="">&lt;/p>
&lt;p>第一个选择是 Sidecar 代理部署，这种方法也是最受欢迎的。&lt;/p>
&lt;p>通过这样的部署，管理员可以告诉 Kubernetes，每当启动特定 pod 时，应在该 pod 中启动一个或多个其他容器。&lt;/p>
&lt;p>通常，其他容器是某种类型的代理，可以管理从 Pod 流入和流出的流量。&lt;/p>
&lt;p>从上图可以看出，Sidecar 代理部署的不利之处在于，每个 pod 都需要启动一个 Sidecar，因此将占用一定数量的资源。&lt;/p>
&lt;p>另一方面，企业也可以选择中心辐射代理部署。在这种类型的部署中，一个代理会处理从每个 Kubernetes 节点流出的流量。这样只需要较少的资源。&lt;/p>
&lt;h3 id="7-应用流量分析">7. 应用流量分析&lt;/h3>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1gc1j83rredj20r30dfn2i.jpg" alt="">&lt;/p>
&lt;p>最后一点是，企业了解应用程序层流量的详细信息至关重要。&lt;/p>
&lt;p>有了可同时监控南北和东西向流量的控制器，就已经有了两个理想的点来收集流量信息。&lt;/p>
&lt;p>这样做既可以帮助优化应用程序，又可以提高安全性，还可以拓展多种不同的功能。从最简单到最高级的顺序排列，这些功能可以实现：&lt;/p>
&lt;ul>
&lt;li>通过描述性分析进行&lt;strong>性能监控&lt;/strong>。大多数供应商都提供此功能。&lt;/li>
&lt;li>通过诊断分析&lt;strong>更快地进行故障排除&lt;/strong>。少数供应商提供此功能。&lt;/li>
&lt;li>通过机器学习系统生成的预测分析获得&lt;strong>建议&lt;/strong>。更少的供应商提供此功能。&lt;/li>
&lt;li>通过真实直观的AI生成的规范分析进行&lt;strong>自适应控制&lt;/strong>。只有最好，最先进的供应商才能提供此功能。&lt;/li>
&lt;/ul>
&lt;p>因此，当企业与供应商交流时，至关重要的是确定他们的产品可以提供哪些功能。&lt;/p>
&lt;p>使用 A10 Networks 的类似产品，可以查看大图分析以及相关的单个数据包，日志条目或问题。具有这种粒度的产品是企业应寻求的产品。&lt;/p>
&lt;h2 id="关于开发和操作简便性的注意事项">关于开发和操作简便性的注意事项&lt;/h2>
&lt;p>最后，让我们看一下企业在 Kubernetes 中的流量和安全性方面应该追寻的东西。考虑这些因素还可以为开发和运维团队大大简化工作：&lt;/p>
&lt;ul>
&lt;li>具有统一解决方案的简单体系结构。&lt;/li>
&lt;li>集中管理和控制，便于进行分析和故障排除。&lt;/li>
&lt;li>使用常见的配置格式，例如 YAML 和 JSON。&lt;/li>
&lt;li>无需更改应用程序代码或配置即可实现安全性和收集分析信息。&lt;/li>
&lt;li>自动化应用安全策略。&lt;/li>
&lt;/ul>
&lt;p>如果公司优先考虑以上这些，则企业可以在使用 Kubernetes 时享受简单、自动化和安全的流量。您的基础设施、架构和运维团队都会对此感到满意。&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;p>&lt;strong>原文信息&lt;/strong>&lt;/p>
&lt;p>作者：Almas Raza、John Allen&lt;/p>
&lt;p>发表时间：31 Jul 2019 9:51am&lt;/p>
&lt;p>地址：https://thenewstack.io/7-requirements-for-optimized-traffic-flow-and-security-in-kubernetes/&lt;/p>
&lt;/div></description></item><item><title>Post: K3d+Kubecm 本地开发运维两不误</title><link>https://guoxudong.io/post/k3d-k3s-kubecm/</link><pubDate>Mon, 17 Feb 2020 11:51:39 +0800</pubDate><guid>https://guoxudong.io/post/k3d-k3s-kubecm/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>k3s 是由 Rancher Labs 于2019年年初推出的一款轻量级 Kubernetes 发行版，满足在边缘计算环境中运行在 x86、ARM64 和 ARMv7 处理器上的小型、易于管理的 Kubernetes 集群日益增长的需求。&lt;/p>
&lt;p>k3s 除了在边缘计算领域的应用外，在研发侧的表现也十分出色。我们可以快速在本地拉起一个轻量级的 k8s 集群，而 k3d 则是 k3s 社区创建的一个小工具，可以在一个 docker 进程中运行整个 k3s 集群，相比直接使用 k3s 运行在本地，更好管理和部署。&lt;/p>
&lt;p>在日常工作中，时长要在本地集群和多个远程集群之间切换来完成运维工作，这时使用 &lt;code>kubecm&lt;/code> 快速将 k3s 集群的 kubeconfig 与现有集群的 kubeconfig 合并，并可快速切换集群，开发运维两不误。&lt;/p>
&lt;h2 id="安装-k3d">安装 k3d&lt;/h2>
&lt;p>k3d 提供了多种安装方式，十分方便。&lt;/p>
&lt;h3 id="使用脚本安装">使用脚本安装&lt;/h3>
&lt;p>直接使用 &lt;code>wget&lt;/code> 和 &lt;code>curl&lt;/code> 安装&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">wget -q -O - https://raw.githubusercontent.com/rancher/k3d/master/install.sh | bash
&lt;span style="color:#999;font-style:italic"># 或&lt;/span>
curl -s https://raw.githubusercontent.com/rancher/k3d/master/install.sh | bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装指定版本&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">wget -q -O - https://raw.githubusercontent.com/rancher/k3d/master/install.sh | &lt;span style="color:#40ffff">TAG&lt;/span>=v1.3.4 bash
&lt;span style="color:#999;font-style:italic"># 或&lt;/span>
curl -s https://raw.githubusercontent.com/rancher/k3d/master/install.sh | &lt;span style="color:#40ffff">TAG&lt;/span>=v1.3.4 bash
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="使用-homebrew-安装">使用 Homebrew 安装&lt;/h3>
&lt;p>MacOS 或安装了 Homebrew 的 Linux 可以使用 brew 安装：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">brew install k3d
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="其他">其他&lt;/h3>
&lt;p>还可以直接前往 &lt;a href="https://github.com/rancher/k3d/releases">release 页面&lt;/a> 下载二进制可执行文件，或者直接使用 &lt;code>go install github.com/rancher/k3d&lt;/code> 安装。&lt;/p>
&lt;h2 id="创建-k3s-集群">创建 k3s 集群&lt;/h2>
&lt;p>创建 k3s 集群也十分简单，一行命令就可拉起，速度非常快。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> k3d create -n k3s-local
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Created cluster network with ID facae4a046b169721805f93ec21ba1acb65b9efb8cf35866529178cb0fba75a9
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Created docker volume k3d-k3s-local-images
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Creating cluster [k3s-local]
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Creating server using docker.io/rancher/k3s:v1&lt;span style="color:#3677a9">.0.1&lt;/span>...
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] SUCCESS: created cluster [k3s-local]
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] You can now use the cluster with:
export KUBECONFIG=&lt;span style="color:#ed9d13">&amp;#34;$(k3d get-kubeconfig --name=&amp;#39;k3s-local&amp;#39;)&amp;#34;&lt;/span>
kubectl cluster-info
&lt;/code>&lt;/pre>&lt;/div>&lt;p>但是一般情况下，如果没有梯子的话，k3s 集群虽然拉起来很快，但因为拉不到镜像，集群组件都无法正常拉起。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> export KUBECONFIG=&lt;span style="color:#ed9d13">&amp;#34;$(k3d get-kubeconfig --name=&amp;#39;k3s-local&amp;#39;)&amp;#34;&lt;/span>
&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> kubectl get pod -n kube-system
NAME READY STATUS RESTARTS AGE
helm-install-traefik-&lt;span style="color:#3677a9">8&lt;/span>wxmr &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">3&lt;/span>m30s
metrics-server-&lt;span style="color:#3677a9">6&lt;/span>d684c7b5-j4sc7 &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">3&lt;/span>m30s
coredns-d798c9dd-j6lpw &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">3&lt;/span>m30s
local-path-provisioner-&lt;span style="color:#3677a9">58&lt;/span>fb86bdfd-wv7sw &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">3&lt;/span>m30s
&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> kubectl describe pod coredns-d798c9dd-j6lpw -n kube-system
...
Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Normal Scheduled &amp;lt;unknown&amp;gt; &lt;span style="color:#6ab825;font-weight:bold">default&lt;/span>-scheduler Successfully assigned kube-system/coredns-d798c9dd-j6lpw to k3d-k3s-local-server
Warning FailedCreatePodSandBox &lt;span style="color:#3677a9">7&lt;/span>&lt;span style="color:#447fcf">s&lt;/span> (x7 over &lt;span style="color:#3677a9">4&lt;/span>m30s) kubelet, k3d-k3s-local-server Failed create pod sandbox: rpc &lt;span style="color:#6ab825;font-weight:bold">error&lt;/span>: code = Unknown desc = failed to get sandbox image &lt;span style="color:#ed9d13">&amp;#34;k8s.gcr.io/pause:3.1&amp;#34;&lt;/span>: failed to pull image &lt;span style="color:#ed9d13">&amp;#34;k8s.gcr.io/pause:3.1&amp;#34;&lt;/span>: failed to pull and unpack image &lt;span style="color:#ed9d13">&amp;#34;k8s.gcr.io/pause:3.1&amp;#34;&lt;/span>: failed to resolve reference &lt;span style="color:#ed9d13">&amp;#34;k8s.gcr.io/pause:3.1&amp;#34;&lt;/span>: failed to do request: Head https:&lt;span style="color:#999;font-style:italic">//k8s.gcr.io/v2/pause/manifests/3.1: dial tcp 64.233.189.82:443: i/o timeout
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="离线安装">离线安装&lt;/h3>
&lt;p>如果没有梯子的话，就只能选择使用离线安装。&lt;/p>
&lt;h4 id="下载离线镜像">下载离线镜像&lt;/h4>
&lt;p>前往 &lt;a href="https://github.com/rancher/k3s/releases">release 页面&lt;/a> 下载指定版本的镜像，这里我们下载最新的 &lt;a href="https://github.com/rancher/k3s/releases/tag/v1.17.2%2Bk3s1">v1.17.2+k3s1&lt;/a> 镜像。&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1gbzdedmqpdj20sh0k776o.jpg" alt="image">&lt;/p>
&lt;p>下载到 &lt;code>~/airgap&lt;/code> 目录中，并进行解压，将解压后的目录重命名为 &lt;code>1.17.2&lt;/code>。&lt;/p>
&lt;h3 id="运行离线镜像">运行离线镜像&lt;/h3>
&lt;p>这里再次运行 k3d，部署 k3s 集群。这里要注意的是，挂载离线镜像的话，必须使用 &lt;code>-i&lt;/code> flag 来指定镜像版本，这里我们使用的是 &lt;a href="https://github.com/rancher/k3s/releases/tag/v1.17.2%2Bk3s1">v1.17.2+k3s1&lt;/a> 版本，而镜像的 tag 则是 &lt;code>v1.17.2-k3s1&lt;/code>，如果不确定 tag，可以去 &lt;a href="https://hub.docker.com/r/rancher/k3s/tags">DockerHub&lt;/a> 上查看。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> k3d create -n k3s-local -i rancher/k3s:v1&lt;span style="color:#3677a9">.17.2&lt;/span>-k3s1 -v &lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span>(pwd)/airgap/v1&lt;span style="color:#3677a9">.17.2&lt;/span>/:/&lt;span style="color:#6ab825;font-weight:bold">var&lt;/span>/lib/rancher/k3s/agent/images/
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Created cluster network with ID &lt;span style="color:#3677a9">10&lt;/span>b3fca995fcb491ae1fe1c901672bf6f0a0fd6f51785ba8403947d2773ebd43
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Created docker volume k3d-k3s-local-images
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Creating cluster [k3s-local]
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] Creating server using docker.io/rancher/k3s:v1&lt;span style="color:#3677a9">.17.2&lt;/span>-k3s1...
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] SUCCESS: created cluster [k3s-local]
INFO[&lt;span style="color:#3677a9">0000&lt;/span>] You can now use the cluster with:
export KUBECONFIG=&lt;span style="color:#ed9d13">&amp;#34;$(k3d get-kubeconfig --name=&amp;#39;k3s-local&amp;#39;)&amp;#34;&lt;/span>
kubectl cluster-info
&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看 k3s 集群组件启动状态：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> export KUBECONFIG=&lt;span style="color:#ed9d13">&amp;#34;$(k3d get-kubeconfig --name=&amp;#39;k3s-local&amp;#39;)&amp;#34;&lt;/span>
&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> kubectl get pod -A -w
NAMESPACE NAME READY STATUS RESTARTS AGE
kube-system local-path-provisioner-&lt;span style="color:#3677a9">58&lt;/span>fb86bdfd-&lt;span style="color:#3677a9">7&lt;/span>jzbw &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">6&lt;/span>m35s
kube-system coredns-d798c9dd-jhmds &lt;span style="color:#3677a9">1&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> Running &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">6&lt;/span>m35s
kube-system metrics-server-&lt;span style="color:#3677a9">6&lt;/span>d684c7b5-&lt;span style="color:#3677a9">4&lt;/span>x2cd &lt;span style="color:#3677a9">1&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> Running &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">6&lt;/span>m35s
kube-system traefik-&lt;span style="color:#3677a9">6787&lt;/span>cddb4b-&lt;span style="color:#3677a9">9&lt;/span>v7r4 &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">16&lt;/span>s
kube-system svclb-traefik-fzrqj &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">2&lt;/span> ContainerCreating &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">15&lt;/span>s
kube-system helm-install-traefik-h8k2j &lt;span style="color:#3677a9">0&lt;/span>/&lt;span style="color:#3677a9">1&lt;/span> Completed &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">6&lt;/span>m35s
kube-system svclb-traefik-fzrqj &lt;span style="color:#3677a9">2&lt;/span>/&lt;span style="color:#3677a9">2&lt;/span> Running &lt;span style="color:#3677a9">0&lt;/span> &lt;span style="color:#3677a9">21&lt;/span>s
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="使用-kubecm">使用 kubecm&lt;/h2>
&lt;p>在 k3s 集群启动成功后，使用 &lt;a href="https://github.com/sunny0826/kubecm">&lt;code>kubecm&lt;/code>&lt;/a>，将 k3s 的 kubeconfig 与现有 kubeconfig 合并。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubecm add -f &lt;span style="color:#6ab825;font-weight:bold">$(&lt;/span>k3d get-kubeconfig --name=&lt;span style="color:#ed9d13">&amp;#39;k3s-local&amp;#39;&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">)&lt;/span> -n k3s -c
&lt;/code>&lt;/pre>&lt;/div>&lt;p>切换集群，选择 k3s。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#a61717;background-color:#e3d2d2">$&lt;/span> kubecm s
Use the arrow keys to navigate: &lt;span style="color:#a61717;background-color:#e3d2d2">↓&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">↑&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">→&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">←&lt;/span> and / toggles search
Select Kube Context
&lt;span style="color:#a61717;background-color:#e3d2d2">😼&lt;/span> &lt;span style="color:#447fcf">k3s&lt;/span>(*)
prod-tg
test
&lt;span style="color:#a61717;background-color:#e3d2d2">↓&lt;/span> banma
--------- Info ----------
Name: k3s
Cluster: cluster-&lt;span style="color:#3677a9">485&lt;/span>d6mhcfm
User: user-&lt;span style="color:#3677a9">485&lt;/span>d6mhcfm
&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在就可以在本地使用 k3s 集群进行开发工作，而有运维工作的时候，使用 &lt;code>kubecm switch&lt;/code> 快速切换集群。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1gbzegsyex5j20x90n70vv.jpg" alt="image">&lt;/p>
&lt;p>k3s 同时支持 &lt;strong>x86_64&lt;/strong>、&lt;strong>ARM64&lt;/strong> 和 &lt;strong>ARMv7&lt;/strong> 架构，它可以十分灵活地跨任何边缘基础架构工作。不提 k3s 在边缘计算领域的应用，与之前使用的 &lt;a href="https://github.com/kubernetes/minikube">minikube&lt;/a> 相比，k3s 裁剪掉了许多用不到的功能，并且安装更简单，启动更快，空间占用也更小。相信 k3s 在开发侧的作用也会越来越大，使云原生应用的开发更加的便利。&lt;/p></description></item><item><title>Post: Kubecm：管理你的 kubeconfig</title><link>https://guoxudong.io/post/kubecm/</link><pubDate>Mon, 09 Dec 2019 10:07:46 +0800</pubDate><guid>https://guoxudong.io/post/kubecm/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>该项目脱胎于 &lt;a href="https://github.com/sunny0826/mergeKubeConfig">mergeKubeConfig&lt;/a> 项目，最早写该项目的目的是在一堆杂乱无章的 kubeconfig 中自由的切换。随着需要操作的 Kubernetes 集群越来越多，在不同的集群之间切换也越来越麻烦，而操作 Kubernetes 集群的本质不过是通过 &lt;code>kubeconfig&lt;/code> 访问 Kubernetes 集群的 API Server，以操作 Kubernetes 的各种资源，而 &lt;code>kubeconfig&lt;/code> 不过是一个 yaml 文件，用来保存访问集群的密钥，最早的 &lt;a href="https://github.com/sunny0826/mergeKubeConfig">mergeKubeConfig&lt;/a> 不过是一个操作 yaml 文件的 Python 脚本。而随着 golang 学习的深入，也就动了重写这个项目的念头，就这样 &lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 诞生了。&lt;/p>
&lt;h2 id="kubecm">kubecm&lt;/h2>
&lt;p>&lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 由 golang 编写，支持 &lt;code>Mac&lt;/code> &lt;code>Linux&lt;/code> 和 &lt;code>windows&lt;/code> 平台，&lt;code>delete&lt;/code> &lt;code>rename&lt;/code> &lt;code>switch&lt;/code> 提供比较实用的交互式的操作，目前的功能包括：&lt;/p>
&lt;ul>
&lt;li>add ：添加新的 &lt;code>kubeconfig&lt;/code> 到 &lt;code>$HOME/.kube/config&lt;/code> 中&lt;/li>
&lt;li>completion ：命令行自动补全功能&lt;/li>
&lt;li>delete：删除已有的 &lt;code>context&lt;/code> ，提供交互式和指定删除两种方式&lt;/li>
&lt;li>merge：将指定目录中的 &lt;code>kubeconfig&lt;/code> 合并为一个 &lt;code>kubeconfig&lt;/code> 文件&lt;/li>
&lt;li>rename：重名指定的 &lt;code>context&lt;/code>，提供交互式和指定重命名两种方式&lt;/li>
&lt;li>switch：交互式切换 &lt;code>context&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="安装">安装&lt;/h2>
&lt;p>&lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 支持 &lt;code>Mac&lt;/code> &lt;code>Linux&lt;/code> 和 &lt;code>windows&lt;/code> 平台，安装方式也比较简单：&lt;/p>
&lt;h4 id="macos">MacOS&lt;/h4>
&lt;div class="alert alert-primary" role="alert">
使用 &lt;code>brew&lt;/code> 或者直接下载二进制可执行文件
&lt;/div>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">brew install sunny0826/tap/kubecm
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="linux">Linux&lt;/h4>
&lt;div class="alert alert-primary" role="alert">
下载二进制可执行文件
&lt;/div>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># linux x86_64&lt;/span>
curl -Lo kubecm.tar.gz https://github.com/sunny0826/kubecm/releases/download/v&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">VERSION&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>/kubecm_&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">VERSION&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>_Linux_x86_64.tar.gz
tar -zxvf kubecm.tar.gz kubecm
&lt;span style="color:#24909d">cd&lt;/span> kubecm
sudo mv kubecm /usr/local/bin/
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="windows">Windows&lt;/h4>
&lt;div class="alert alert-primary" role="alert">
下载二进制可执行文件，并将文件移动到 &lt;code>$PATH&lt;/code> 中即可
&lt;/div>
&lt;h2 id="命令行自动补全">命令行自动补全&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 提供了和 &lt;a href="https://github.com/kubernetes/kubectl">kubectl&lt;/a> 一样的 completion 命令行自动补全功能（支持 bash/zsh）
&lt;/div>
&lt;p>以 &lt;code>zsh&lt;/code> 为例，在 &lt;code>$HOME/.zshrc&lt;/code> 中添加&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-vim" data-lang="vim">source &amp;lt;(kubecm completion zsh)&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后使用 &lt;code>source&lt;/code> 命令，使其生效&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-zsh" data-lang="zsh">&lt;span style="color:#24909d">source&lt;/span> &lt;span style="color:#40ffff">$HOME&lt;/span>/.zshrc
&lt;/code>&lt;/pre>&lt;/div>&lt;p>之后，在输入 &lt;code>kubecm&lt;/code> 后按 &lt;kbd>tab&lt;/kbd> 键，就可以看到命令行自动补全的内容&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g9qa0yy3bvj21co0f2hdt.jpg" alt="image">&lt;/p>
&lt;h2 id="操作-kubeconfig">操作 kubeconfig&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 可以实现 &lt;code>kubeconfig&lt;/code> 的查看、添加、删除、合并、重命名和切换
&lt;/div>
&lt;h4 id="查看">查看&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 查看 $HOME/.kube/config 中所有的 context&lt;/span>
kubecm
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="添加">添加&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 添加 example.yaml 到 $HOME/.kube/config.yaml，该方式不会覆盖源 kubeconfig，只会在当前目录中生成一个 config.yaml 文件&lt;/span>
kubecm add -f example.yaml
&lt;span style="color:#999;font-style:italic"># 功能同上，但是会将 example.yaml 中的 context 命名为 test&lt;/span>
kubecm add -f example.yaml -n &lt;span style="color:#24909d">test&lt;/span>
&lt;span style="color:#999;font-style:italic"># 添加 -c 会覆盖源 kubeconfig&lt;/span>
kubecm add -f example.yaml -c
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="删除">删除&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 交互式删除&lt;/span>
kubecm delete
&lt;span style="color:#999;font-style:italic"># 删除指定 context&lt;/span>
kubecm delete my-context
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="合并">合并&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 合并 test 目录中的 kubeconfig,该方式不会覆盖源 kubeconfig，只会在当前目录中生成一个 config.yaml 文件&lt;/span>
kubecm merge -f &lt;span style="color:#24909d">test&lt;/span>
&lt;span style="color:#999;font-style:italic"># 添加 -c 会覆盖源 kubeconfig&lt;/span>
kubecm merge -f &lt;span style="color:#24909d">test&lt;/span> -c
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="重命名">重命名&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 交互式重命名&lt;/span>
kubecm rename
&lt;span style="color:#999;font-style:italic"># 将 dev 重命名为 test&lt;/span>
kubecm rename -o dev -n &lt;span style="color:#24909d">test&lt;/span>
&lt;span style="color:#999;font-style:italic"># 重命名 current-context 为 dev&lt;/span>
kubecm rename -n dev -c
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="切换默认-namespace">切换默认 namespace&lt;/h4>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 交互式切换 namespace&lt;/span>
kubecm namespace
&lt;span style="color:#999;font-style:italic"># 或者&lt;/span>
kubecm ns
&lt;span style="color:#999;font-style:italic"># 切换默认 namespace 为 kube-system&lt;/span>
kubecm ns kube-system
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="效果展示">效果展示&lt;/h2>
&lt;p>&lt;img src="Interaction.gif" alt="">&lt;/p>
&lt;h2 id="视频介绍">视频介绍&lt;/h2>
&lt;div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
&lt;iframe src="//player.bilibili.com/player.html?aid=88259938&amp;amp;cid=150776221&amp;amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"> &lt;/iframe>
&lt;/div>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>&lt;a href="https://github.com/sunny0826/kubecm">kubecm&lt;/a> 项目的初衷为学习 golang 并熟悉 client-go 的使用，随着使用的深入，断断续续增加了不少功能，开发出了一个看上去还算正规的项目。总的来说都是根据自己的喜好来开发的业余项目，欢迎各位通过 &lt;a href="https://github.com/sunny0826/kubecm/issues/new">ISSUE&lt;/a> 来进行交流和讨论。&lt;/p></description></item><item><title>Post: 小工具介绍：KubeWatch</title><link>https://guoxudong.io/post/kubewatch/</link><pubDate>Wed, 04 Dec 2019 17:09:51 +0800</pubDate><guid>https://guoxudong.io/post/kubewatch/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>这次要介绍一个 Kubernetes 资源观测工具，实时监控 Kubernetes 集群中各种资源的新建、更新和删除，并实时通知到各种协作软件/聊天软件，目前支持的通知渠道有：&lt;/p>
&lt;ul>
&lt;li>&lt;code>slack&lt;/code>&lt;/li>
&lt;li>&lt;code>hipchat&lt;/code>&lt;/li>
&lt;li>&lt;code>mattermost&lt;/code>&lt;/li>
&lt;li>&lt;code>flock&lt;/code>&lt;/li>
&lt;li>&lt;code>webhook&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>我这边开发了钉钉的通知渠道，但是在上游 &lt;a href="https://github.com/bitnami-labs/kubewatch/issues/198">ISSUE#198&lt;/a> 中提出的贡献请求并没有得到回应，所以这边只能 fork 了代码，然后自己进行了开发，以支持钉钉通知。&lt;/p>
&lt;h2 id="安装">安装&lt;/h2>
&lt;p>这里推荐使用 helm 进行安装，快速部署&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm install kubewatch stable/kubewatch &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set rbac.create=&lt;span style="color:#24909d">true&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set slack.channel=&lt;span style="color:#ed9d13">&amp;#39;#YOUR_CHANNEL&amp;#39;&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set slack.token=&lt;span style="color:#ed9d13">&amp;#39;xoxb-YOUR_TOKEN&amp;#39;&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set resourcesToWatch.pod=&lt;span style="color:#24909d">true&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set resourcesToWatch.daemonset=&lt;span style="color:#24909d">true&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果想使用钉钉通知，则可以在 &lt;a href="https://github.com/sunny0826/kubewatch-chat">GitHub&lt;/a> 上拉取我的代码，代码中包含 helm chart 包，可直接进行安装&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">git clone https://github.com/sunny0826/kubewatch-chat.git
&lt;span style="color:#24909d">cd&lt;/span> kubewatch-chat
helm install kubewatch kubewatch &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set dingtalk.sign=&lt;span style="color:#ed9d13">&amp;#34;XXX&amp;#34;&lt;/span> &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set dingtalk.token=&lt;span style="color:#ed9d13">&amp;#34;XXXX-XXXX-XXXX&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="钉钉配置">钉钉配置&lt;/h2>
&lt;p>在钉钉中创建 &lt;code>智能群助手&lt;/code> ，之后&lt;/p>
&lt;h3 id="获取-token">获取 token&lt;/h3>
&lt;p>复制的 webhook 中 &lt;code>https://oapi.dingtalk.com/robot/send?access_token={YOUR_TOKEN}&lt;/code>, &lt;code>{YOUR_TOKEN}&lt;/code> 就是要填入的 token。&lt;/p>
&lt;p>&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1g9ku2hvs16j20ep05smxk.jpg" alt="">&lt;/p>
&lt;h2 id="安全设置">安全设置&lt;/h2>
&lt;p>钉钉智能群助手在更新后新增了安全设置，提供三种验证方式 &lt;code>自定义关键词&lt;/code> &lt;code>加签&lt;/code> &lt;code>IP地址（段）&lt;/code>，这里推荐使用 &lt;code>IP地址（段）的方式&lt;/code>，直接将 Kubernetes 集群的出口 IP 填入设置即可。同时也提供了 &lt;code>加签&lt;/code> 的方式，拷贝秘钥，将其填入 &lt;code>dingtalk.sign&lt;/code> 中。&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1g9ku6qjwy2j20fo077glw.jpg" alt="">&lt;/p>
&lt;h2 id="项目配置">项目配置&lt;/h2>
&lt;p>编辑 &lt;code>kubewatch/value.yaml&lt;/code> ，修改配置&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic">## Global Docker image parameters&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">## Please, note that this will override the image parameters, including dependencies, configured to use the global value&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">## Current available global Docker image parameters: imageRegistry and imagePullSecrets&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">##&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># global:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># imageRegistry: myRegistryName&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># imagePullSecrets:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># - myRegistryKeySecretName&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">slack&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">channel&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">token&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;xoxb&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">hipchat&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># room: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># token: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># url: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">mattermost&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># channel: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># url: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># username: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">flock&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># url: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">webhook&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># url: &amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">dingtalk&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enabled&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">token&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">sign&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># namespace to watch, leave it empty for watching all.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespaceToWatch&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Resources to watch&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resourcesToWatch&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deployment&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicationcontroller&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicaset&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">daemonset&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">services&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">pod&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">job&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">persistentvolume&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">registry&lt;/span>:&lt;span style="color:#666"> &lt;/span>docker.io&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># repository: bitnami/kubewatch&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">repository&lt;/span>:&lt;span style="color:#666"> &lt;/span>guoxudongdocker/kubewatch-chart&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># tag: 0.0.4-debian-9-r405&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tag&lt;/span>:&lt;span style="color:#666"> &lt;/span>latest&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">pullPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>Always&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">## Optionally specify an array of imagePullSecrets.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">## Secrets must be manually created in the namespace.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">##&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># pullSecrets:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># - myRegistryKeySecretName&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">## String to partially override kubewatch.fullname template (will maintain the release name)&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">##&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># nameOverride:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">## String to fully override kubewatch.fullname template&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic">##&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># fullnameOverride:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">rbac&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># If true, create &amp;amp; use RBAC resources&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">create&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">serviceAccount&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Specifies whether a ServiceAccount should be created&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">create&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># The name of the ServiceAccount to use.&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># If not set and create is true, a name is generated using the fullname template&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># limits:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># cpu: 100m&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># memory: 300Mi&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># requests:&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># cpu: 100m&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># memory: 300Mi&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Affinity for pod assignment&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># affinity: {}&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Tolerations for pod assignment&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tolerations&lt;/span>:&lt;span style="color:#666"> &lt;/span>[]&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Node labels for pod assignment&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># Ref: https://kubernetes.io/docs/user-guide/node-selection/&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">nodeSelector&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">podAnnotations&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">podLabels&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicaCount&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用 &lt;code>value.yaml&lt;/code> 安装&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">git clone https://github.com/sunny0826/kubewatch-chat.git
&lt;span style="color:#24909d">cd&lt;/span> kubewatch-chat
helm install my-release -f kubewatch/values.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="slack-配置">Slack 配置&lt;/h2>
&lt;p>Slack 为 kubewatch 默认的通知软件，这里就不简介 Slack 的安装和注册，直接从创建 APP 开始&lt;/p>
&lt;h3 id="创建一个-app">创建一个 APP&lt;/h3>
&lt;p>进去创建 &lt;a href="https://api.slack.com/apps">APP 页面&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1g9kum3x5npj21h40p6tdx.jpg" alt="image">&lt;/p>
&lt;p>选择 &lt;code>App Name&lt;/code> 和 &lt;code>Development Slack Workspace&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://tva1.sinaimg.cn/large/ad5fbf65gy1g9kupp0av1j210c0uejvj.jpg" alt="">&lt;/p>
&lt;h3 id="添加-bot-用户">添加 Bot 用户&lt;/h3>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1g9kuszmgggj21n4156gu2.jpg" alt="image">&lt;/p>
&lt;h3 id="添加-app-到-workspace">添加 App 到 Workspace&lt;/h3>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/large/ad5fbf65gy1g9kuyzwzetj21qu0wmq9n.jpg" alt="image">&lt;/p>
&lt;h3 id="获取-bot-token">获取 Bot-token&lt;/h3>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1g9kv06dva8j21s60uajxf.jpg" alt="image">&lt;/p>
&lt;h2 id="通知效果">通知效果&lt;/h2>
&lt;p>在 Slack 中，&lt;code>创建&lt;/code> &lt;code>更新&lt;/code> &lt;code>删除&lt;/code> 分别以绿、黄和红色代表&lt;/p>
&lt;p>&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1g9kv23nvmoj213c0mewj4.jpg" alt="image">&lt;/p>
&lt;p>在钉钉中，我进行了汉化&lt;/p>
&lt;p>&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1g9kv5fppglj20dd08zdgs.jpg" alt="image">&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1g9kv5uuxn4j20ea08fgmk.jpg" alt="image">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>对于 kubewatch 我们这里主要用作监控各种 CronJob 的定时触发状态，已经 ConfigMap 和 Secrets 的状态变化，同时也观察 HPA 触发的弹性伸缩的状态，可以实时观测到业务高峰的到来，是一个不错的小工具。&lt;/p></description></item><item><title>Post: 使用 Velero 进行集群备份与迁移</title><link>https://guoxudong.io/post/aliyun-velero/</link><pubDate>Wed, 13 Nov 2019 09:13:22 +0800</pubDate><guid>https://guoxudong.io/post/aliyun-velero/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>在近日的一个风和日丽的下午，正在快乐的写 bug 时，突然间钉钉就被 call 爆了，原来是 k8s 测试集群的一个 namespace 突然不见了。这个 namespace 里面有 60 多个服务，瞬间全部没有了……虽然得益于我们的 CI/CD 系统，这些服务很快都重新部署并正常运行了，但是如果在生产环境，那后果就是不可想象的了。在排查这个问题发生的原因的同时，集群资源的灾备和恢复功能就提上日程了，这时 Velero 就出现了。&lt;/p>
&lt;h2 id="velero">Velero&lt;/h2>
&lt;p>&lt;a href="https://github.com/vmware-tanzu/velero">Velero&lt;/a> 是 VMWare 开源的 k8s 集群备份、迁移工具。可以帮助我们完成 k8s 的例行备份工作，以便在出现上面问题的时候可以快速进行恢复。同时也提供了集群迁移功能，可以将 k8s 资源迁移到其他 k8s 集群的功能。Velero 将集群资源保存在对象存储中，默认情况下可以使用 &lt;a href="https://velero.io/docs/v1.1.0/aws-config">AWS&lt;/a>、&lt;a href="https://velero.io/docs/v1.1.0/azure-config">Azure&lt;/a>、&lt;a href="https://velero.io/docs/v1.1.0/gcp-config">GCP&lt;/a> 的对象存储，同时也给出了插件功能用来拓展其他平台的存储，这里我们用到的就是阿里云的对象存储 OSS，阿里云也提供了 Velero 的插件，用于将备份存储到 OSS 中。下面我就介绍一下如何在阿里云容器服务 ACK 使用 Velero 完成备份和迁移。&lt;/p>
&lt;blockquote>
&lt;p>Velero 地址：https://github.com/vmware-tanzu/velero&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>ACK 插件地址：https://github.com/AliyunContainerService/velero-plugin&lt;/p>
&lt;/blockquote>
&lt;h3 id="下载-velero-客户端">下载 Velero 客户端&lt;/h3>
&lt;p>Velero 由客户端和服务端组成，服务器部署在目标 k8s 集群上，而客户端则是运行在本地的命令行工具。&lt;/p>
&lt;ul>
&lt;li>前往 &lt;a href="https://github.com/vmware-tanzu/velero/releases">Velero 的 Release 页面&lt;/a> 下载客户端，直接在 GitHub 上下载即可&lt;/li>
&lt;li>解压 release 包&lt;/li>
&lt;li>将 release 包中的二进制文件 &lt;code>velero&lt;/code> 移动到 &lt;code>$PATH&lt;/code> 中的某个目录下&lt;/li>
&lt;li>执行 &lt;code>velero -h&lt;/code> 测试&lt;/li>
&lt;/ul>
&lt;h3 id="创建-oss-bucket">创建 OSS bucket&lt;/h3>
&lt;p>创建一个 OSS bucket 用于存储备份文件，这里也可以用已有的 bucket，之后会在 bucket 中创建 &lt;code>backups&lt;/code>、&lt;code>metadata&lt;/code>、&lt;code>restores&lt;/code>三个目录，这里建议在已有的 bucket 中创建一个子目录用于存储备份文件。&lt;/p>
&lt;p>创建 OSS 的时候一定要选对区域，要和 ACK 集群在同一个区域，存储类型和读写权限选择&lt;strong>标准存储&lt;/strong>和&lt;strong>私有&lt;/strong>：&lt;/p>
&lt;p>&lt;img src="https://tva3.sinaimg.cn/wap720/ad5fbf65gy1g8w7t8c4xbj21021d8thq.jpg" alt="image">&lt;/p>
&lt;h3 id="创建阿里云-ram-用户">创建阿里云 RAM 用户&lt;/h3>
&lt;p>这里需要创建一个阿里云 RAM 的用户，用于操作 OSS 以及 ACK 资源。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>新建权限策略&lt;/p>
&lt;p>&lt;img src="https://tvax4.sinaimg.cn/large/ad5fbf65gy1g8w80cjiv2j21uo18cag8.jpg" alt="image">&lt;/p>
&lt;p>策略内容：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#6ab825;font-weight:bold">&amp;#34;Version&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;1&amp;#34;&lt;/span>,
&lt;span style="color:#6ab825;font-weight:bold">&amp;#34;Statement&amp;#34;&lt;/span>: [
{
&lt;span style="color:#6ab825;font-weight:bold">&amp;#34;Action&amp;#34;&lt;/span>: [
&lt;span style="color:#ed9d13">&amp;#34;ecs:DescribeSnapshots&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;ecs:CreateSnapshot&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;ecs:DeleteSnapshot&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;ecs:DescribeDisks&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;ecs:CreateDisk&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;ecs:Addtags&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;oss:PutObject&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;oss:GetObject&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;oss:DeleteObject&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;oss:GetBucket&amp;#34;&lt;/span>,
&lt;span style="color:#ed9d13">&amp;#34;oss:ListObjects&amp;#34;&lt;/span>
],
&lt;span style="color:#6ab825;font-weight:bold">&amp;#34;Resource&amp;#34;&lt;/span>: [
&lt;span style="color:#ed9d13">&amp;#34;*&amp;#34;&lt;/span>
],
&lt;span style="color:#6ab825;font-weight:bold">&amp;#34;Effect&amp;#34;&lt;/span>: &lt;span style="color:#ed9d13">&amp;#34;Allow&amp;#34;&lt;/span>
}
]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>新建用户&lt;/p>
&lt;p>在新建用户的时候要选择 &lt;code>编程访问&lt;/code>，来获取 &lt;code>AccessKeyID&lt;/code> 和 &lt;code>AccessKeySecret&lt;/code>，这里请创建一个新用于用于备份，不要使用老用户的 AK 和 AS。&lt;/p>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1g8w8h4ek4uj21h40ue785.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="部署服务端">部署服务端&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>拉取 &lt;a href="https://github.com/AliyunContainerService/velero-plugin">Velero 插件&lt;/a> 到本地&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">git clone https://github.com/AliyunContainerService/velero-plugin
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>配置修改&lt;/p>
&lt;ol>
&lt;li>
&lt;p>修改 &lt;code>install/credentials-velero&lt;/code> 文件，将新建用户中获得的 &lt;code>AccessKeyID&lt;/code> 和 &lt;code>AccessKeySecret&lt;/code> 填入，这里的 OSS EndPoint 为之前 OSS 的访问域名（&lt;strong>注：这里需要选择外网访问的 EndPoint。&lt;/strong>）：&lt;/p>
&lt;p>&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1g8w8xd1sgzj21c20cm75z.jpg" alt="image">&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#40ffff">ALIBABA_CLOUD_ACCESS_KEY_ID&lt;/span>=&amp;lt;ALIBABA_CLOUD_ACCESS_KEY_ID&amp;gt;
&lt;span style="color:#40ffff">ALIBABA_CLOUD_ACCESS_KEY_SECRET&lt;/span>=&amp;lt;ALIBABA_CLOUD_ACCESS_KEY_SECRET&amp;gt;
&lt;span style="color:#40ffff">ALIBABA_CLOUD_OSS_ENDPOINT&lt;/span>=&amp;lt;ALIBABA_CLOUD_OSS_ENDPOINT&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>修改 &lt;code>install/01-velero.yaml&lt;/code>，将 OSS 配置填入：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero.io/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>BackupStorageLocation&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">component&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>default&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">config&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">objectStorage&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">bucket&lt;/span>:&lt;span style="color:#666"> &lt;/span>&amp;lt;ALIBABA_CLOUD_OSS_BUCKET&amp;gt; &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># OSS bucket 名称&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prefix&lt;/span>:&lt;span style="color:#666"> &lt;/span>&amp;lt;OSS_PREFIX&amp;gt; &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># bucket 子目录&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">provider&lt;/span>:&lt;span style="color:#666"> &lt;/span>alibabacloud&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero.io/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>VolumeSnapshotLocation&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">component&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>default&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">config&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">region&lt;/span>:&lt;span style="color:#666"> &lt;/span>&amp;lt;REGION&amp;gt; &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 地域，如果是华东2（上海），则为 cn-shanghai&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">provider&lt;/span>:&lt;span style="color:#666"> &lt;/span>alibabacloud&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>k8s 部署 Velero 服务&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 新建 namespace&lt;/span>
kubectl create namespace velero
&lt;span style="color:#999;font-style:italic"># 部署 credentials-velero 的 secret&lt;/span>
kubectl create secret generic cloud-credentials --namespace velero --from-file &lt;span style="color:#40ffff">cloud&lt;/span>=install/credentials-velero
&lt;span style="color:#999;font-style:italic"># 部署 CRD&lt;/span>
kubectl apply -f install/00-crds.yaml
&lt;span style="color:#999;font-style:italic"># 部署 Velero&lt;/span>
kubectl apply -f install/01-velero.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>测试 Velero 状态&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ velero version
Client:
Version: v1.1.0
Git commit: a357f21aec6b39a8244dd23e469cc4519f1fe608
Server:
Version: v1.1.0
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到 Velero 的客户端和服务端已经部署成功。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务端清理&lt;/p>
&lt;p>在完成测试或者需要重新安装时，执行如下命令进行清理：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl delete namespace/velero clusterrolebinding/velero
kubectl delete crds -l &lt;span style="color:#40ffff">component&lt;/span>=velero
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h3 id="备份测试">备份测试&lt;/h3>
&lt;p>&lt;code>velero-plugin&lt;/code> 项目中已经给出 &lt;code>example&lt;/code> 用于测试备份。&lt;/p>
&lt;ul>
&lt;li>部署测试服务&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl apply -f examples/base.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>对 &lt;code>nginx-example&lt;/code> 所在的 namespace 进行备份&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero backup create nginx-backup --include-namespaces nginx-example --wait
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>模拟 namespace 被误删&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl delete namespaces nginx-example
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>使用 Velero 进行恢复&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero restore create --from-backup nginx-backup --wait
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="集群迁移">集群迁移&lt;/h3>
&lt;p>迁移方法同备份，在备份后切换集群，在新集群恢复备份即可。&lt;/p>
&lt;h3 id="高级用法">高级用法&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>定时备份&lt;/p>
&lt;p>对集群资源进行定时备份，则可在发生意外的情况下，进行恢复（默认情况下，备份保留 30 天）。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 每日1点进行备份&lt;/span>
velero create schedule &amp;lt;SCHEDULE NAME&amp;gt; --schedule=&lt;span style="color:#ed9d13">&amp;#34;0 1 * * *&amp;#34;&lt;/span>
&lt;span style="color:#999;font-style:italic"># 每日1点进行备份，备份保留48小时&lt;/span>
velero create schedule &amp;lt;SCHEDULE NAME&amp;gt; --schedule=&lt;span style="color:#ed9d13">&amp;#34;0 1 * * *&amp;#34;&lt;/span> --ttl 48h
&lt;span style="color:#999;font-style:italic"># 每6小时进行一次备份&lt;/span>
velero create schedule &amp;lt;SCHEDULE NAME&amp;gt; --schedule=&lt;span style="color:#ed9d13">&amp;#34;@every 6h&amp;#34;&lt;/span>
&lt;span style="color:#999;font-style:italic"># 每日对 web namespace 进行一次备份&lt;/span>
velero create schedule &amp;lt;SCHEDULE NAME&amp;gt; --schedule=&lt;span style="color:#ed9d13">&amp;#34;@every 24h&amp;#34;&lt;/span> --include-namespaces web
&lt;/code>&lt;/pre>&lt;/div>&lt;p>定时备份的名称为：&lt;code>&amp;lt;SCHEDULE NAME&amp;gt;-&amp;lt;TIMESTAMP&amp;gt;&lt;/code>，恢复命令为：&lt;code>velero restore create --from-backup &amp;lt;SCHEDULE NAME&amp;gt;-&amp;lt;TIMESTAMP&amp;gt;&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>备份删除&lt;/p>
&lt;p>直接执行命令进行删除&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero delete backups &amp;lt;BACKUP_NAME&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>备份资源查看&lt;/p>
&lt;p>备份查看&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero backup get
&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看定时备份&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero schedule get
&lt;/code>&lt;/pre>&lt;/div>&lt;p>查看可恢复备份&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">velero restore get
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>备份排除项目&lt;/p>
&lt;p>可为资源添加指定标签，添加标签的资源在备份的时候被排除。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># 添加标签&lt;/span>
kubectl label -n &amp;lt;ITEM_NAMESPACE&amp;gt; &amp;lt;RESOURCE&amp;gt;/&amp;lt;NAME&amp;gt; velero.io/exclude-from-backup=&lt;span style="color:#24909d">true&lt;/span>
&lt;span style="color:#999;font-style:italic"># 为 default namespace 添加标签&lt;/span>
kubectl label -n default namespace/default velero.io/exclude-from-backup=&lt;span style="color:#24909d">true&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;h3 id="问题汇总">问题汇总&lt;/h3>
&lt;h4 id="时区问题">时区问题&lt;/h4>
&lt;p>进行定时备份时，发现备份使用的事 UTC 时间，并不是本地时间，经过排查后发现是 &lt;code>velero&lt;/code> 镜像的时区问题，在调整后就会正常定时备份了，这里我重新调整了时区，直接调整镜像就好，修改 &lt;code>install/01-velero.yaml&lt;/code> 文件，将镜像替换为 &lt;code>registry-vpc.cn-shanghai.aliyuncs.com/keking/velero:latest&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">caption&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;Image from: [**Pexels**](https://www.pexels.com)&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">focal_point&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">preview_only&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>extensions/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deploy&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">template&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prometheus.io/path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/metrics&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prometheus.io/port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;8085&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prometheus.io/scrape&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">component&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deploy&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">serviceAccountName&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># sync from gcr.io/heptio-images/velero:latest&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>registry-vpc.cn-shanghai.aliyuncs.com/keking/velero:latest &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 修复时区后的镜像&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>IfNotPresent&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">command&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- /velero&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">args&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- server&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- --default-volume-snapshot-locations=alibabacloud:default&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>VELERO_SCRATCH_DIR&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>/scratch&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>ALIBABA_CLOUD_CREDENTIALS_FILE&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>/credentials/cloud&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/plugins&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>plugins&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/scratch&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>scratch&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/credentials&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>cloud-credentials&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">initContainers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>registry.cn-hangzhou.aliyuncs.com/acs/velero-plugin-alibabacloud:v1.2&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>IfNotPresent&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>velero-plugin-alibabacloud&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/target&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>plugins&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">emptyDir&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>plugins&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">emptyDir&lt;/span>:&lt;span style="color:#666"> &lt;/span>{}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>scratch&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>cloud-credentials&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">secret&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">secretName&lt;/span>:&lt;span style="color:#666"> &lt;/span>cloud-credentials&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="版本问题">版本问题&lt;/h4>
&lt;p>截止发稿时，Velero 已经发布了 v1.2.0 版本，目前 ACK 的 Velero 的插件还未升级。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>近日正好有 k8s 集群服务迁移服务的需求，使用 Velero 完成了服务的迁移，同时也每日进行集群资源备份，其能力可以满足容器服务的灾备和迁移场景，实测可用，现已运行在所有的 k8s 集群。&lt;/p></description></item><item><title>Post: 使用 Grafana 展示阿里云监控指标</title><link>https://guoxudong.io/post/aliyun-cms-grafana/</link><pubDate>Thu, 07 Nov 2019 11:08:36 +0800</pubDate><guid>https://guoxudong.io/post/aliyun-cms-grafana/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>对于阿里云用户来说，阿里云监控是一个很不错的产品，首先它在配额内使用是免费的！免费的！免费的！重要的事情说三遍。他的功能类似于 zabbix，但是比 zabbix 提供了更多的监控项，基本上在云上使用的资源都可以通过云监控来实时监控。而它提供的开箱即用方式，天然集成云资源，并提供多种告警方式，免去了监控与告警系统搭建与维护的繁琐，并且减少了资源的消耗，比购买 ECS 自己搭建 zabbix 要少消耗很多资源。同时阿里云监控和阿里云其他服务一样，也提供了比较完整的 OpenApi 以及各种语言的 sdk，可以基于阿里云的 OpenApi 将其与自己的系统集成。我们之前也是这么做的，但是随着监控项的增加，以及经常需要在办公场地监控投屏的专项监控页，光凭我们的运维开发工程师使用 vue 写速度明显跟不上，而且页面的美观程度也差很多。&lt;/p>
&lt;h3 id="手写前端-vs-grafana">手写前端 VS Grafana&lt;/h3>
&lt;p>手写前端虽然可定制化程度更高，但是需要消耗大量精力进行调试，对于运维人员，哪怕是运维开发也是吃不消的（前端小哥哥和小姐姐是不会来帮你的，下图就是我去年拿 vue 写的伪 Grafana 展示页面，花费了大约一周时间在调整这些前端元素）。
&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1g8pfrw1licj22ye1gg4qp.jpg" alt="image">&lt;/p>
&lt;p>Grafana 则标准化程度很高，展示也更加符合大众审美，某些定制化需求可以通过自定义 DataSource 或者 AJAX 插件的 iframe 模式完成。开发后端 DataSource 肯定就没有前端调整 css 那么痛苦和耗时了，整体配置开发一个这样的页面可能只消耗一人天就能完成。而在新产品上线时，构建一个专项监控展示页面速度就更快了，几分钟内就能完成。
&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1g8pfvp0keej22yc1g2khm.jpg" alt="image">&lt;/p>
&lt;h2 id="关于阿里云监控">关于阿里云监控&lt;/h2>
&lt;p>云监控（CloudMonitor）是一项针对阿里云资源和互联网应用进行监控的服务。&lt;/p>
&lt;p>云监控为云上用户提供开箱即用的企业级开放型一站式监控解决方案。涵盖 IT 设施基础监控，外网网络质量拨测监控，基于事件、自定义指标、日志的业务监控。为您全方位提供更高效、更全面、更省钱的监控服务。通过提供跨产品、跨地域的应用分组管理模型和报警模板，帮助您快速构建支持几十种云产品、管理数万实例的高效监控报警管理体系。通过提供 Dashboard，帮助您快速构建自定义业务监控大盘。使用云监控，不但可以帮助您提升您的系统服务可用时长，还可以降低企业 IT 运维监控成本。&lt;/p>
&lt;p>云监控服务可用于收集获取阿里云资源的监控指标或用户自定义的监控指标，探测服务可用性，以及针对指标设置警报。使您全面了解阿里云上的资源使用情况、业务的运行状况和健康度，并及时收到异常报警做出反应，保证应用程序顺畅运行。&lt;/p>
&lt;h2 id="关于-grafana">关于 Grafana&lt;/h2>
&lt;p>Grafana 是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。由于云监控的 Grafana 还没有支持告警，所以我们这里只用了 Grafana 的可视化功能，而告警本身就是云监控自带的，所以也不需要依赖 Grafana 来实现。而我们的 Prometheus 也使用了 Grafana 进行数据可视化，所以有现成的 Grafana-Server 使用。&lt;/p>
&lt;h2 id="阿里云监控对接-grafana">阿里云监控对接 Grafana&lt;/h2>
&lt;p>首先 Grafana 服务的部署方式这里就不做介绍了，请使用较新版本的 Grafana，最好是 5.5.0+。后文中也有我开源的基于阿里云云监控的 Grafana 的 helm chart，可以使用 helm 安装，并会直接导入云监控的指标，这个会在后文中介绍。&lt;/p>
&lt;h3 id="安装阿里云监控插件">安装阿里云监控插件&lt;/h3>
&lt;p>进入插件目录进行安装&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#24909d">cd&lt;/span> /var/lib/grafana/plugins/
git clone https://github.com/aliyun/aliyun-cms-grafana.git
service grafana-server restart
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果是使用 docker 或者部署在 k8s 集群，这里也可以使用环境变量在 Grafana 部署的时候进行安装&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>GF_INSTALL_PLUGINS &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 多个插件请使用,隔开&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>grafana-simple-json-datasource,https://github.com/aliyun/aliyun-cms-grafana/archive/master.zip;aliyun-cms-grafana&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>您也可以下载 aliyun-cms-grafana.zip 插件解压后，上传服务器的 Grafana 的 plugins 目录下，重启 grafana-server 即可。&lt;/p>
&lt;h3 id="配置云监控-datasource">配置云监控 DataSource&lt;/h3>
&lt;ol>
&lt;li>Grafana 启动后，进入 &lt;code>Configuration&lt;/code> 页面，选择 &lt;code>DataSource&lt;/code> Tab 页，单击右上方的&lt;code>Add data source&lt;/code>，添加数据源。&lt;/li>
&lt;li>选中&lt;code>CMS Grafana Service&lt;/code>，单击&lt;code>select&lt;/code>。
&lt;img src="https://tvax2.sinaimg.cn/large/ad5fbf65gy1g8ph0ukr0pj21nm0jk76m.jpg" alt="image">&lt;/li>
&lt;li>填写配置项，URL 根据云监控所在地域填写，并且填写阿里云账号的 accessKeyId 和 accessSecret，完成后单击&lt;code>Save&amp;amp;Test&lt;/code>。
&lt;img src="https://tvax3.sinaimg.cn/large/ad5fbf65gy1g8ph4bg2bij218m194n9f.jpg" alt="image">&lt;/li>
&lt;/ol>
&lt;h3 id="创建-dashboard">创建 Dashboard&lt;/h3>
&lt;ol>
&lt;li>单击 &lt;code>Create&lt;/code> -&amp;gt; &lt;code>Dashboard&lt;/code> -&amp;gt; &lt;code>Add Query&lt;/code>&lt;/li>
&lt;li>配置图标，数据源选择之前添加的 &lt;code>CMS Grafana Service&lt;/code>，然后文档中的配置项填入指标即可（这里要注意的是，云监控 API 给返回的只有实例 ID，并没有自定义的实例名称，这里需要手动将其填入 &lt;code>Y - column describe&lt;/code> 中；而且只支持输入单个 Dimension，若输入多个，默认选第一个，由于这些问题才有了后续我开发的 &lt;code>cms-grafana-builder&lt;/code> 的动机）。
&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1g8phck0irbj22ye13in79.jpg" alt="image">&lt;/li>
&lt;li>配置参考 &lt;a href="https://help.aliyun.com/document_detail/28619.html">云产品监控项&lt;/a>，
&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g8phg832uvj21a40vo793.jpg" alt="image">&lt;/li>
&lt;/ol>
&lt;h2 id="使用-helm-chart-的方式部署-grafana">使用 helm chart 的方式部署 Grafana&lt;/h2>
&lt;p>项目地址：https://github.com/sunny0826/cms-grafana-builder&lt;/p>
&lt;h3 id="cms-grafana-builder">cms-grafana-builder&lt;/h3>
&lt;p>由于上文中的问题，我们需要手动选择每个实例 ID 到 Dimension 中，并且还要讲该实例的名称键入 &lt;code>Y - column describe&lt;/code> 中，十分的繁琐，根本不可能大批量的输入。&lt;/p>
&lt;p>这就是我开发这个 Grafana 指标参数生成器的原因，起初只是一个 python 脚本，用来将我们要监控的指标组装成一个 Grafana 可以使用 json 文件，之后结合 Grafana 的容器化部署方法，将其做成了一个 helm chart。可以在启动的时候自动将需要的参数生成，并且每日会对所有指标进行更新，这样就不用每次新购或者释放掉资源后还需要再跑一遍脚本。&lt;/p>
&lt;h3 id="部署">部署&lt;/h3>
&lt;p>只需要将项目拉取下来运行 &lt;code>helm install&lt;/code> 命令&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">helm install my-release kk-grafana-cms &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--namespace {your_namespace} &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set &lt;span style="color:#40ffff">access_key_id&lt;/span>={your_access_key_id} &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set &lt;span style="color:#40ffff">access_secret&lt;/span>={your_access_secret} &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set &lt;span style="color:#40ffff">region_id&lt;/span>={your_aliyun_region_id} &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span>--set &lt;span style="color:#40ffff">password&lt;/span>={admin_password}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>更多详情见 &lt;a href="https://github.com/sunny0826/cms-grafana-builder">github README&lt;/a>，欢迎提 issue 交流。&lt;/p>
&lt;h3 id="指标选择">指标选择&lt;/h3>
&lt;p>在部署成功后，可修改 ConfigMap：&lt;code>grafana-cms-metric&lt;/code>，然后修改对应的监控指标项。&lt;/p>
&lt;h3 id="效果">效果&lt;/h3>
&lt;p>ECS:
&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1g8pi9toh3dj21gv0pldyf.jpg" alt="">&lt;/p>
&lt;p>RDS:
&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g8pi9o91ejj21h80q316p.jpg" alt="">&lt;/p>
&lt;p>EIP:
&lt;img src="https://tva4.sinaimg.cn/large/ad5fbf65gy1g8pi9i9if3j21h70q3aif.jpg" alt="">&lt;/p>
&lt;p>Redis:
&lt;img src="https://tvax1.sinaimg.cn/large/ad5fbf65gy1g8pi8ss733j21h30pz7b6.jpg" alt="">&lt;/p>
&lt;h2 id="后记">后记&lt;/h2>
&lt;p>为了满足公司需求，后续还开发 DataSource 定制部分，用于公司监控大屏的展示，这部分是另一个项目，不在这个项目里，就不细说了，之后有机会总结后再进行分享。&lt;/p></description></item><item><title>Post: 解决 Nginx-Ingress 重定向失败问题</title><link>https://guoxudong.io/post/nginx-ingress-error/</link><pubDate>Fri, 16 Aug 2019 11:15:37 +0800</pubDate><guid>https://guoxudong.io/post/nginx-ingress-error/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近对公司 Kubernetes 集群的 &lt;code>nginx-ingress-controller&lt;/code> 进行了升级，但是升级后却出现了大问题，之前所有采用 &lt;code>nginx.ingress.kubernetes.io/rewrite-target: /&lt;/code> 注释进行重定向的 Ingress 路由全部失效了，但是那些直接解析了域名，没有进行重定向的却没有发生这个问题。&lt;/p>
&lt;h2 id="问题分析">问题分析&lt;/h2>
&lt;ol>
&lt;li>首先检查对应服务健康状态，发现所有出问题的服务的状态均正常，同时受影响的之后 http 调用，而 RPC 调用却不受影响，这时问题就定位到了 ingress。&lt;/li>
&lt;li>然后检查 nginx-ingress-controller ，发现 nginx-ingress-controller 的状态也是正常的，路由也是正常的。&lt;/li>
&lt;li>最后发现受影响的只有添加了重定向策略的 ingress 。&lt;/li>
&lt;/ol>
&lt;h2 id="问题解决">问题解决&lt;/h2>
&lt;p>问题已经定位，接下来就是着手解决问题，这时候值得注意的就是之前进行了什么变更：升级了 nginx-ingress-controller 版本！看来问题就出现在新版本上，那么就打开官方文档：https://kubernetes.github.io/ingress-nginx/examples/rewrite/ 看一下吧。&lt;/p>
&lt;h3 id="attention">Attention&lt;/h3>
&lt;blockquote>
&lt;p>Starting in Version 0.22.0, ingress definitions using the annotation &lt;code>nginx.ingress.kubernetes.io/rewrite-target&lt;/code> are not backwards compatible with previous versions. In Version 0.22.0 and beyond, any substrings within the request URI that need to be passed to the rewritten path must explicitly be defined in a &lt;a href="https://www.regular-expressions.info/refcapture.html">capture group&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>文档上给出了非常明显的警告⚠️：从 V0.22.0 版本开始将不再兼容之前的入口定义，再查看一下我的 nginx-ingress-controller 版本，果然问题出现来这里。&lt;/p>
&lt;h3 id="note">Note&lt;/h3>
&lt;blockquote>
&lt;p>&lt;a href="https://www.regular-expressions.info/refcapture.html">Captured groups&lt;/a> are saved in numbered placeholders, chronologically, in the form &lt;code>$1&lt;/code>, &lt;code>$2&lt;/code> &amp;hellip; &lt;code>$n&lt;/code>. These placeholders can be used as parameters in the &lt;code>rewrite-target&lt;/code> annotation.&lt;/p>
&lt;/blockquote>
&lt;h3 id="示例">示例&lt;/h3>
&lt;p>到这里问题已经解决了，在更新了 ingress 的配置之后，之前所有无法重定向的服务现在都已经可以正常访问了。修改见如下示例：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ &lt;span style="color:#24909d">echo&lt;/span> &lt;span style="color:#ed9d13">&amp;#39;
&lt;/span>&lt;span style="color:#ed9d13">apiVersion: extensions/v1beta1
&lt;/span>&lt;span style="color:#ed9d13">kind: Ingress
&lt;/span>&lt;span style="color:#ed9d13">metadata:
&lt;/span>&lt;span style="color:#ed9d13"> annotations:
&lt;/span>&lt;span style="color:#ed9d13"> nginx.ingress.kubernetes.io/rewrite-target: /$2
&lt;/span>&lt;span style="color:#ed9d13"> name: rewrite
&lt;/span>&lt;span style="color:#ed9d13"> namespace: default
&lt;/span>&lt;span style="color:#ed9d13">spec:
&lt;/span>&lt;span style="color:#ed9d13"> rules:
&lt;/span>&lt;span style="color:#ed9d13"> - host: rewrite.bar.com
&lt;/span>&lt;span style="color:#ed9d13"> http:
&lt;/span>&lt;span style="color:#ed9d13"> paths:
&lt;/span>&lt;span style="color:#ed9d13"> - backend:
&lt;/span>&lt;span style="color:#ed9d13"> serviceName: http-svc
&lt;/span>&lt;span style="color:#ed9d13"> servicePort: 80
&lt;/span>&lt;span style="color:#ed9d13"> path: /something(/|$)(.*)
&lt;/span>&lt;span style="color:#ed9d13">&amp;#39;&lt;/span> | kubectl create -f -
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="结语">结语&lt;/h2>
&lt;p>解决这个问题的实际时间虽然不长，但是着实让人出了一身冷汗，同时也给了我警示：变更有风险，升级需谨慎。在升级之前需要先浏览新版本的升级信息，同时需要制定完善的回滚策略，确保万无一失。&lt;/p></description></item><item><title>Post: 如何构建混合Kubernetes平台</title><link>https://guoxudong.io/post/how-we-built-our-hybrid-kubernetes-platfor/</link><pubDate>Tue, 06 Aug 2019 14:01:30 +0800</pubDate><guid>https://guoxudong.io/post/how-we-built-our-hybrid-kubernetes-platfor/</guid><description>
&lt;blockquote>
&lt;p>随着3年前重构 &lt;a href="https://www.dailymotion.com/">Dailymotion&lt;/a> 核心API的决定，我们希望提供一种更有效的方式来托管应用程序，&lt;a href="https://medium.com/dailymotion/deploying-apps-on-multiple-kubernetes-clusters-with-helm-19ee2b06179e">促进我们的开发和生产工作流程&lt;/a>。 最终决定使用容器编排平台来实现这一目标，那么自然就选择了 Kubernetes。&lt;/p>
&lt;/blockquote>
&lt;p>那么为什么要建立自己的Kubernetes平台？&lt;/p>
&lt;h2 id="借由-google-cloud-快速推动的-api-投入生产">借由 Google Cloud 快速推动的 API 投入生产&lt;/h2>
&lt;blockquote>
&lt;p>2016年夏&lt;/p>
&lt;/blockquote>
&lt;p>三年前，在 &lt;a href="https://www.vivendi.com/">Vivendi&lt;/a> 收购 Dailymotion 之后，所有开发团队都专注于一个目标：提供全新的 Dailymotion 产品。&lt;/p>
&lt;p>根据对容器、编排解决方案和以前的经验的分析，使我们确信 Kubernetes 是正确的选择。许多开发人员已经掌握了这一概念并知道如何使用 Kubernetes ，这对我们的基础设施转型来说是一个巨大的优势。在基础架构方面，我们需要一个强大而灵活的平台来托管这些新型的云原生应用程序。而公有云为我们提供了极大的便利，于是我们决定在 Google Kubernetes Engine 上部署我们的应用程序，即使之后我们也会在自己的数据中心中进行混合部署。&lt;/p>
&lt;h3 id="为何选择-gke-">为何选择 GKE ？&lt;/h3>
&lt;p>我们做出这个选择主要是出于技术原因，但也因为我们需要快速提供基础设施来满足 Dailymotion 的业务需求。并且对托管的应用程序（如地理分布，可伸缩性和弹性）有一些要求。&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g5py1vm2k2j20hd0bbjtq.jpg" alt="">&lt;/p>
&lt;center>Dailymotion 的 GKE 集群&lt;/center>
&lt;p>Dailymotion 作为一个全球性的视频平台，需要通过减少延迟来改善用户体验。之前我们仅在巴黎提供 &lt;a href="https://developer.dailymotion.com/">API&lt;/a> ，但这样并非最佳，我们希望能够在欧洲、亚洲以及美国托管我们的应用程序。&lt;/p>
&lt;p>这种延迟限制意味着我们在平台的网络设计方面面临着巨大的挑战。大多数云供应商要求我们在每个地区创建一个网络，并将所有这些网络通过 VPN 与托管服务互连，但 Google Cloud 允许我们在所有 Google 地区创建一个完全路由的单一网络，该网络在运营方面提供了便利并提高了效率。&lt;/p>
&lt;p>此外，Google Cloud 的网络和负载均衡服务非常棒。它可以将我们的用户路由到最近的集群，并且在发生故障的情况下，流量会自动路由到另一个区域而无需任何人为干预。&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g5pytelbwnj20jg0avq4x.jpg" alt="">&lt;/p>
&lt;center>Google 负载均衡监控&lt;/center>
&lt;p>我们的平台同样需要使用 GPU，而 Google Cloud 允许我们以非常有效的方式直接在我们的 Kubernetes 集群中使用它们。&lt;/p>
&lt;p>所有这一切使我们在启动后6个月开始接入 Google Cloud 基础架构上的生产流量。&lt;/p>
&lt;p>但是，尽管具有整体优势，但使用共有云服务还是要花费不少成本。这就是为什么我们要评估采取的每项托管服务，以便将来将其内部化。事实上，我们在2016年底开始构建我们的本地集群，并启动了我们的混合策略。&lt;/p>
&lt;h2 id="在-dailymotion-的内部构建容器编排平台">在 Dailymotion 的内部构建容器编排平台&lt;/h2>
&lt;blockquote>
&lt;p>2016年秋&lt;/p>
&lt;/blockquote>
&lt;p>看到整个技术栈已经准备好在生产环境中应用，但&lt;a href="https://tartiflette.io/">API仍在开发中&lt;/a>，这使得我们有时间专注搭建我们的本地集群。&lt;/p>
&lt;p>Dailymotion 多年来在全球拥有自己的内容分发网络，每月有超过30亿的视频播放量。显然，我们希望利用现有的优势并在我们现有的数据中心部署自己的 Kubernetes 集群。&lt;/p>
&lt;p>我的目前拥有6个数据中心的2500多台服务器。所有这些都使用 Saltstack 进行配置，我们开始准备所有需要的公式来创建主节点、工作节点以及 Etcd 集群。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g5pzm4m985j20jg06tgm7.jpg" alt="">&lt;/p>
&lt;h3 id="网络部分">网络部分&lt;/h3>
&lt;p>我们的网络是一个完全路由的网络。每个服务器使用Exabgp通过网络广播自己的IP。我们比较了几个网络插件， &lt;a href="https://www.projectcalico.org/">Calico&lt;/a> 使用的是三层网络，因此这是唯一满足我们需求的网络插件。&lt;/p>
&lt;p>由于我们想要重用基础架构中的所有现有工具，首先要解决的问题是插入一个自制网络工具（我们所有服务器都使用它），通过我们的 Kubernetes 节点通过网络广播 IP 范围。我们让 Calico 为 pod 分配 IP，但不使用它与我们的网络设备进行BGP会话。路由实际上是由Exabgp处理的，它宣布了Calico使用的子网。这使我们可以从内部网络访问任何pod，尤其是来自我们的负载均衡器。&lt;/p>
&lt;h3 id="我们如何管理入口流量">我们如何管理入口流量&lt;/h3>
&lt;p>为了将传入的请求路由到正确的服务，我们希望使用 Ingress Controllers 与 Kubernetes 的入口资源集成。&lt;/p>
&lt;p>3年前，nginx-ingress-controller 是最成熟的控制器 ，并且 Nginx 已经使用多年，并以其稳定性和性能而闻名。&lt;/p>
&lt;p>在我们的设计中，我们决定在专用的 10Gbps 刀片服务器上托管我们的控制器。每个控制器都插入其所属集群的 kube-apiserver 端点。在这些服务器上，我们还使用Exabgp来广播公共或私有IP。我们的网络拓扑允许我们使用来自这些控制器的BGP将所有流量直接路由到我们的pod，而无需使用NodePort服务类型。这样可以避免节点之间的水平流量，从而提高效率。&lt;/p>
&lt;p>&lt;img src="https://ws3.sinaimg.cn/large/ad5fbf65gy1g5q05ex27bj20in0fbt9q.jpg" alt="">&lt;/p>
&lt;center>从 Internet 到 pods 的流量&lt;/center>
&lt;p>现在我们已经看到了我们如何构建混合平台，我们可以深入了解流量迁移本身。&lt;/p>
&lt;h2 id="将流量从-google-cloud-迁移到-dailymotions-基础架构">将流量从 Google Cloud 迁移到 Dailymotions 基础架构&lt;/h2>
&lt;blockquote>
&lt;p>2018年秋&lt;/p>
&lt;/blockquote>
&lt;p>经过近2年的构建、测试和微调，我们发现自己拥有完整的 Kubernetes 技术栈，可以接收部分流量。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g5q0b3o8laj20jg06sq36.jpg" alt="">&lt;/p>
&lt;p>目前，我们的路由策略非常简单，但足以解决我们的问题。除了我们的公共IP（Google Cloud和Dailymotion）之外，我们还使用AWS Route 53 来定义策略并将终端用户流量引入我们选择的集群。&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g5q0ds3spjj20jg07a0tk.jpg" alt="">&lt;/p>
&lt;center>使用Route 53的路由策略示例&lt;/center>
&lt;p>在 Google Cloud 上很简单，因为我们为所有群集使用唯一的IP，并且用户被路由到他最近的 GKE 群集。对于我们来说，我们不使用相同的技术，因此我们每个群集都有不同的IP。&lt;/p>
&lt;p>在此次迁移过程中，我们将目标国家逐步纳入我们的集群并分析其收益。&lt;/p>
&lt;p>由于我们的GKE集群配置了自动调节自定义指标，因此它们会根据传入流量进行扩展/缩小。&lt;/p>
&lt;p>在正常模式下，区域的所有流量都路由到我们的内部部署集群，而GKE集群则使用Route 53提供的运行状况检查作为故障转移。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>我们接下来的步骤是完全自动化我们的路由策略，以实现自动混合策略，不断增强我们的用户体验。在效益方面，我们大大降低了云的成本，甚至改善了API响应时间。我们相信我们的云平台足以在需要时处理更多流量。&lt;/p></description></item><item><title>Post: 使用 Helm 在多集群部署应用</title><link>https://guoxudong.io/post/deploying-apps-on-multiple-kubernetes-clusters-with-hel/</link><pubDate>Sun, 14 Jul 2019 14:16:56 +0800</pubDate><guid>https://guoxudong.io/post/deploying-apps-on-multiple-kubernetes-clusters-with-hel/</guid><description>
&lt;blockquote>
&lt;p>&lt;a href="https://www.dailymotion.com/">Dailymotion&lt;/a> 在生产环境使用 Kubernetes 已经3年了，但是也面临着多集群部署应用的挑战，这也是在过去的几年中我一直努力优化工具和改进工作流的原因。&lt;/p>
&lt;/blockquote>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>本文将重点介绍我们如何在全球多个 Kubernetes 集群上部署我们的应用程序。&lt;/p>
&lt;p>为了将应用一次部署到多个 Kubernetes 集群，我们使用了 &lt;a href="https://helm.sh/">Helm&lt;/a>，并将所有 chart 存储在一个 git 仓库中。我们使用 &lt;strong>umbrella&lt;/strong> 来部署由多个服务组成的完整应用程序，这基本上是一个声明依赖关系的 chart ，其允许我们在单个命令行中引导我们的 API 及其服务。&lt;/p>
&lt;p>此外，我们在使用 Helm 之前会运行一个 python 脚本，用来进行检查，构建 chart ，添加 secrets 并部署我们的应用程序。所有这些任务都是使用 docker 镜像在 CI 平台上完成的。&lt;/p>
&lt;p>下面就进行详细介绍&lt;/p>
&lt;p>&lt;strong>注意！：&lt;/strong> 当你阅读这篇博文的时候，Helm 3 的第一个 &lt;a href="https://github.com/helm/helm/releases/tag/v3.0.0-alpha.1">release&lt;/a> 已经发布。这个版本带来了一系列增强功能，肯定会解决我们过去遇到的一些问题。&lt;/p>
&lt;h2 id="preview_only-false">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;h2 id="charts-开发流程">Charts 开发流程&lt;/h2>
&lt;p>在开发应用程序时，我们使用&lt;a href="https://git-scm.com/book/en/v2/Git-Branching-Branching-Workflows">分支工作流&lt;/a>，开发 chart 时也使用相同流程。&lt;/p>
&lt;ul>
&lt;li>首先，&lt;strong>dev&lt;/strong> 分支用于构建要在开发集群上进行测试的 chart 。&lt;/li>
&lt;li>然后，当发起 PR 请求到 &lt;strong>master&lt;/strong> 分支时，将发布到演示环境中进行验证。&lt;/li>
&lt;li>最终，我们将 PR 请求提交的修改合并到 &lt;strong>prod&lt;/strong> 分支，将这个修改应用于生产环境。&lt;/li>
&lt;/ul>
&lt;p>我们使用 &lt;a href="https://chartmuseum.com/">Chartmuseum&lt;/a> 作为私有仓库来存储 chart ，每个环境都有一个 。这样我们就可以在__环境之间实现明确的隔离__，并且确保该 chart 在生产环境中使用之前已经过测试。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g50h10d4xbj20ys0ee75e.jpg" alt="">&lt;/p>
&lt;center>每个环境的 Chart 仓库&lt;/center>
&lt;p>值得注意的是，当开发人员 push 代码到他们的 dev 分支时，他们的 chart 版本也会自动 push 到 dev 环境的 Chartmuseum 。因此，所有开发人员都使用相同的 dev 存储库，他们必须小心的指定自己的 chart 版本，以避免使用其他人的对 chart 的更改。&lt;/p>
&lt;p>此外，我们的 python 脚本通过使用 &lt;a href="https://kubeval.instrumenta.dev/">Kubeval&lt;/a> 在它们推送到 Chartmusem 之前验证 Kubernetes 对象与 Kubernetes OpenAPI 规范。&lt;/p>
&lt;blockquote>
&lt;p>chart 开发工作流&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://ws3.sinaimg.cn/large/ad5fbf65gy1g50hg9gmh2j20gr047t8o.jpg" alt="">&lt;/p>
&lt;ol>
&lt;li>根据 &lt;a href="https://gazr.io/">gazr.io&lt;/a> 规范设置我们的 pipeline 任务（lint，unit-test）。&lt;/li>
&lt;li>push docker 镜像，该镜像包含部署应用程序的 Python 工具。&lt;/li>
&lt;li>根据分支名称设置相应环境。&lt;/li>
&lt;li>使用 Kubeval 检查 Kubernetes yamls 。&lt;/li>
&lt;li>自动增加 chart 版本及其父项（取决于更改的 chart ）。&lt;/li>
&lt;li>将 chart push 到与其环境对应的 Chartmuseum 。&lt;/li>
&lt;/ol>
&lt;h2 id="管理集群差异">管理集群差异&lt;/h2>
&lt;blockquote>
&lt;p>Cluster federation&lt;/p>
&lt;/blockquote>
&lt;p>我们使用 &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/federation/">Kubernetes cluster federation&lt;/a>，它允许我们从单个 API 端声明 Kubernetes 对象。但是我们遇到的问题是，无法在 federation 端中创建某些 Kubernetes 对象，因此很难维护 federation 对象和其他的群集对象。&lt;/p>
&lt;p>为了解决这个问题，我们决定独立管理我们的集群，反而使这个过程变得更加容易（我们使用的是 federation v1，v2 可能有所改善）。&lt;/p>
&lt;blockquote>
&lt;p>平台地理分布&lt;/p>
&lt;/blockquote>
&lt;p>目前，我们的平台分布在6个地区，3个在自己的数据中心，3个在公有云。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g50klup6yaj212w0ftq4h.jpg" alt="">&lt;/p>
&lt;center>分布式部署&lt;/center>
&lt;blockquote>
&lt;p>Helm global values&lt;/p>
&lt;/blockquote>
&lt;p>4个全局的 Helm value 定义集群间的差异。这些是我们所有 chart 的最小默认值。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">global&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cloud&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">True&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666"> &lt;/span>staging&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">region&lt;/span>:&lt;span style="color:#666"> &lt;/span>us-central1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">clusterName&lt;/span>:&lt;span style="color:#666"> &lt;/span>staging-us-central1&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;center>global values&lt;/center>
&lt;p>这些信息有助于我们为应用程序定义上下文，它们可用于监控，跟踪，记录，进行外部调用，扩展等许多内容&amp;hellip;&amp;hellip;&lt;/p>
&lt;ul>
&lt;li>&lt;strong>cloud&lt;/strong>：我们有一个混合 Kubernetes 集群。例如，我们的 API 部署在 GCP 和我们自己的数据中心。&lt;/li>
&lt;li>&lt;strong>env&lt;/strong>：对于非生产环境，某些值可能会发生变化。本质上是资源定义和自动扩展配置。&lt;/li>
&lt;li>&lt;strong>region&lt;/strong>：此信息用于标识群集的位置，并可用于定义外部服务的最近端点。&lt;/li>
&lt;li>&lt;strong>clusterName&lt;/strong>：如果我们想要为每个群集定义一个值。&lt;/li>
&lt;/ul>
&lt;p>下面是一个具体的示例：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">{{/* Returns Horizontal Pod Autoscaler replicas for GraphQL*/}}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- define &amp;#34;graphql.hpaReplicas&amp;#34; -}}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- if eq .Values.global.env &amp;#34;prod&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- if eq .Values.global.region &amp;#34;europe-west1&amp;#34; }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">minReplicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">40&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- else }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">minReplicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">150&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- end }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">maxReplicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1400&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- else }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">minReplicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">4&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">maxReplicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">20&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- end }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- end -}}&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;center>helm template example&lt;/center>
&lt;p>请注意，此逻辑在帮助模板中定义，以保持 Kubernetes YAML 的可读性。&lt;/p>
&lt;blockquote>
&lt;p>声明应用&lt;/p>
&lt;/blockquote>
&lt;p>我们的部署工具基于几个 YAML 文件，下面是我们声明服务及其每个集群的扩展拓扑（副本数量）的示例。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">releases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- foo.world&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">foo.world&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># Release name&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">services&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># List of dailymotion&amp;#39;s apps/projects&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">foobar&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart_name&lt;/span>:&lt;span style="color:#666"> &lt;/span>foo-foobar&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">repo&lt;/span>:&lt;span style="color:#666"> &lt;/span>git@github.com:dailymotion/foobar&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">contexts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">prod-europe-west1&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deployments&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>foo-bar-baz&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">18&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>another-deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">3&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;center>service definition&lt;/center>
&lt;p>这是部署工作流的所有步骤，最后一步将在多个生产集群上同时部署应用程序。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g50ldllp33j20mw0bxglz.jpg" alt="">&lt;/p>
&lt;center>Jenkins deployment steps&lt;/center>
&lt;h2 id="secrets-怎么办">Secrets 怎么办&lt;/h2>
&lt;p>在安全领域，我们专注于跟踪可能在不同位置传播的所有的 Secrets ，并将其存储在巴黎的 &lt;a href="https://www.vaultproject.io/">Vault&lt;/a> 。&lt;/p>
&lt;p>我们的部署工具负责从 Vault 检索加密的值，并在部署时将其注入 Helm 。&lt;/p>
&lt;p>为此，我们定义了存储在 Vault 中的 Secrets 与我们的应用程序所需的 Secrets 之间的映射，如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">secrets&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">secret_id&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;stack1-app1-password&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">contexts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;default&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;/kv/dev/stack1/app1/test&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultKey&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;password&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;cluster1&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;/kv/dev/stack1/app1/test&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultKey&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;password&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>定义将 Secrets 写入 Vault 时要遵循的通用规则。&lt;/li>
&lt;li>如果 Secrets 有特定的上下文/集群，则必须添加特定条目。&lt;/li>
&lt;li>否则，将使用默认值。&lt;/li>
&lt;li>对于此列表中的每个项目，将在 Kubernetes Secrets 中插入一个 key/value 。这样我们 chart 中的 Secrets 模板非常简单。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">data&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{- range $key,$value := .Values.secrets }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">$key }}&lt;/span>:&lt;span style="color:#666"> &lt;/span>{{&lt;span style="color:#666"> &lt;/span>$value | b64enc | quote }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>{{&lt;span style="color:#666"> &lt;/span>end }}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Secret&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;{{ .Chart.Name }}&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chartVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;{{ .Chart.Version }}&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tillerVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;{{ .Capabilities.TillerVersion.SemVer }}&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>Opaque&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="警告与限制">警告与限制&lt;/h2>
&lt;h2 id="preview_only-false-1">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;h3 id="操作多个存储库">操作多个存储库&lt;/h3>
&lt;p>目前，chart 和应用程序开发是分离的。这意味着开发人员必须处理两个 git 存储库，一个用于应用程序，另一个用于定义如何在 Kubernetes 上部署。而2个 git 存储库意味着两个工作流程，这对于新手来说可能相当复杂。&lt;/p>
&lt;h3 id="管理-umbrella-charts-可能很棘手">管理 umbrella charts 可能很棘手&lt;/h3>
&lt;p>如前所述，umbrella charts 非常适合定义依赖关系并快速部署多个应用程序。同时我们使用 &lt;code>--reuse-values&lt;/code> 选项，以避免每次部署作为 umbrella charts 一部分的应用程序时都要传递所有值。&lt;/p>
&lt;p>在我们的 CD 工作流中，只有2个值会定期更改：副本数量和镜像标签（版本）。对于其他更稳定的值，需要手动更新，而且这些值并不是很容易弄清楚。此外，我们曾遇到过部署 umbrella charts 的一个错误导致严重的中断。&lt;/p>
&lt;h3 id="更新多个配置文件">更新多个配置文件&lt;/h3>
&lt;p>添加新应用程序时，开发人员必须更改多个文件：应用程序声明， Secrets 列表，如果应用程序是 umbrella charts 的一部分，则将其添加到依赖。&lt;/p>
&lt;h3 id="在-vault-上-jenkins-权限过大">在 Vault 上， Jenkins 权限过大&lt;/h3>
&lt;p>目前，我们有一个 &lt;a href="https://www.vaultproject.io/docs/auth/approle.html">AppRole&lt;/a> 可以读取 Vault 的所有 Secrets 。&lt;/p>
&lt;h3 id="回滚过程不是自动化的">回滚过程不是自动化的&lt;/h3>
&lt;p>回滚需要在多个集群上运行该命令，这可能容易出错。我们制作本操作手册是因为我们要确保应用正确的版本 ID 。&lt;/p>
&lt;h2 id="gitops-实践">GitOps 实践&lt;/h2>
&lt;blockquote>
&lt;p>目标&lt;/p>
&lt;/blockquote>
&lt;p>我们的想法是将 chart 放回到它部署的应用程序的存储库下。工作流程与应用同时开发，例如，无论何时在主服务器上合并分支，都会自动触发部署。这种方法与当前工作流程的主要区别在于，所有内容都将通过 git 进行管理（应用程序本身以及我们在 Kubernetes 中部署它的方式）。&lt;/p>
&lt;p>这样做优点：&lt;/p>
&lt;ul>
&lt;li>从开发人员的角度来看，更容易理解。学习如何在本地 chart 中应用更改将更容易。&lt;/li>
&lt;li>将服务 deployment 定义在与此服务的代码相同的位置。&lt;/li>
&lt;li>移除 umbrella charts 管理。服务将拥有自己的 Helm 版本。这使得应用程序生命周期管理（回滚，升级）形成闭环，不会影响其他服务。&lt;/li>
&lt;li>git 功能对 chart 管理的好处：回滚，审计日志&amp;hellip;&amp;hellip;如果要还原 chart 更改，可以使用 git 进行更改。同时部署将自动触发。&lt;/li>
&lt;li>我们考虑使用 Skaffold 等工具改进开发工作流程，这些工具允许开发人员在类似于生产的环境中测试他们的更改。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2步迁移&lt;/p>
&lt;/blockquote>
&lt;p>我们的开发人员已使用上述工作流程2年，因此我们需要尽可能顺利地进行迁移。这就是为什么我们决定在达到目标之前添加一个中间步骤。&lt;/p>
&lt;p>第一步很简单：&lt;/p>
&lt;ul>
&lt;li>我们将保留一个类似的结构来配置我们的应用程序部署，但是在名为 “DailymotionRelease” 的单个对象中&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;v1&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;DailymotionRelease&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;app1.ns1&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">environment&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;dev&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">branch&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;mybranch&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">slack_channel&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;#admin&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">chart_name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;app1&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">scaling&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">context&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;dev-us-central1-0&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;hermes&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">count&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">2&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">context&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;dev-europe-west1-0&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;app1-deploy&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">count&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">2&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">secrets&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">secret_id&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;app1&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">contexts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;default&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;/kv/dev/ns1/app1/test&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultKey&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;password&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;dev-europe-west1-0&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;/kv/dev/ns1/app1/test&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">vaultKey&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;password&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>每个应用程序一个版本（不再使用 umbrella charts ）&lt;/li>
&lt;li>将 chart 加入应用程序 git 存储库中&lt;/li>
&lt;/ul>
&lt;p>我们已经开始向所有开发人员科普这个词，并且迁移过程已经开始。第一步仍然使用 CI 平台进行控制。我将在短期内撰写另一篇博文，介绍第二步：我们如何通过 &lt;a href="https://github.com/weaveworks/flux">Flux&lt;/a> 实现向 GitOps 工作流程的迁移。将描述我们的设置和面临的挑战（多个存储库，Secrets 等）。 敬请期待！&lt;/p></description></item><item><title>Post: 阿里云 ACK 挂载 NAS 数据卷</title><link>https://guoxudong.io/post/nas-k8s/</link><pubDate>Mon, 08 Jul 2019 15:09:56 +0800</pubDate><guid>https://guoxudong.io/post/nas-k8s/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>今天接到一个将 NAS 数据卷挂载到 Kubernetes 集群的需求，需要将一个 NAS 数据卷挂载到集群中。这一很简单的操作由于好久没有操作了，去翻看了一下官方文档，发现官方文档还在停留在去年7月份&amp;hellip;为了防止之后还有相似情况的发生，这里将所有操作做一个简单记录。&lt;/p>
&lt;h2 id="购买存储包创建文件系统">购买存储包（创建文件系统）&lt;/h2>
&lt;p>在挂载 NAS 之前，首先要先购买 NAS 文件存储，这里推荐购买存储包，100G 的 SSD 急速型一年只需1400多，而容量型只要279，对于我这种只有少量 NAS 存储需求的人来说是是靠谱的，因为我只需要5G的左右的存储空间，SSD 急速型 NAS 一年只要18块，完美。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4sglwrx0gj22wa09gae4.jpg" alt="image">&lt;/p>
&lt;p>选择想要创建 NAS 所在 VPC 和 区域&lt;/p>
&lt;h2 id="添加挂载点">添加挂载点&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>点击添加挂载点
&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4sgp0dos2j22ky0iowkr.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选择 VPC 网络、交换机和权限组
&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4sgpwqrgoj20xu0vowib.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="linux-挂载-nas-数据卷">Linux 挂载 NAS 数据卷&lt;/h2>
&lt;p>在挂载点创建成功后，就可以将 NAS 数据卷挂载到 Linux 系统，这里以 CentOS 为例：&lt;/p>
&lt;h3 id="安装-nfs-客户端">安装 NFS 客户端&lt;/h3>
&lt;p>如果 Linux 系统要挂载 NAS ，首先需要安装 NFS 客户端&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo yum install nfs-utils
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="挂载-nfs-文件系统">挂载 NFS 文件系统&lt;/h3>
&lt;p>这里阿里云早就进行了优化，点击创建的文件系统，页面上就可以 copy 挂载命令。页面提供了挂载地址的 copy 和挂载命令的 copy 功能。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4sh2i33wnj22w40yyn55.jpg" alt="image">&lt;/p>
&lt;p>挂载命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo mount -t nfs -o &lt;span style="color:#40ffff">vers&lt;/span>=4,minorversion=0,noresvport xxxxx.cn-shanghai.nas.aliyuncs.com:/ /mnt
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="查看挂载结果">查看挂载结果&lt;/h3>
&lt;p>直接在挂载数据卷所在服务上执行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">df -h
&lt;/code>&lt;/pre>&lt;/div>&lt;p>就可以看到结果：&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4sh6xwyt8j20lj0850tq.jpg" alt="image">&lt;/p>
&lt;h2 id="kubernetes-集群挂载-nas-数据卷">Kubernetes 集群挂载 NAS 数据卷&lt;/h2>
&lt;p>K8S 的持久数据卷挂载大同小异，流程都是：&lt;strong>创建PV&lt;/strong> -&amp;gt; &lt;strong>创建PVC&lt;/strong> -&amp;gt; &lt;strong>使用PVC&lt;/strong>&lt;/p>
&lt;p>下面就简单介绍在阿里云上的操作：&lt;/p>
&lt;h3 id="创建存储卷pv">创建存储卷（PV）&lt;/h3>
&lt;p>首先要创建存储卷，选择 &lt;strong>容器服务&lt;/strong> -&amp;gt; &lt;strong>存储卷&lt;/strong> -&amp;gt; &lt;strong>创建&lt;/strong>&lt;/p>
&lt;p>这里要注意的是：&lt;strong>挂载点域名使用上面面的挂载地址&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g4shuiiyyqj20hc0hp0tz.jpg" alt="image">&lt;/p>
&lt;h3 id="创建存储声明pvc">创建存储声明（PVC）&lt;/h3>
&lt;p>&lt;strong>选择 NAS&lt;/strong> -&amp;gt; &lt;strong>已有存储卷&lt;/strong>&lt;/p>
&lt;p>选择刚才创建的存储卷&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g4shv5vs1kj20hx0bvt9g.jpg" alt="image">&lt;/p>
&lt;h3 id="使用pvc">使用PVC&lt;/h3>
&lt;p>使用的方法这里就不做详细介绍了，相关文章也比较多，这里就只记录 Deployment 中使用的 yaml 片段：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/data &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 挂载路径&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>volume-nas-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>volume-nas-test&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">persistentVolumeClaim&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">claimName&lt;/span>:&lt;span style="color:#666"> &lt;/span>nas-test &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># PVC 名称&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="结语">结语&lt;/h2>
&lt;p>这里只是做一个简单的记录，仅适用于阿里云 ACK 容器服务，同时也是 ACK 的一个简单应用。由于不经常对数据卷进行操作，这里做简单的记录，防止以后使用还要再看一遍文档。&lt;/p></description></item><item><title>Post: 【转】Kubernetes 儿童插图指南</title><link>https://guoxudong.io/post/the-childrens-illustrated-guide-to-kubernetes/</link><pubDate>Fri, 05 Jul 2019 09:50:58 +0800</pubDate><guid>https://guoxudong.io/post/the-childrens-illustrated-guide-to-kubernetes/</guid><description>
&lt;blockquote>
&lt;p>转自掘金社区，原文地址：https://juejin.im/post/5d1b2a656fb9a07edc0b7058&lt;/p>
&lt;/blockquote>
&lt;h2 id="kubernetes-儿童插图指南">Kubernetes 儿童插图指南&lt;/h2>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g4nwsdbr8wj20qo0hs0w2.jpg" alt="">
&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwt5keovj210u0shmyc.jpg" alt="">
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g4nwteb85hj20qo0hsk5v.jpg" alt="">&lt;/p>
&lt;p>&lt;strong>献给所有试图向孩子们解释软件工程的家长。&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwu2t40sj20qo0hswqv.jpg" alt="">&lt;/p>
&lt;p>很久很久以前，有一个叫 Phippy 的应用程序。她是一个简单的应用程序，由 PHP 编写且只有一个页面。她住在一个需要和其他可怕的应用程序分享环境的主机中，她不认识这些应用程序并且不愿意和他们来往。她希望她能拥有一个属于自己的环境：只有她自己和她可以称之为家的 Web 服务器。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwutz6f2j20qo0hsq90.jpg" alt="">&lt;/p>
&lt;p>每个应用程序都有个运行所依赖的环境。对于 PHP 应用程序来说，这个环境可能包括 Web 服务器，一个可读文件系统和 PHP 引擎本身。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nwvduq0mj20qo0hsdu8.jpg" alt="">&lt;/p>
&lt;p>有一天，一只善良的鲸鱼出现了。他建议小 Phippy 住在容器里，这样可能会更快乐。所以应用程序 Phippy 迁移到了容器中。这个容器很棒，但是……它有点像一个漂浮在大海中央的豪华起居室。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nwwr0uk3j20qo0hs0zi.jpg" alt="">&lt;/p>
&lt;p>容器提供了一个独立的环境，应用程序可以在这个环境中运行。但是这些孤立的容器常常需要被管理并与外面的世界连接。对于孤立的容器而言，共享文件系统、网络通信、调度、负载均衡和分发都是要面对的挑战。&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g4nwx3kj32j20qo0hswr7.jpg" alt="">&lt;/p>
&lt;p>鲸鱼耸了耸肩。“对不起，孩子。”他说着，消失在海面下。就在 Phippy 甚至开始绝望时，一位驾驶着巨轮的船长出现在海平线上。这艘船由几十个绑在一起的木筏组成，但从外面来看，它就像一艘巨轮。
“你好呀，这位 PHP 应用程序朋友。我是 Kube 船长。”睿智的老船长说。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwxm9w44j20qo0hsn3b.jpg" alt="">&lt;/p>
&lt;p>“Kubernetes” 在希腊语中是船长的意思。我们可以从这个单词中得到 Cybernetic 和 Gubernatorial 这两个词组。Kubernetes 项目专注于构建一个健壮的平台，用于在生产环境中运行数千个容器。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nwxzqi7vj20qo0hsgxn.jpg" alt="">&lt;/p>
&lt;p>“我是 Phippy。”小应用程序说。&lt;/p>
&lt;p>“很高兴认识你。”船长一边说，一边在她身上贴上了一张标有姓名的标签。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwygks8xj20qo0hs0zy.jpg" alt="">&lt;/p>
&lt;p>Kubernetes 使用标签作为“名牌”来标识事物。它可以根据这些标签进行查询。标签是开放性的：你可以用他们来表示角色、稳定性或其他重要的属性。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwyt7gtqj20qo0hsdso.jpg" alt="">&lt;/p>
&lt;p>船长建议应用程序把她的容器搬到船上的一个船舱中。Phippy 很高兴地把她的容器搬到 Kube 船长巨轮的船舱内。Phippy 觉得这里像家一样。&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nwzc5uqej20qo0hswlp.jpg" alt="">&lt;/p>
&lt;p>在 Kubernetes 中，Pod 代表一个可运行的工作单元。通常，你会在 Pod 中运行一个容器。但是对于一些容器紧密耦合的情况，你可以选择在同一个 Pod 中运行多个容器。Kubernetes 负责将你的 Pod 和网络以及 Kubernetes 的其余环境相连。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nwztzwfsj20qo0hsqdi.jpg" alt="">&lt;/p>
&lt;p>Phippy 有一些不同寻常的兴趣，她很喜欢遗传学和绵羊。所以她问船长：“如果我想克隆我自己，是否可以根据需求克隆任意次数呢？”&lt;/p>
&lt;p>“这很容易。”船长说。船长把 Phippy 介绍给了 Replication Controller。&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g4nx08r8toj20qo0hsdnl.jpg" alt="">&lt;/p>
&lt;p>Replication Controller 提供一种管理任意数量 Pod 的方法。一个 Replication Controller 包含一个 Pod 模板，该模板可以被复制任意次数。通过 Replication Controller，Kubernetes 将管理 Pod 的生命周期，包括伸缩、滚动更新和监控。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nx0phj56j20qo0hsnb3.jpg" alt="">&lt;/p>
&lt;p>无数个日夜，小应用程序在她的船舱中与她的复制品相处十分愉快。但与自己为伍并没有所说的那么好……即使你拥有 N 个自己的克隆体。
Kube 船长慈祥地笑了笑：“我正好有一样东西。”
他刚开口，在 Phippy 的 Replication Controller 和船的其他部分之间打开了一条隧道。Kube 船长笑着说：“即使你的复制品来了又去，这条隧道始终会留在这里，你可以通过它发现其他 Pod，其他 Pod 也可以发现你！”&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g4nx160hjkj20qo0hsjyp.jpg" alt="">&lt;/p>
&lt;p>服务告知 Kubernetes 环境的其余部分（包括其他 Pod 和 Replication Controller）你的应用程序包含了哪些服务，当 Pod 来来往往，服务的 IP 地址和端口始终保持不变。其他应用程序可以通过 Kurbenetes 服务发现找到你的服务。&lt;/p>
&lt;p>&lt;img src="https://wx2.sinaimg.cn/large/ad5fbf65gy1g4nx1kbahcj20qo0hsk2e.jpg" alt="">&lt;/p>
&lt;p>多亏了这些服务，Phippy 开始探索船的其他部分。不久之后，Phippy 遇到了 Goldie。他们成了最好的朋友。有一天，Goldie 做了一件不同寻常的事。她送给 Phippy 一件礼物。Phippy 看了礼物一眼，悲伤的泪水夺眶而出。
“你为什么这么伤心呢？”Goldie 问道。
“我喜欢这个礼物，但我没有地方可以放它！”Phippy 抽噎道。
但 Goldie 知道该怎么做。“为什么不把它放入卷中呢？”&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g4nx2ibi95j20qo0hsdnp.jpg" alt="">&lt;/p>
&lt;p>卷表示容器可以访问和存储信息的位置。对于应用程序，卷显示为本地文件系统的一部分。但卷可以由本地存储、Ceph、Gluster、持久性块存储，以及其他存储后端支持。
Phippy 喜欢在 Kube 船长的船上生活，她很享受来自新朋友的陪伴（Goldie 的每个克隆人都同样令人愉悦）。但是，当她回想起在可怕的主机度过的日子，她想知道她是否也可以拥有一点自己的隐私。
“这听起来像是你所需要的，”Kube 船长说，“这是一个命名空间。”&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g4nx2nyz4uj20qo0hs10l.jpg" alt="">&lt;/p>
&lt;p>命名空间是 Kubernetes 内部的分组机制。服务、Pod、Replication Controller 和卷可以在命名空间内部轻松协作，但命名空间提供了与集群其他部分一定程度的隔离。
Phippy 与她的新朋友一起乘坐 Kube 船长的巨轮航行于大海之上。她经历了许多伟大的冒险，但最重要的是，Phippy 找到了自己的家。
所以 Phippy 从此过上了幸福的生活。&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g4nx34vepkj21120shwek.jpg" alt="">&lt;/p></description></item><item><title>Post: 由一封邮件看 Mailing List 在开源项目中的重要性</title><link>https://guoxudong.io/post/kubernetes-client-python/</link><pubDate>Thu, 04 Jul 2019 09:16:41 +0800</pubDate><guid>https://guoxudong.io/post/kubernetes-client-python/</guid><description>
&lt;blockquote>
&lt;p>只要仔细找，想要的轮子总会有的。
&amp;mdash; 某不知名 DevOps 工程师&lt;/p>
&lt;/blockquote>
&lt;p>感谢 &lt;code>kubernetes-dev&lt;/code> 的 Mailing List ！早上在浏览邮件时发现了下面这封有趣的邮件：&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4nkmrb8scj21780q0afv.jpg" alt="image">&lt;/p>
&lt;p>接触 Kubernetes 也有不短的时间了，也见证了 Kubernetes 干掉 Swarm 和 Mesos 成为容器编排领域的事实标准的过程。在享受 Kubernetes 及其生态圈带来的便利的同时也在为 Kubernetes 及 CNCF 项目进行贡献。而使用 &lt;a href="https://github.com/kubernetes/kubectl">&lt;code>kubectl&lt;/code>&lt;/a>、&lt;a href="https://github.com/rancher/rancher">&lt;code>rancher&lt;/code>&lt;/a> 甚至是 &lt;a href="https://github.com/IBM/kui">&lt;code>kui&lt;/code>&lt;/a> 这些 CLI 和 UI 工具对 Kubernetes 集群进行操作和观察。&lt;/p>
&lt;p>虽然上面这些工具为操作 Kubernetes 集群带来了极大的便利，但是归根到底还是一些开源项目，并不能满足我们的全部需求。所以我们只能根据我们自己的需求和 Kubernetes 的 api-server 进行定制，但是由于 Kubernetes 的 api-server 比较复杂，短时间内并不是那么好梳理的。&lt;/p>
&lt;h2 id="kubernetes-clientpython">kubernetes-client/python&lt;/h2>
&lt;p>由于我们自研的 DevOps 平台是使用 python 开发的，所以我也基于 python 语言开发了一套 Kubernetes Client ，但总的来说由于 Kubernetes 的功能实在太多，而我的开发实践并不是很多，开发出来的功能只是差强人意。&lt;/p>
&lt;p>而 &lt;a href="https://github.com/kubernetes-client/python">&lt;code>kubernetes-client/python&lt;/code>&lt;/a> 这个官方给出的轮子是真的香！&lt;/p>
&lt;h3 id="安装方便">安装方便&lt;/h3>
&lt;p>这个安装方式简单的令人发指，支持的 python 版本为 &lt;code>2.7 | 3.4 | 3.5 | 3.6 | 3.7&lt;/code> 并且和所有 python 依赖包一样，只需要使用 &lt;code>pip&lt;/code> 安装即可：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">pip install kubernetes
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="简单示例">简单示例&lt;/h3>
&lt;p>查看所有的 pod ：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#999;font-style:italic">#!/usr/bin/env python&lt;/span>
&lt;span style="color:#999;font-style:italic">#encoding: utf-8&lt;/span>
&lt;span style="color:#999;font-style:italic">#Author: guoxudong&lt;/span>
&lt;span style="color:#6ab825;font-weight:bold">from&lt;/span> &lt;span style="color:#447fcf;text-decoration:underline">kubernetes&lt;/span> &lt;span style="color:#6ab825;font-weight:bold">import&lt;/span> client, config
&lt;span style="color:#999;font-style:italic"># Configs can be set in Configuration class directly or using helper utility&lt;/span>
config.load_kube_config()
v1 = client.CoreV1Api()
&lt;span style="color:#6ab825;font-weight:bold">print&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;Listing pods with their IPs:&amp;#34;&lt;/span>)
ret = v1.list_pod_for_all_namespaces(watch=False)
&lt;span style="color:#6ab825;font-weight:bold">for&lt;/span> i &lt;span style="color:#6ab825;font-weight:bold">in&lt;/span> ret.items:
&lt;span style="color:#6ab825;font-weight:bold">print&lt;/span>(&lt;span style="color:#ed9d13">&amp;#34;&lt;/span>&lt;span style="color:#ed9d13">%s&lt;/span>&lt;span style="color:#ed9d13">\t&lt;/span>&lt;span style="color:#ed9d13">%s&lt;/span>&lt;span style="color:#ed9d13">\t&lt;/span>&lt;span style="color:#ed9d13">%s&lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&lt;/span> % (i.status.pod_ip, i.metadata.namespace, i.metadata.name))
&lt;/code>&lt;/pre>&lt;/div>&lt;p>运行查看结果：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">Listing pods &lt;span style="color:#6ab825;font-weight:bold">with&lt;/span> their IPs:
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">1.126&lt;/span> kube-system coredns-&lt;span style="color:#3677a9">5975&lt;/span>fdf55b-bqgkx
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">0.2&lt;/span> kube-system coredns-&lt;span style="color:#3677a9">5975&lt;/span>fdf55b-vxbb4
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.13&lt;/span> kube-system flexvolume-&lt;span style="color:#3677a9">9&lt;/span>ccf7
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.15&lt;/span> kube-system flexvolume-h5xn2
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.14&lt;/span> kube-system flexvolume-kvn5x
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.17&lt;/span> kube-system flexvolume-mf4zv
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.14&lt;/span> kube-system kube-proxy-worker-&lt;span style="color:#3677a9">7&lt;/span>lpfz
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.15&lt;/span> kube-system kube-proxy-worker-&lt;span style="color:#3677a9">9&lt;/span>wd9s
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.17&lt;/span> kube-system kube-proxy-worker-phbbj
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.13&lt;/span> kube-system kube-proxy-worker-pst5d
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">1.9&lt;/span> kube-system metrics-server-&lt;span style="color:#3677a9">78&lt;/span>b597d5bf-wdvqh
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">1.12&lt;/span> kube-system nginx-ingress-controller-&lt;span style="color:#3677a9">796&lt;/span>ccc5d76-&lt;span style="color:#3677a9">9j&lt;/span>h5s
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">1.125&lt;/span> kube-system nginx-ingress-controller-&lt;span style="color:#3677a9">796&lt;/span>ccc5d76-jwwwz
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.17&lt;/span> kube-system terway-&lt;span style="color:#3677a9">6&lt;/span>mfs8
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.14&lt;/span> kube-system terway-fz9ck
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.13&lt;/span> kube-system terway-t9777
&lt;span style="color:#3677a9">10.16&lt;/span>.&lt;span style="color:#3677a9">16.15&lt;/span> kube-system terway-xbxlp
&lt;span style="color:#3677a9">172.22&lt;/span>.&lt;span style="color:#3677a9">1.8&lt;/span> kube-system tiller-deploy-&lt;span style="color:#3677a9">5&lt;/span>b5d8dd754-wpcrc
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>果然是一个好轮子，引入 kubeconfig 的方式及展示所有 namespace 的 pod 的方法封装的也十分简洁，是个非常漂亮的范例。建议可以看一下&lt;a href="https://github.com/kubernetes-client/python">源码&lt;/a>，肯定会有收获的！&lt;/p>
&lt;h3 id="支持版本">支持版本&lt;/h3>
&lt;p>&lt;code>client-python&lt;/code> 遵循 &lt;a href="https://semver.org/lang/zh-CN/">semver&lt;/a> 规范，所以在 &lt;code>client-python&lt;/code> 的主要版本增加之前，代码将继续使用明确支持的 Kubernetes 集群版本。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>Kubernetes 1.5&lt;/th>
&lt;th>Kubernetes 1.6&lt;/th>
&lt;th>Kubernetes 1.7&lt;/th>
&lt;th>Kubernetes 1.8&lt;/th>
&lt;th>Kubernetes 1.9&lt;/th>
&lt;th>Kubernetes 1.10&lt;/th>
&lt;th>Kubernetes 1.11&lt;/th>
&lt;th>Kubernetes 1.12&lt;/th>
&lt;th>Kubernetes 1.13&lt;/th>
&lt;th>Kubernetes 1.14&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>client-python 1.0&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 2.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 3.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 4.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 5.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 6.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 7.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 8.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 9.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;td>-&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python 10.0&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>client-python HEAD&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>+&lt;/td>
&lt;td>✓&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="mailing-list-的重要性">Mailing List 的重要性&lt;/h2>
&lt;p>这次的收获很大程度得益于 &lt;code>kubernetes-dev&lt;/code> 的 Mailing List 也就是邮件列表。这种沟通方式在国内不是很流行，大家更喜欢使用 QQ 和微信这样的即时通讯软件进行交流，但是大多数著名开源项目都是主要使用 &lt;strong>Mailing List&lt;/strong> 进行交流，交流的数量甚至比在 GitHub issue 中还多，在与 Apache 、 CNCF 项目开源的贡献者和维护者交流中得知了使用 &lt;strong>Mailing List&lt;/strong> 主要考虑是一下几点：&lt;/p>
&lt;ul>
&lt;li>这种异步的交流方式可以让更多关心该话题的开发人员一起加入到讨论中。&lt;/li>
&lt;li>mailing list 是永久保留的，如果你对某个话题感兴趣，可以随时回复邮件，关注这个话题的开发者都会收到邮件，无论这个话题是昨天提出的，还是去年提出的，有助于解决一些陈年老 BUG （俗称技术债）。&lt;/li>
&lt;li>即时通讯软件虽然很便利，但是问题很快会被评论顶掉，虽然诸如 slack 这样的工具解决了部分这方面的问题，但是还是不如 mailing list 好用。&lt;/li>
&lt;li>并不是所有地区的开发者都有高速的宽带，性能优秀的PC，在地球上很多地区还是只能使用拨号上网，网速只有几kb/s，他们甚至 GitHub issue 都无法使用。但是你不能剥夺他们参与开源项目的权利，而 mailing list 是一种很好的交流方式。&lt;/li>
&lt;li>通过 mailing list 可以很好掌握社区动态，效果明显好于 GitHub watch ，因为并不是项目的所有 commit 都是你关心的。&lt;/li>
&lt;/ul>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>如果你有志于参与到开源运动，在享受开源软件带来便利的同事，还想为开源软件做出自己的贡献，那么 mailing list 是你进入社区最好的选择。在 mailing list 中和来自世界各地志同道合的开发者交流中提升自己的能力，创造更大的价值，迈出你参与开源运动的第一步。&lt;/p></description></item><item><title>Post: 使用 Kustomize 帮你管理 kubernetes 应用（五）：配合 kubedog 完善 CI/CD 的最后一步</title><link>https://guoxudong.io/post/kustomize-5/</link><pubDate>Wed, 03 Jul 2019 15:20:31 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-5/</guid><description>
&lt;blockquote>
&lt;p>在以往的 pipeline 中，使用 kubectl 进行部署 Deployment 后无法检查 Deployment 是否部署成功，只能通过使用命令/脚本来手动检查 Deployment 状态，而 kubedog 这个小工具完美解决了这个问题，完善了 CI/CD 流水线的最后一步。&lt;/p>
&lt;/blockquote>
&lt;h2 id="kubedog">KubeDog&lt;/h2>
&lt;p>kubedog 是一个 lib 库和 CLI 小工具，允许在 CI/CD 部署 pipeline 中观察和跟踪 Kubernetes 资源。与 kustomize 配合，集成到 pipeline 之后，完美的解决了 CI/CD 的最后一步，完美的替代了之前不够灵活的脚本（好吧，其实我也开发了类似的小工具，但是有这么好用的轮子，拿来直接用何乐而不为呢？）。&lt;/p>
&lt;p>kubedog 提供了 lib 库和 CLI 小工具，这里由于是介绍 CI/CD 中的实践，所以只介绍其中的 &lt;code>rollout track&lt;/code> 功能。 lib 库的使用和 CLI 的 &lt;code>follow&lt;/code> 功能这里就不做介绍了，有兴趣的同学可以去 &lt;a href="https://github.com/flant/kubedog">GitHub&lt;/a> 上查看该项目的各种使用方式。&lt;/p>
&lt;h3 id="集成-kubedog">集成 KubeDog&lt;/h3>
&lt;p>由于我司目前使用的是 &lt;a href="https://drone.io/">drone&lt;/a> 进行 CI ，每个 step 都是由一个 docker 制作的插件组成。我制作了一个包含 &lt;code>kubectl&lt;/code> 、 &lt;code>kustomize&lt;/code> 和 &lt;code>kubedog&lt;/code> 的镜像。该镜像已上传 dockerhub ，需要的可以自行拉取使用 &lt;code>guoxudongdocker/kubectl&lt;/code> ,而该插件的使用也在 &lt;a href="https://github.com/sunny0826/kubectl-kustomize">GitHub&lt;/a> 和 &lt;a href="https://cloud.docker.com/u/guoxudongdocker/repository/docker/guoxudongdocker/kubectl">DockerHub&lt;/a> 上查看。&lt;/p>
&lt;p>而集成方式也比较简单，直接将 &lt;code>kubectl&lt;/code> 、 &lt;code>kustomize&lt;/code> 和 &lt;code>kubedog&lt;/code> 的可执行包下载到 &lt;code>/usr/local/bin&lt;/code> 并赋予执行权限即可，下面就是 &lt;code>Dockerfile&lt;/code> 文件：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span style="color:#6ab825;font-weight:bold">FROM&lt;/span>&lt;span style="color:#ed9d13"> alpine&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">LABEL&lt;/span> &lt;span style="color:#40ffff">maintainer&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;sunnydog0826@gmail.com&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ENV&lt;/span> &lt;span style="color:#40ffff">KUBE_LATEST_VERSION&lt;/span>=&lt;span style="color:#ed9d13">&amp;#34;v1.14.1&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">RUN&lt;/span> apk add --update ca-certificates &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; apk add --update -t deps curl &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; curl -L https://storage.googleapis.com/kubernetes-release/release/&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">KUBE_LATEST_VERSION&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>/bin/linux/amd64/kubectl -o /usr/local/bin/kubectl &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubectl &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; curl -L https://github.com/kubernetes-sigs/kustomize/releases/download/v2.0.3/kustomize_2.0.3_linux_amd64 -o /usr/local/bin/kustomize &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; chmod +x /usr/local/bin/kustomize &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; curl -L https://dl.bintray.com/flant/kubedog/v0.2.0/kubedog-linux-amd64-v0.2.0 -o /usr/local/bin/kubedog &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; chmod +x /usr/local/bin/kubedog &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; apk del --purge deps &lt;span style="color:#ed9d13">\
&lt;/span>&lt;span style="color:#ed9d13">&lt;/span> &amp;amp;&amp;amp; rm /var/cache/apk/*&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">WORKDIR&lt;/span>&lt;span style="color:#ed9d13"> /root&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ENTRYPOINT&lt;/span> [&lt;span style="color:#ed9d13">&amp;#34;kubectl&amp;#34;&lt;/span>]&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">CMD&lt;/span> [&lt;span style="color:#ed9d13">&amp;#34;help&amp;#34;&lt;/span>]&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="kustomize-配合-kubedog-使用">Kustomize 配合 KubeDog 使用&lt;/h2>
&lt;p>在镜像构建好之后就可以直接使用了，这里使用的是 DockerHub 的镜像仓库，这里建议将镜像同步到私有仓库，比如阿里云的容器镜像服务或者 Habor ，因为国内拉取 DockerHub 的镜像不太稳定，经常会拉取镜像失败或者访问超时，在 CI/CD 流水线中推荐使用更稳定镜像。&lt;/p>
&lt;p>以下是 &lt;code>.drone.yml&lt;/code> 示例：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>pipeline&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>{your-pipeline-name}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">steps&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>Kubernetes 部署&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>guoxudongdocker/kubectl&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>kube&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/root/.kube&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">commands&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- cd deploy/overlays/dev &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 这里使用 kustomize ,详细使用方法请见 https://github.com/kubernetes-sigs/kustomize&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- kubectl apply -k . &amp;amp;&amp;amp; kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">...&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>kube&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">host&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/tmp/cache/.kube &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># kubeconfig 挂载位置&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">trigger&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">branch&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- master &lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># 触发 CI 的分支&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>从上面的配置可见，在该 step 中执行了如下几步：&lt;/p>
&lt;ol>
&lt;li>进入 patch 所在路径&lt;/li>
&lt;li>使用了 Kustomize 命令 &lt;code>kustomize edit set image {your-docker-registry}:${DRONE_BUILD_NUMBER}&lt;/code> 方式将前面 step 中构建好的镜像的 tag 插入到 patch 中&lt;/li>
&lt;li>使用 &lt;code>kubectl apply -k .&lt;/code> 进行 k8s 部署，要注意最后的那个 &lt;code>.&lt;/code>&lt;/li>
&lt;li>使用 kubedog 跟踪 Deployment 部署状态&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>命令解析：&lt;code>kubedog rollout track deployment {your-deployment-name} -n {your-namespace} -t {your-tomeout}&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>deployment {your-deployment-name} : Deployment 的名称&lt;/li>
&lt;li>-n {your-namespace} : Deployment 所在的 namespace&lt;/li>
&lt;li>-t {your-tomeout} : 超时时间，单位为秒，超时后会报错，这里请根据实际部署情况进行设置&lt;/li>
&lt;/ul>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>从 Kubernetes release v1.14 版本开始，&lt;code>kustomize&lt;/code> 集成到 &lt;code>kubectl&lt;/code> 中，越来越多 k8S 周边的小工具出现。这些小工具的出现帮助了 Kubernetes 的使用者来拉平 Kubernetes 的使用曲线，同时也标志着 K8S 的成熟，越来越多的开发人员基于使用 K8S 的痛点开发相关工具。套用一句今年 KubeCon 的 Keynote 演讲上，阿里云智能容器平台负责人丁宇的话： &lt;strong>Kubernetes 正当时，云原生未来可期&lt;/strong> 。&lt;/p></description></item><item><title>Post: 记一次使用 Kustomize 时遇到的愚蠢问题</title><link>https://guoxudong.io/post/kustomize-err-1/</link><pubDate>Wed, 03 Jul 2019 13:44:50 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-err-1/</guid><description>
&lt;h2 id="现象">现象&lt;/h2>
&lt;p>在日常 CI/CD 流程中，已经将 Kustomize 集成到 pipeline 中使用，但是在对一个项目进行 Kustomize 改造时，将单个 &lt;code>deploy.yaml&lt;/code> 拆分为了若干个 patch 以达到灵活 Kubernetes 部署的目的。但是在使用 &lt;code>kubectl apply -k .&lt;/code> 命令进行部署的时候遇到了 &lt;code>error: failed to find an object with apps_v1_Deployment|myapp to apply the patch&lt;/code> 的报错。&lt;/p>
&lt;p>&lt;img src="http://tva2.sinaimg.cn/large/ad5fbf65gy1g4mm1m3vx9j21oe10y102.jpg" alt="image">&lt;/p>
&lt;h2 id="解决之路">解决之路&lt;/h2>
&lt;p>由于之前的使用中没有遇到此类报错，看报错信息像是 &lt;code>apiVersion&lt;/code> 的问题，所以先检查了所有 patch 的 &lt;code>apiVersion&lt;/code> ，但是并没有找到有什么问题。&lt;/p>
&lt;h3 id="google-搜索">Google 搜索&lt;/h3>
&lt;p>对该报错进行了搜索，搜索到如下结果：&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g4mmee8ctxj21900ns44c.jpg" alt="image">
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g4mmgrdz0fj21ou1b6wro.jpg" alt="image">&lt;/p>
&lt;p>？？？ 为何这个 issue 没有解决就被提出者关闭了？&lt;/p>
&lt;h3 id="问题解决">问题解决&lt;/h3>
&lt;p>在 Google 了一圈之后还是没有找到什么有营养的回答，问题又回到了原点&amp;hellip;只能对所有的 patch 的每个字符和每个配置逐一进行了检查。结果发现是 &lt;code>name&lt;/code> 的内容 base 与 overlays 不同&amp;hellip; base 中是 &lt;code>name:myapp&lt;/code> ，而 overlays 中是 &lt;code>name:my-app&lt;/code> &amp;hellip;&lt;/p>
&lt;p>好吧，issue 关的是有道理的&amp;hellip;&lt;/p>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65gy1g4mmuqm6n2j2098048a9z.jpg" alt="">&lt;/p></description></item><item><title>Post: 使用 Kustomize 帮你管理 kubernetes 应用（四）：简述核心配置 kustomization.yaml</title><link>https://guoxudong.io/post/kustomize-4/</link><pubDate>Thu, 23 May 2019 12:50:12 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-4/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>在前面的文章中已经介绍了 kustomize 是什么，以及如何开始使用和如何简单的在 CI/CD 中使用，本篇文章将会介绍 kustomize 的核心文件 &lt;a href="https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml">kustomization.yaml&lt;/a>。&lt;/p>
&lt;p>另外，博主已经向 kustomize 贡献了中文文档，已被官方采纳，现在在 kustomize 中的 &lt;a href="https://github.com/kubernetes-sigs/kustomize/tree/master/docs/zh">&lt;code>docs/zh&lt;/code>&lt;/a> 目录中就可看到，翻译的不好的地方欢迎指正。同时也在 GitHub 上新建了一个 名为 &lt;a href="https://github.com/sunny0826/kustomize-lab">kustomize-lab&lt;/a> 的 repo 用于演示 kustomize 的各种用法及技巧，本文中介绍的内容也会同步更新到该 repo 中，欢迎 fork、star、PR。&lt;/p>
&lt;h2 id="kustomizationyaml-的作用">&lt;code>kustomization.yaml&lt;/code> 的作用&lt;/h2>
&lt;blockquote>
&lt;p>Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。&lt;/p>
&lt;/blockquote>
&lt;p>有前面的文章&lt;a href="../kustomize-2">《使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法》&lt;/a>中已经介绍了，每个 &lt;code>base&lt;/code> 或 &lt;code>overlays&lt;/code> 中都必须要有一个 &lt;code>kustomization.yaml&lt;/code>，这里我们看一下官方示例 &lt;code>helloWorld&lt;/code> 中的 &lt;code>kustomization.yaml&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="color:#6ab825;font-weight:bold">commonLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- deployment.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- service.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- configMap.yaml&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到该项目中包含3个 resources ， &lt;code>deployment.yaml&lt;/code>、&lt;code>service.yaml&lt;/code> 、 &lt;code>configMap.yaml&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">.
└── helloWorld
├── configMap.yaml
├── deployment.yaml
├── kustomization.yaml
└── service.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>直接执行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build helloWorld
&lt;/code>&lt;/pre>&lt;/div>&lt;p>就可以看到结果了：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">data&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">altGreeting&lt;/span>:&lt;span style="color:#666"> &lt;/span>Good Morning!&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">enableRisky&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;false&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>ConfigMap&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-map&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">caption&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;Image from: [**Pexels**](https://www.pexels.com)&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">focal_point&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">preview_only&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Service&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-service&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">8666&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">protocol&lt;/span>:&lt;span style="color:#666"> &lt;/span>TCP&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">8080&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deployment&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>LoadBalancer&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">caption&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;Image from: [**Pexels**](https://www.pexels.com)&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">focal_point&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">preview_only&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">3&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">template&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">deployment&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">command&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- /hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- --port=8080&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- --enableRiskyFeature=$(ENABLE_RISKY)&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>ALT_GREETING&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">valueFrom&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">configMapKeyRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">key&lt;/span>:&lt;span style="color:#666"> &lt;/span>altGreeting&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-map&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>ENABLE_RISKY&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">valueFrom&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">configMapKeyRef&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">key&lt;/span>:&lt;span style="color:#666"> &lt;/span>enableRisky&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-map&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>monopole/hello:1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-container&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">8080&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>从上面的结果可以看大 kustomize 通过 &lt;code>kustomization.yaml&lt;/code> 将3个 resources 进行了处理，给三个 resources 添加了共同的 labels &lt;code>app: hello&lt;/code> 。这个示例展示了 &lt;code>kustomization.yaml&lt;/code> 的作用：&lt;strong>将不同的 resources 进行整合，同时为他们加上相同的配置&lt;/strong>。&lt;/p>
&lt;h2 id="进阶使用">进阶使用&lt;/h2>
&lt;p>上面只不过是一个简单的示例，下面将结合实际情况分享一些比较实用的用法&lt;/p>
&lt;h3 id="根据环境生成不同配置">根据环境生成不同配置&lt;/h3>
&lt;p>在实际的使用中，使用最多的就是为不同的环境配置不同的 &lt;code>deploy.yaml&lt;/code>，而使用 kustomize 可以把配置拆分为多个小的 patch ，然后通过 kustomize 来进行组合。而根据环境的不同，每个 patch 都可能不同，包括分配的资源、访问的方式、部署的节点都可以自由的定制。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">.
├── flask-env
│ ├── README.md
│ ├── base
│ │ ├── deployment.yaml
│ │ ├── kustomization.yaml
│ │ └── service.yaml
│ └── overlays
│ ├── dev
│ │ ├── healthcheck_patch.yaml
│ │ ├── kustomization.yaml
│ │ └── memorylimit_patch.yaml
│ └── prod
│ ├── healthcheck_patch.yaml
│ ├── kustomization.yaml
│ └── memorylimit_patch.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里可以看到配置分为了 &lt;code>base&lt;/code> 和 &lt;code>overlays&lt;/code>， &lt;code>overlays&lt;/code> 则是继承了 &lt;code>base&lt;/code> 的配置，同时添加了诸如 healthcheck 和 memorylimit 等不同的配置，那么我们分别看一下 &lt;code>base&lt;/code> 和 &lt;code>overlays&lt;/code> 中 &lt;code>kustomization.yaml&lt;/code> 的内容&lt;/p>
&lt;ul>
&lt;li>base&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="color:#6ab825;font-weight:bold">commonLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- service.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- deployment.yaml&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>base&lt;/code> 中的 &lt;code>kustomization.yaml&lt;/code> 中定义了一些基础配置&lt;/p>
&lt;ul>
&lt;li>overlays&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="color:#6ab825;font-weight:bold">bases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- ../../base&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">patchesStrategicMerge&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- healthcheck_patch.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- memorylimit_patch.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>devops-dev&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>overlays&lt;/code> 中的 &lt;code>kustomization.yaml&lt;/code> 则是基于 &lt;code>base&lt;/code> 新增了一些个性化的配置，来达到生成不同环境的目的。&lt;/p>
&lt;p>执行命令&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build flask-env/overlays/dev
&lt;/code>&lt;/pre>&lt;/div>&lt;p>结果&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Service&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>devops-dev&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>http&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>ClusterIP&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">caption&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;Image from: [**Pexels**](https://www.pexels.com)&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">focal_point&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">preview_only&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">false&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#447fcf;text-decoration:underline">---&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>devops-dev&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">template&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">version&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">0.0.3&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>ENV&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">value&lt;/span>:&lt;span style="color:#666"> &lt;/span>dev&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>guoxudongdocker/flask-python:latest&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>Always&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">livenessProbe&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">httpGet&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">initialDelaySeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">periodSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">successThreshold&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeoutSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">20&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>test-cicd&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">readinessProbe&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">httpGet&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">initialDelaySeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">periodSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">successThreshold&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">timeoutSeconds&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">20&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">limits&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#666"> &lt;/span>300m&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">memory&lt;/span>:&lt;span style="color:#666"> &lt;/span>500Mi&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">requests&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#666"> &lt;/span>300m&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">memory&lt;/span>:&lt;span style="color:#666"> &lt;/span>500Mi&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/etc/localtime&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>host-time&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">imagePullSecrets&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>registry-pull-secret&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">hostPath&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/etc/localtime&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>host-time&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到包括 &lt;code>replicas&lt;/code>、&lt;code>limits&lt;/code>、&lt;code>requests&lt;/code>、&lt;code>env&lt;/code> 等 dev 中个性的配置都已经出现在了生成的 yaml 中。由于篇幅有限，这里没有把所有的配置有罗列出来，需要的可以去 &lt;a href="https://github.com/sunny0826/kustomize-lab">GitHub&lt;/a> 上自取。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>上面所有的 &lt;code>kustomize build dir/&lt;/code> 都可以使用 &lt;code>kubectl apply -k dir/&lt;/code> 实现，但是需要 &lt;code>v14.0&lt;/code> 版以上的 &lt;code>kubectl&lt;/code>，也就是说，其实我们在集成到 CI/CD 中的时候，甚至都不需要用来 &lt;code>kustomize&lt;/code> 命令集，有 &lt;code>kubectl&lt;/code> 就够了。&lt;/p>
&lt;p>由于篇幅有限，这里没法吧所有 &lt;code>kustomization.yaml&lt;/code> 的用途都罗列出来，不过可以在官方文档中找到我提交的中文翻译版 &lt;a href="https://github.com/kubernetes-sigs/kustomize/blob/master/docs/zh/kustomization.yaml">&lt;code>kustomization.yaml&lt;/code>&lt;/a>，可以直接去官方 GitHub 查看。同时 &lt;a href="https://github.com/sunny0826/kustomize-lab">kustomize-lab&lt;/a> 会持续更行，敬请关注。&lt;/p></description></item><item><title>Post: 使用 Kustomize 帮你管理 kubernetes 应用（三）：将 Kustomize 应用于 CI/CD</title><link>https://guoxudong.io/post/kustomize-3/</link><pubDate>Mon, 06 May 2019 16:46:28 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-3/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>首先明确软件版本，我这里使用的是 &lt;code>Jenkins ver. 2.121.3&lt;/code> ，这个版本比较老，其上安装 Kubernetes 插件所使用 &lt;code>kubectl&lt;/code> 版本也比较老，&lt;strong>无法使用&lt;/strong> Kustomize 的 yaml 文件需要的 &lt;code>apiVersion: apps/v1&lt;/code> ，直接使用生成 &lt;code>deploy.yaml&lt;/code> 文件会报错，所以这里选择了自己构建一个包含 &lt;code>kubectl&lt;/code> 和 &lt;code>kustomize&lt;/code> 的镜像，在镜像中使用 Kustomize 生成所需 yaml 文件并在 Kubernetes 上部署。&lt;/p>
&lt;h2 id="软件版本">软件版本&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>软件&lt;/th>
&lt;th>版本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Jenkins&lt;/td>
&lt;td>&lt;a href="https://jenkins.io/">2.121.3&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kubectl&lt;/td>
&lt;td>&lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">v1.14.1&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kustomize&lt;/td>
&lt;td>&lt;a href="https://github.com/kubernetes-sigs/kustomize/releases">v2.0.3&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="前期准备">前期准备&lt;/h2>
&lt;ul>
&lt;li>Jenkins ：本篇使用 Jenkins 演示 CI/CD ，安装 Jenkins 就不在赘述，可以使用多种方法安装 Jenkins ，详细方法见&lt;a href="https://jenkins.io">官网&lt;/a>。同时。 CI/CD 的工具有很多，这里为了省事使用笔者现有的 Jenkins 进行演示，&lt;strong>不推荐&lt;/strong>使用同笔者一样的版本，请使用较新的版本；同时也可以使用其他 CI/CD 工具，这里推荐使用 &lt;a href="https://drone.io/">drone&lt;/a>。如果有更好的方案，欢迎交流，可以在&lt;a href="https://blog.maoxianplay.com/contact/">关于&lt;/a>中找到我的联系方式。&lt;/li>
&lt;li>&lt;code>kubectl&lt;/code> &amp;amp; &lt;code>kustomize&lt;/code> ：上文中提到了由于 Jenkins 版本比较老，所以这里笔者自己制作了包含二者的 docker 镜像，已上传 dockerhub ，需要自取： &lt;a href="https://hub.docker.com/r/guoxudongdocker/kubectl">&lt;code>guoxudongdocker/kubectl&lt;/code>&lt;/a>&lt;/li>
&lt;li>Web 应用：这里使用 flask 写了一个简单的 web 应用，用于演示，同样以上传 dockerhub &lt;a href="https://hub.docker.com/r/guoxudongdocker/flask-python">&lt;code>guoxudongdocker/flask-python&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="目录结构">目录结构&lt;/h2>
&lt;p>首先看一下目录结构，目录中包括 &lt;code>Dockerfile&lt;/code> 、 &lt;code>Jenkinsfile&lt;/code> 、 Kustomize 要使用的 &lt;code>deploy&lt;/code> 目录以及 web 应用目录。&lt;/p>
&lt;pre>&lt;code class="language-bush" data-lang="bush">.
├── Dockerfile
├── Jenkinsfile
├── app
│ ├── main.py
│ └── uwsgi.ini
└── deploy
├── base
│ ├── deployment.yaml
│ ├── kustomization.yaml
│ └── service.yaml
└── overlays
├── dev
│ ├── healthcheck_patch.yaml
│ ├── kustomization.yaml
│ └── memorylimit_patch.yaml
└── prod
├── healthcheck_patch.yaml
├── kustomization.yaml
└── memorylimit_patch.yaml
&lt;/code>&lt;/pre>&lt;p>这里可以看到 overlays 总共有两个子目录 &lt;code>dev&lt;/code> 和 &lt;code>prod&lt;/code> ，分别代表不同环境，在不同的环境中，应用不同的配置。&lt;/p>
&lt;h2 id="jenkins-配置">Jenkins 配置&lt;/h2>
&lt;p>Jenkins 的配置相对简单，只需要新建一个 pipeline 类型的 job&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g2rr57oixbj20tn0ogq6v.jpg" alt="WX20190506-180159">&lt;/p>
&lt;p>增加参数化构建，&lt;strong>注&lt;/strong>：参数化构建需要安装 Jenkins 插件&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g2rrcb5ic9j21470q7mz8.jpg" alt="WX20190506-180918">&lt;/p>
&lt;p>然后配置代码仓库即可&lt;/p>
&lt;p>&lt;img src="https://ws3.sinaimg.cn/large/ad5fbf65gy1g2sij1xlb2j214w0nw0uw.jpg" alt="WX20190507-094958">&lt;/p>
&lt;h2 id="pipeline">Pipeline&lt;/h2>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-groovy" data-lang="groovy">podTemplate(label: &lt;span style="color:#ed9d13">&amp;#39;jnlp-slave&amp;#39;&lt;/span>, cloud: &lt;span style="color:#ed9d13">&amp;#39;kubernetes&amp;#39;&lt;/span>,
containers: [
containerTemplate(
name: &lt;span style="color:#ed9d13">&amp;#39;jnlp&amp;#39;&lt;/span>,
image: &lt;span style="color:#ed9d13">&amp;#39;guoxudongdocker/jenkins-slave&amp;#39;&lt;/span>,
alwaysPullImage: &lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>
),
containerTemplate(name: &lt;span style="color:#ed9d13">&amp;#39;kubectl&amp;#39;&lt;/span>, image: &lt;span style="color:#ed9d13">&amp;#39;guoxudongdocker/kubectl:v1.14.1&amp;#39;&lt;/span>, command: &lt;span style="color:#ed9d13">&amp;#39;cat&amp;#39;&lt;/span>, ttyEnabled: &lt;span style="color:#6ab825;font-weight:bold">true&lt;/span>),
],
nodeSelector:&lt;span style="color:#ed9d13">&amp;#39;ci=jenkins&amp;#39;&lt;/span>,
volumes: [
hostPathVolume(mountPath: &lt;span style="color:#ed9d13">&amp;#39;/var/run/docker.sock&amp;#39;&lt;/span>, hostPath: &lt;span style="color:#ed9d13">&amp;#39;/var/run/docker.sock&amp;#39;&lt;/span>),
hostPathVolume(mountPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/bin/docker&amp;#39;&lt;/span>, hostPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/bin/docker&amp;#39;&lt;/span>),
hostPathVolume(mountPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/local/jdk&amp;#39;&lt;/span>, hostPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/local/jdk&amp;#39;&lt;/span>),
hostPathVolume(mountPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/local/maven&amp;#39;&lt;/span>, hostPath: &lt;span style="color:#ed9d13">&amp;#39;/usr/local/maven&amp;#39;&lt;/span>),
secretVolume(mountPath: &lt;span style="color:#ed9d13">&amp;#39;/home/jenkins/.kube&amp;#39;&lt;/span>, secretName: &lt;span style="color:#ed9d13">&amp;#39;devops-ctl&amp;#39;&lt;/span>),
],
)
{
node(&lt;span style="color:#ed9d13">&amp;#34;jnlp-slave&amp;#34;&lt;/span>){
stage(&lt;span style="color:#ed9d13">&amp;#39;Git Checkout&amp;#39;&lt;/span>){
git branch: &lt;span style="color:#ed9d13">&amp;#39;${branch}&amp;#39;&lt;/span>, url: &lt;span style="color:#ed9d13">&amp;#39;https://github.com/sunny0826/flask-python.git&amp;#39;&lt;/span>
}
stage(&lt;span style="color:#ed9d13">&amp;#39;Build and Push Image&amp;#39;&lt;/span>){
withCredentials([usernamePassword(credentialsId: &lt;span style="color:#ed9d13">&amp;#39;docker-register&amp;#39;&lt;/span>, passwordVariable: &lt;span style="color:#ed9d13">&amp;#39;dockerPassword&amp;#39;&lt;/span>, usernameVariable: &lt;span style="color:#ed9d13">&amp;#39;dockerUser&amp;#39;&lt;/span>)]) {
sh &lt;span style="color:#ed9d13">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span style="color:#ed9d13"> docker login -u ${dockerUser} -p ${dockerPassword}
&lt;/span>&lt;span style="color:#ed9d13"> docker build -t guoxudongdocker/flask-python:${Tag} .
&lt;/span>&lt;span style="color:#ed9d13"> docker push guoxudongdocker/flask-python:${Tag}
&lt;/span>&lt;span style="color:#ed9d13"> &amp;#39;&amp;#39;&amp;#39;&lt;/span>
}
}
stage(&lt;span style="color:#ed9d13">&amp;#39;Deploy to K8s&amp;#39;&lt;/span>){
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> (&lt;span style="color:#ed9d13">&amp;#39;true&amp;#39;&lt;/span> == &lt;span style="color:#ed9d13">&amp;#34;${deploy}&amp;#34;&lt;/span>) {
container(&lt;span style="color:#ed9d13">&amp;#39;kubectl&amp;#39;&lt;/span>) {
sh &lt;span style="color:#ed9d13">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span style="color:#ed9d13"> cd deploy/base
&lt;/span>&lt;span style="color:#ed9d13"> kustomize edit set image guoxudongdocker/flask-python:${Tag}
&lt;/span>&lt;span style="color:#ed9d13"> &amp;#39;&amp;#39;&amp;#39;&lt;/span>
echo &lt;span style="color:#ed9d13">&amp;#34;部署到 Kubernetes&amp;#34;&lt;/span>
&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> (&lt;span style="color:#ed9d13">&amp;#39;prod&amp;#39;&lt;/span> == &lt;span style="color:#ed9d13">&amp;#34;${ENV}&amp;#34;&lt;/span>) {
sh &lt;span style="color:#ed9d13">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span style="color:#ed9d13"> # kustomize build deploy/overlays/prod | kubectl apply -f -
&lt;/span>&lt;span style="color:#ed9d13"> kubectl applt -k deploy/overlays/prod
&lt;/span>&lt;span style="color:#ed9d13"> &amp;#39;&amp;#39;&amp;#39;&lt;/span>
}&lt;span style="color:#6ab825;font-weight:bold">else&lt;/span> {
sh &lt;span style="color:#ed9d13">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;span style="color:#ed9d13"> # kustomize build deploy/overlays/dev | kubectl apply -f -
&lt;/span>&lt;span style="color:#ed9d13"> kubectl applt -k deploy/overlays/dev
&lt;/span>&lt;span style="color:#ed9d13"> &amp;#39;&amp;#39;&amp;#39;&lt;/span>
}
}
}&lt;span style="color:#6ab825;font-weight:bold">else&lt;/span>{
echo &lt;span style="color:#ed9d13">&amp;#34;跳过Deploy to K8s&amp;#34;&lt;/span>
}
}
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里要注意几点：&lt;/p>
&lt;ul>
&lt;li>拉取 git 中的代码需要在 jenkins 中配置凭据。&lt;/li>
&lt;li>笔者的 jenkins 部署在 Kubernetes 上，要操作集群的话，需要将 kubeconfig 以 Secret 的形式挂载到 jenkins 所在 namespace。&lt;/li>
&lt;li>&lt;code>jenkins-slave&lt;/code> 需要 Java 环境运行，所以要将宿主机的 &lt;code>jdk&lt;/code> 挂载到 &lt;code>jenkins-slave&lt;/code> 中。&lt;/li>
&lt;li>同样的，宿主机中需要事先安装 &lt;code>docker&lt;/code>。&lt;/li>
&lt;li>&lt;code>docker-register&lt;/code> 为 dockerhub 的登录凭证，需要在 jenkins 中添加相应的凭证。&lt;/li>
&lt;/ul>
&lt;h2 id="演示">演示&lt;/h2>
&lt;h2 id="preview_only-false">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;h3 id="开始构建">开始构建&lt;/h3>
&lt;p>这里选择环境、分支，填入版本即可开始构建，**注意：**这里的版本将已 tag 的形式标记 docker 镜像。&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65gy1g2sikst7tuj20ob0evabw.jpg" alt="WX20190507-095142">&lt;/p>
&lt;p>这里就可以看到构建成功了&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sjw9w22ej20v80km0w3.jpg" alt="WX20190507-103721">&lt;/p>
&lt;h3 id="查看结果">查看结果&lt;/h3>
&lt;p>这里为了方便（其实就是懒），我就不给这个服务添加 ingress 来从外部访问了，这里使用 &lt;a href="https://yq.aliyun.com/articles/690519">KT&lt;/a> 打通本地和 k8s 集群网络来进行调试。&lt;/p>
&lt;blockquote>
&lt;p>为了简化在Kubernetes下进行联调测试的复杂度，云效在SSH隧道网络的基础上并结合Kubernetes特性构建了一款面向开发者的辅助工具kt&lt;/p>
&lt;/blockquote>
&lt;p>这里看到这个服务正常启动了&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/large/ad5fbf65ly1g2sk11dnzxj20av027jrn.jpg" alt="WX20190507-104154">&lt;/p>
&lt;h3 id="发布新版本">发布新版本&lt;/h3>
&lt;p>更新 web 服务并提交&lt;/p>
&lt;p>&lt;img src="https://ws4.sinaimg.cn/large/ad5fbf65gy1g2sk94v1c5j209702vwej.jpg" alt="WX20190507-104936">&lt;/p>
&lt;p>按照上面步骤在 jenkins 中重新构建，当然也可以配置钩子，每次代码提交后自动构建&lt;/p>
&lt;h3 id="查看查看新版本">查看查看新版本&lt;/h3>
&lt;p>同上面一样，在构建成功后查看服务是否更新&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g2skfczaz4j20by01smx7.jpg" alt="WX20190507-105539">&lt;/p>
&lt;p>可以看到，版本已经更新了&lt;/p>
&lt;h3 id="发布生产环境">发布生产环境&lt;/h3>
&lt;p>这里模拟一下发布生产环境，假设生产环境是在 &lt;code>devops-prod&lt;/code> 的 namespace 中，这里只做演示之用，真正的生产环境中，可能存在不止一个 k8s 集群，这时需要修改 Jenkinsfile 中的 &lt;code>secretVolume&lt;/code> 来挂载不同 k8s 的 kubeconfig 来达到发布到不同集群的目的。当然，一般发布生产环境只需选择测试通过的镜像来发布即可，不需要在进行构建打包。&lt;/p>
&lt;p>&lt;img src="https://ws3.sinaimg.cn/large/ad5fbf65gy1g2skrnbjyuj20fc0bjmxp.jpg" alt="WX20190507-110730">&lt;/p>
&lt;h3 id="查看生产版本">查看生产版本&lt;/h3>
&lt;p>&lt;img src="https://tva2.sinaimg.cn/large/ad5fbf65ly1g2skt3rp4yj20aq010glj.jpg" alt="WX20190507-110850">&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>上面的这些步骤简单的演示了使用 jenkins 进行 CI/CD 的流程，流程十分简单，这里仅供参考&lt;/p>
&lt;h2 id="kustomize-的作用">Kustomize 的作用&lt;/h2>
&lt;p>那么， Kustomize 在整个流程中又扮演了一个什么角色呢？&lt;/p>
&lt;h3 id="更新镜像">更新镜像&lt;/h3>
&lt;p>在 &lt;code>jenkinsfile&lt;/code> 中可以看到， kustomize 更新了基础配置的镜像版本，这里我们之前一直是使用 &lt;code>sed -i &amp;quot;s/#Tag/${Tag}/g&amp;quot; deploy.yaml&lt;/code> 来进行替换了，但是不同环境存在比较多的差异，需要替换的越来越多，导致 Jekninsfile 也越来越臃肿和难以维护。 kustomize 解决了这个问题。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize edit &lt;span style="color:#24909d">set&lt;/span> image guoxudongdocker/flask-python:&lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">Tag&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="环境区分">环境区分&lt;/h3>
&lt;p>上面也提到了，不同的环境我们存在这许多差异，虽然看上去大致类似，但是很多细节都需要修改。这时 kustomize 就起到了很大的作用，不同环境相同的配置都放在 &lt;code>base&lt;/code> 中，而差异就可以在 &lt;code>overlays&lt;/code> 中实现。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">.
├── base
│ ├── deployment.yaml
│ ├── kustomization.yaml
│ └── service.yaml
└── overlays
├── dev
│ ├── healthcheck_patch.yaml
│ ├── kustomization.yaml
│ └── memorylimit_patch.yaml
└── prod
├── healthcheck_patch.yaml
├── kustomization.yaml
└── memorylimit_patch.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到， &lt;code>base&lt;/code> 中维护了项目共同的基础配置，如果有镜像版本等基础配置需要修改，可以使用 &lt;code>kustomize edit set image ...&lt;/code> 来直接修改基础配置，而真正不同环境，或者不同使用情况的配置则在 &lt;code>overlays&lt;/code> 中 以 patch 的形式添加配置。这里我的配置是 prod 环境部署的副本为2，同时给到的资源也更多，详情可以在 &lt;a href="https://github.com/sunny0826/flask-python">Github&lt;/a> 上查看。&lt;/p>
&lt;h3 id="与-kubectl-的集成">与 kubectl 的集成&lt;/h3>
&lt;p>在 jenkinsfile 中可以看到&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#999;font-style:italic"># kustomize build deploy/overlays/dev | kubectl apply -f -&lt;/span>
kubectl apply -k deploy/overlays/dev
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这两条命令的执行效果是一样的，在 &lt;code>kubectl v1.14.0&lt;/code> 以上的版本中，已经集成了 kustomize ，可以直接使用 &lt;code>kubectl&lt;/code> 进行部署。&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>这里只是对 kustomize 在 CI/CD 中简单应用的展示，只是一种比较简单和基础的使用，真正的 CI 流程要比这个复杂的多，这里只是为了演示 kustomize 的使用而临时搭建的。而 kustomize 还有很多黑科技的用法，将会在后续的文章中介绍。&lt;/p></description></item><item><title>Post: 4月29日 云栖社区分享PPT -- 阿里云容器服务的优势与调优</title><link>https://guoxudong.io/post/aliyun-share/</link><pubDate>Tue, 30 Apr 2019 18:46:24 +0800</pubDate><guid>https://guoxudong.io/post/aliyun-share/</guid><description>
&lt;p>该PPT 为 2019年4月26日 在云栖社区分享使用，这里留作展示和记录，下载地址可以参考下方链接。&lt;/p>
&lt;iframe src="https://guoxudong.io/aliyun-share/index.html" style="width: 100%;height:600px;" frameborder="0">&lt;/iframe>
&lt;p>由于图片资源位于 GitHub 上，国内访问可能会有些慢，建议下载观看。&lt;/p>
&lt;p>PPT 下载地址：https://yq.aliyun.com/articles/700084&lt;/p></description></item><item><title>Post: 8分钟入门 K8S</title><link>https://guoxudong.io/post/an-8-minute-introduction-to-k8s/</link><pubDate>Tue, 30 Apr 2019 13:38:12 +0800</pubDate><guid>https://guoxudong.io/post/an-8-minute-introduction-to-k8s/</guid><description>
&lt;blockquote>
&lt;p>读完 &lt;a href="https://www.amazon.com/Kubernetes-Running-Dive-Future-Infrastructure/dp/1491935677">Kubernetes: Up and Running&lt;/a> 后，我写下了这篇文章。旨在为那些认为文章 &lt;a href="https://blog.maoxianplay.com/posts/cant/">TL;DR&lt;/a> 的人进行一些总结，这同时也是一种强迫自己检查所阅读内容的好方法。&lt;/p>
&lt;/blockquote>
&lt;p>基于 Google &lt;a href="https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/">Borg&lt;/a> 的开源系统 K8S( Kubernetes ) 是一个非常强大的容器编排调度系统。 其整个生态系统，包括：工具，模块，附加组件等，都是使用 Golang 语言编写的，这使得 K8S 及其周边生态系统基本上是面向 API 对象、运行速度非常快的二进制文件的集合，并且这些二进制文件都有很好的文档记录，易于编写和构建应用程序。&lt;/p>
&lt;p>在深入了解之前，我想先介绍一下 K8S 的竞争对手：ECS 、 Nomad 和 Mesos 。ECS 是 AWS 自己的业务编排解决方案，而最近 AWS 上也引入了一个托管的 K8S 系统 &amp;ndash; EKS 。两者都提供 &lt;a href="https://aws.amazon.com/fargate/">FARGATE&lt;/a> ，允许用户运行其应用并忽略其运行物理资源。&lt;/p>
&lt;p>K8S 作为一个开源系统，在采用量上毫无疑问是最大赢家，同时它也可以以托管形式在三个主要云提供商上提供服务。然而，它比其他系统更加复杂。K8S 可以处理几乎任何类型的容器化工作负载，但这并不意味着每个人都需要它。用户也可以选择其他解决方案，例如，单独部署在 AWS 上的互联网产品可以在生产环境很好的使用 ECS 而非 K8S。&lt;/p>
&lt;p>话虽如此，k8s也有其神奇之处 &amp;ndash; 它可以在任何地方部署，同时拥有一个活跃的社区和数百个核心开发人员，以及其广泛生态系统中的数千个其他开源贡献者。它快速、新颖、模块化和面向 API ，使其成为对于构建插件和服务非常友好的系统。&lt;/p>
&lt;h2 id="话不多说这里把-k8s-分为的11个部分介绍">话不多说，这里把 K8S 分为的11个部分介绍&lt;/h2>
&lt;h3 id="1-pods">1. Pods&lt;/h3>
&lt;p>&lt;strong>Pods&lt;/strong> 是 K8S 中创建或部署的最小基本单位。一个 pod 可以由多个容器组成，这些容器将形成一个部署在单个节点上的单元。一个 pod 包含一个容器之间共享的 IP。在微服务中， pod 将是执行某些后端工作或提供传入请求的微服务的单个实例。&lt;/p>
&lt;h3 id="2-nodes">2. Nodes&lt;/h3>
&lt;p>&lt;strong>Node&lt;/strong> 就是服务器。它们是 K8S 部署其 pod 的“裸机”（也可以是虚拟机）。Nodes 为 K8S 提供可用的群集资源，以保持数据，运行作业，维护工作负载和创建网络路由。&lt;/p>
&lt;h3 id="3-labels--annotations">3. Labels &amp;amp; Annotations&lt;/h3>
&lt;p>&lt;strong>Labels&lt;/strong> 是 K8S 及其终端用户过滤和筛选系统中类似资源的方式，也是一个资源需要“访问”或与另一个资源关联的粘合剂。例如：一个 Service 想要开放 Deployment 的端口。无论是监控，记录，日志，测试，任何k8s资源都应添加 Labels 以供进一步检查。例如： &lt;code>app=worker&lt;/code> ，一个给系统中所有工作 pod 的标签，稍后可以使用 &lt;code>kubectl&lt;/code> 工具或 k8s api 使用 &lt;code>--selector&lt;/code> 字段进行选择。&lt;/p>
&lt;p>&lt;strong>Annotations&lt;/strong> 与 Labels 非常类似，但是它通常以字符串的形式用于存储元数据，但他不能用于标识和选择对象，通常也不会被 Kubernetes 直接使用，其主要目的是方便工具或用户的阅读和查找等。&lt;/p>
&lt;h3 id="4-服务发现">4. 服务发现&lt;/h3>
&lt;p>作为编排调度器，控制不同工作负载的资源，K8S 管理 pods 、jobs 和其他任何需要网络通信的物理资源。 K8S 使用 &lt;a href="https://kubernetes.io/docs/concepts/overview/components/#etcd">etcd&lt;/a> 管理这些。 etcd 是 K8S 的“内部”数据库， Master 节点使用它来知道一切资源都在哪里。K8S 还为您的服务提供了实时的 “服务发现” - 所有 Pod 都使用的自定义 DNS 服务（CoreDNS），您可以通过解析其他服务的名称来获取其 IP 地址和端口。它不需要任何设置，在 K8S 集群中“开箱即用”。&lt;/p>
&lt;h3 id="5-replicasets">5. ReplicaSets&lt;/h3>
&lt;p>虽然 pod 运行任务，但通常单个实例是不够的。出于对冗余和负载处理的考虑，需要进行复制容器，即“弹性缩放”。K8S 使用 &lt;strong>ReplicaSet&lt;/strong> 来实现伸缩扩展。根据副本的数量来表示系统的期望状态，并且在任何给定时刻保持系统的当前状态。&lt;/p>
&lt;p>这也是配置自动扩展的地方，在系统负载高时创建新的副本，以及在不再需要这些资源来支持运行工作负载时减少扩展。简单的讲就是：少则增加，多增删除。&lt;/p>
&lt;h3 id="6-daemonsets">6. DaemonSets&lt;/h3>
&lt;p>有时，某些应用程序在每个节点上只需要一个实例。最好的例子就是像 &lt;a href="https://www.elastic.co/products/beats/filebeat">FileBeat&lt;/a> 这样的日志采集组件。为了让 agent 从节点上收集日志，它需要运行在所有节点上，但只需要一个实例即可。为了创建满足上面需求的的工作负载，K8S 使用 &lt;strong>DaemonSets&lt;/strong> 来完成这个工作。&lt;/p>
&lt;h3 id="7-statefulsets">7. StatefulSets&lt;/h3>
&lt;p>虽然大多数微服务都是无状态的应用程序，但是还是有一部分并不是。有状态的工作负载需要由某种可靠的磁盘卷来支持。虽然应用程序容器本身可以是不变的，并且可以用更新的版本或更健康的实例来替换它们，但是即使使用其他副本也是需要持久化的数据。为此，&lt;strong>StatefulSets&lt;/strong> 允许部署整个生命周期内需要运行在同一节点的应用程序。它还保留了它的 “名称” ; 容器内的 &lt;code>hostname&lt;/code> 和整个集群中服务发现的名称。一个包含3个 ZooKeeper 的 StatefulSet 可以命名为 &lt;code>zk-1&lt;/code> ，&lt;code>zk-2&lt;/code> 和 &lt;code>zk-3&lt;/code> 还可以扩展为包含其他成员，如 &lt;code>zk-4&lt;/code> ， &lt;code>zk-5&lt;/code> 等&amp;hellip; StatefulSets 还需要管理 PVC 。&lt;/p>
&lt;h3 id="8-jobs">8. Jobs&lt;/h3>
&lt;p>K8S 核心团队考察了绝大多数需要使用编排系统的应用程序。虽然大多数应用程序需要持续的正常运行时间来处理服务请求，例如 Web 服务，但有时也需要运行批量任务并在任务完成后进行清理。如果您愿意，可以使用小型无服务器环境。而在 K8S 中实现这一功能，可以使用 &lt;strong>Job&lt;/strong> 资源。Jobs 正是听起来的那样，一个工作负载容器来完成特定的工作，并在成功后被销毁。一个很好的例子是设置一组 worker ，从要处理和存储的队列中读取任务。一旦队列为空，直到下一批准备好进行处理，都不再需要启动 worker。&lt;/p>
&lt;h3 id="9-configmaps--secrets">9. ConfigMaps &amp;amp; Secrets&lt;/h3>
&lt;p>如果您还不熟悉 &lt;a href="https://12factor.net/">Twelve-Factor App manifest&lt;/a> 《&lt;a href="../12-factor">十二要素应用&lt;/a>》 ，可以点击链接了解一下。现代应用程序的一个关键概念是无环境，可通过注入的环境变量进行配置。应用程序应完全与其所在位置无关。&lt;strong>ConfigMaps&lt;/strong> 在 K8S 中实现这一重要概念。其本质上是环境变量的 key-value 列表，这些变量被传递给正在运行的工作负载以确定不同的 runtime 行为。&lt;/p>
&lt;p>&lt;strong>Secrets&lt;/strong> 与 &lt;strong>ConfigMaps&lt;/strong> 类似，通过加密的方式防止密钥、密码、证书等敏感信息泄漏。&lt;/p>
&lt;blockquote>
&lt;p>我个人认为在任何系统上使用密码的最佳选择是 Hashicorp 的 Vault 。请务必阅读我去年写的关于它的&lt;a href="https://medium.com/prodopsio/security-for-dummies-protecting-application-secrets-made-easy-5ef3f8b748f7">文章&lt;/a>，关于 Vault 可以为你的产品提供的功能，以及我的一位同事写的另一篇更具技术性的[文章](&lt;a href="https://medium.com/prodopsio/taking-your-hashicorp-vault-to-the-next-level-8549e7988b24">https://medium.com/prodopsio/taking-your-hashicorp-vault-to-the-next-level-8549e7988b24&lt;/a>）。&lt;/p>
&lt;/blockquote>
&lt;h3 id="10-deployments">10. Deployments&lt;/h3>
&lt;p>为了使新版本快速替换原有的应用程序，我们希望将构建、测试和发布在一块来实现 &lt;a href="https://www.ibm.com/developerworks/community/blogs/beingagile/entry/short_feedback_loops_everywhere?lang=en">short feedback loops&lt;/a> 。K8S 使用 Deployments 来不断部署新软件，Deployments 是一组用来描述特定运行工作负载的元数据。例如：发布新版本，bug 修复，甚至是回滚（这是k8s的另一个内部选项）。&lt;/p>
&lt;p>在 K8S 中部署软件有两个主要__策略__：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Replacement&lt;/strong>：将使用新副本替换您的整个工作负载，整个过程需要强制停机。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RollingUpdate&lt;/strong>：k8s通过两种特定配置来实现使用新的 Pods 实例滚动更新：&lt;/p>
&lt;ol>
&lt;li>&lt;code>MaxAvailable&lt;/code> ： 该设置表示在部署新版本时可用的工作负载的百分比（或确切数量），100％表示“我有2个容器，保持2个存活并在整个部署期间正常提供服务”。&lt;/li>
&lt;li>&lt;code>MaxSurge&lt;/code> ： 该设置表示升级期间总 Pod 数最多可以超出期望的百分比（或数量），100％表示“我有 X 个容器，再部署 X 个容器，然后开始推出旧容器”。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="11-storage">11. Storage&lt;/h3>
&lt;p>K8S 在存储上添加了一层抽象，工作负载可以为不同的任务请求特定的存储，甚至可以管理持续的时间可以超过某个pod的生命周期。为了简短起见，我想向您介绍我最近发布的关于k8s存储的&lt;a href="https://medium.com/prodopsio/k8s-will-not-solve-your-storage-problems-5bda2e6180b5">文章&lt;/a>，特别是为什么它不能完全解决数据库部署等数据持久性要求。&lt;/p>
&lt;h2 id="概念性理解">概念性理解&lt;/h2>
&lt;p>K8S 是根据一些指导方向设计和开发的，考虑到社区的性质，每个特征、概念和想法都被内置于系统中。此外，终端用户会以某种方式使用该系统，作为一个开源和免费的系统，不属于任何人，你可以用它做任何你想要做的事。&lt;/p>
&lt;p>面向 API ：系统中的每个部分都以一种可通过记录良好且可操作的 API 进行交互的方式进行构建。核心开发人员确保作为终端用户的您可以进行更改，查询和更新，用来提供更好的用户体验。&lt;/p>
&lt;p>工具友好 ： 作为上面一点的衍生，K8S 是热衷于在其 API 周围创建工具的。它将自身做为一个原始平台，以可定制的方式构建，以供其他人使用，并进一步开发用于不同的工具。有些已经变得非常有名并被广泛使用，如 Spinnaker ，Istio 和许多其他功工具。&lt;/p>
&lt;p>声明性状态 ： 鼓励用户使用具有声明性描述的系统而不是命令式描述。这意味着系统的状态和组件最好被描述为在某种版本控制（如 git ）中管理的代码，而不会因为某一处手动更改也对整体有影响。这样，k8s更容易&lt;a href="https://en.wikipedia.org/wiki/Disaster_recovery">灾难恢复&lt;/a> ，易于在团队之间分享和传递。&lt;/p>
&lt;h2 id="最后">最后&lt;/h2>
&lt;p>本文试图将重点放在 K8S 的介绍和主要概念上，当然，K8S 还有其他非常重要的领域，比如物理系统构建模块，如 &lt;code>kubelet&lt;/code>， &lt;code>kube-proxy&lt;/code> ， &lt;code>api-server&lt;/code> 和终端操作工具：&lt;code>kubectl&lt;/code>。我将在下一篇文章中讨论以及介绍这些很酷的功能。&lt;/p>
&lt;p>原文地址： &lt;a href="https://medium.com/prodopsio/an-8-minute-introduction-to-k8s-94fda1fa5184">https://medium.com/prodopsio/an-8-minute-introduction-to-k8s-94fda1fa5184&lt;/a>&lt;/p></description></item><item><title>Post: 阿里云容器服务新建集群优化方案(更新版)</title><link>https://guoxudong.io/post/aliyun-k8s-perfect/</link><pubDate>Thu, 25 Apr 2019 22:26:06 +0800</pubDate><guid>https://guoxudong.io/post/aliyun-k8s-perfect/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>选择阿里云的&lt;code>容器服务&lt;/code>，主要原因是公司主要业务基本都在运行在阿里云上。相较自建 kubernetes 集群，容器服务的优势在于部署相对简单，与阿里云 VPC 完美兼容，网络的配置相对简单，而如果使用 &lt;code>kubeadm&lt;/code> 安装部署 kubernetes 集群，除了众所周知的科学上网的问题，还有一系列的问题，包括 &lt;code>etcd&lt;/code> 、 &lt;code>Scheduler&lt;/code> 和 &lt;code>Controller-Manager&lt;/code> 的高可用问题等。并且如果使用托管版的阿里云 kubernetes 容器服务，还会省掉3台 master 节点的钱，并且可能将 master 节点的运维问题丢给阿里云解决，并且其提供的 master 节点性能肯定会比自购的配置好，这点是阿里云容器服务的研发小哥在来我司交流时专门强调的。&lt;/p>
&lt;h2 id="问题">问题&lt;/h2>
&lt;p>前面吹了阿里云容器服务的优势，那这里就说说在实践中遇到的容器服务的问题：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在新建集群的时候需要选择相应的 VPC 并选择 &lt;code>Pod&lt;/code> 和 &lt;code>Service&lt;/code> 所在的网段，这两个网段不能和 Node 节点存在于同一网段，但是如果您在阿里云中存在不止一个 VPC （VPC的网段可以是 10.0.0.0/8，172.16-31.0.0/12-16，192.168.0.0/16 ），如果网段设置不对的话，就可能会使原本存在该网段的 ECS 失联，需要删除集群重新创建。如果删除失败的话，还需要手动删除路由表中的记录（&lt;strong>别问我是怎么知道的&lt;/strong>）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在使用容器服务创建集群后，会创建2个 SLB （之前是3个），一个是 SLB 是在 VPC 上并且绑定一个弹性IP（需要在创建的时候手动勾选创建弹性IP）用于 API Server，一个是经典网络的 SLB 使用提供给 Ingress 使用。但是这两个外网IP创建后的规格都是默认最大带宽、按流量收费，这个并不符合我们的要求，需要手动修改，&lt;del>然而这个修改都会在第二天才能生效&lt;/del>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>容器服务创建集群后，Node 节点的名称会使&lt;code>{region-id}.{ECS-id}&lt;/code>的形式，这个命名方式在集群监控，使用 &lt;code>kubectl&lt;/code> 操作集群方面就显得比较反人类了，每次都要去查 &lt;code>ECS id&lt;/code> 才能确定是哪个节点，而这个 Node 节点名称是不能修改的！&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="网段问题解决">网段问题解决&lt;/h2>
&lt;p>这个比较好解决，甚至可以说不用解决，只要把网段规划好，不要出现网段冲突就好&lt;/p>
&lt;h2 id="node-节点名称无法修改问题解决">Node 节点名称无法修改问题解决&lt;/h2>
&lt;p>这个功能之前已有人在阿里聆听平台提出这个问题了，咨询了容器服务的研发小哥，得到的反馈是该功能已经在灰度测试了，相信很快就可以上线了。&lt;/p>
&lt;h2 id="创建-slb-规格问题解决">创建 SLB 规格问题解决&lt;/h2>
&lt;p>相较之前自动创建3个 SLB 的方式，目前的版本只会自动创建2个并且有一个是 VPC 内网+弹性IP的方式，已经进行了优化，但是 ingress 绑定的 SLB 还是经典网络类型，无法接入云防火墙并且规格也是不合适的。这里给出解决方案：&lt;/p>
&lt;h3 id="方法一使用-kubectl-配置">方法一：使用 &lt;code>kubectl&lt;/code> 配置&lt;/h3>
&lt;h4 id="1-创建新的-slb">1. 创建新的 SLB&lt;/h4>
&lt;ul>
&lt;li>这里需要创建一个新的 SLB 用来代替自动创建的不符合要求的 SLB。这里可以先私网 SLB 先不绑定弹性IP。&lt;em>&lt;strong>这里要注意的事，新建的 SLB 需要与 k8s集群处于同一 VPC 内，否则在后续会绑定失败&lt;/strong>&lt;/em>。
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1ma5lxgvdj21ws0s6qa5.jpg" alt="image">&lt;/li>
&lt;li>查看新购买 SLB 的 ID
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1ma8zuq1gj20sa0hoq4b.jpg" alt="image">&lt;/li>
&lt;/ul>
&lt;h4 id="2-在创建集群后重新绑定-ingress-controller-的-service">2. 在创建集群后重新绑定 &lt;code>ingress-controller&lt;/code> 的 &lt;code>Service&lt;/code>&lt;/h4>
&lt;p>首先需要使用 &lt;code>kubectl&lt;/code> 或者直接在阿里云控制台操作，创建新的 &lt;code>nginx-ingress-svc&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#999;font-style:italic"># nginx ingress service&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Service&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx-ingress-lb-{new-name}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>kube-system&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx-ingress-lb-{new-name}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># set loadbalancer to the specified slb id&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">service.beta.kubernetes.io/alicloud-loadbalancer-id&lt;/span>:&lt;span style="color:#666"> &lt;/span>{SLB-ID}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># set loadbalancer address type to intranet if using private slb instance&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranet&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">service.beta.kubernetes.io/alicloud-loadbalancer-force-override-listeners&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#39;true&amp;#39;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#service.beta.kubernetes.io/alicloud-loadbalancer-backend-label: node-role.kubernetes.io/ingress=true&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>LoadBalancer&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># do not route traffic to other nodes&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#999;font-style:italic"># and reserve client ip for upstream&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">externalTrafficPolicy&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#ed9d13">&amp;#34;Local&amp;#34;&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>http&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">port&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">443&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>https&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">443&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">selector&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic"># select app=ingress-nginx pods&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>ingress-nginx&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>创建成功后，可以进到 SLB 页面查看，可以看到 &lt;code>80&lt;/code> 和 &lt;code>443&lt;/code> 端口的监听已经被添加了
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1maej57c1j21ru0rwq8b.jpg" alt="image">&lt;/p>
&lt;h4 id="3-绑定符合要求的弹性ip">3. 绑定符合要求的弹性IP&lt;/h4>
&lt;p>确定 SLB 创建成功并且已经成功监听后，这里就可以为 SLB 绑定符合您需求的弹性IP了，这里我们绑定一个按宽带计费2M的弹性IP&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1mak2r0p3j207k07mq33.jpg" alt="image">&lt;/p>
&lt;h4 id="4-验证连通性">4. 验证连通性&lt;/h4>
&lt;p>到上面这步，我们的 ingress 入口 SLB 已经创建完成，这里我们验证一下是否联通。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在k8s集群中部署一个 &lt;code>nginx&lt;/code> ，直接在阿里云容器服务控制台操作即可
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1mant7ec6j21s40qegpr.jpg" alt="image">
这里创建 ingress 路由，&lt;strong>注意：这里的域名需要解析到刚才创建的 SLB 绑定的弹性IP&lt;/strong>
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1maqf7gdjj21ns0kymz8.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>访问该域名，显示 &lt;code>nginx&lt;/code> 欢迎页，则证明修改成功
&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g1mat8srhnj21ak0hmact.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="方法二-使用阿里云容器服务控制台配置">方法二： 使用阿里云容器服务控制台配置&lt;/h3>
&lt;h4 id="1-阿里云容器控制台创建新-service">1. 阿里云容器控制台创建新 &lt;code>service&lt;/code>&lt;/h4>
&lt;ul>
&lt;li>在阿里云容器服务控制台：&lt;code>路由与负载均衡&lt;/code> &amp;ndash;&amp;gt; &lt;code>服务&lt;/code> 点击&lt;code>创建&lt;/code>&lt;/li>
&lt;li>选择 &lt;code>kube-system&lt;/code> 命名空间&lt;/li>
&lt;li>类型选中&lt;code>负载均衡&lt;/code> - &lt;code>内网访问&lt;/code>&lt;/li>
&lt;li>关联 &lt;code>nginx-ingress-controller&lt;/code>&lt;/li>
&lt;li>并添加端口映射&lt;/li>
&lt;li>点击创建&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g2g4fwfgevj20i50hsgmp.jpg" alt="image">&lt;/p>
&lt;h4 id="2-进入负载均衡查看-slb-是否创建">2. 进入负载均衡查看 SLB 是否创建&lt;/h4>
&lt;p>可见 SLB 已经成功创建&lt;/p>
&lt;p>&lt;img src="https://wx4.sinaimg.cn/large/ad5fbf65gy1g2g4pb1d45j215303c74r.jpg" alt="image">&lt;/p>
&lt;h4 id="3-绑定符合要求的弹性ip-1">3. 绑定符合要求的弹性IP&lt;/h4>
&lt;p>同方法一&lt;/p>
&lt;h4 id="4验证连通性">4.验证连通性&lt;/h4>
&lt;p>同方法一&lt;/p>
&lt;h3 id="后续操作">后续操作&lt;/h3>
&lt;ul>
&lt;li>在确定新的 SLB 创建成功后，就可以将容器服务自动创建的 SLB 释放了&lt;/li>
&lt;li>删除 &lt;code>kube-system&lt;/code> 中原本绑定的 &lt;code>Service&lt;/code> &lt;strong>（目前版本已经可以关联删除绑定的 SLB 了，不用分开操作）&lt;/strong>&lt;/li>
&lt;li>&lt;strong>这里别忘了，自动创建给API Server 的SLB还是按流量付费的，记得降配&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="后记">后记&lt;/h2>
&lt;p>上面的这些问题和解决方案都属于临时方案，已在阿里的聆听平台提出了上面的问题，相信很快就会有所改进。总的来说，阿里云容器服务在提供优质的 kubernetes 功能，并且只收 ECS 的钱，对于想学习 kubernetes 又没有太多资金的同学也比较友好，直接买按量付费实例，测试完释放即可，不用购买 master 节点，十分良心！&lt;/p></description></item><item><title>Post: 困难的 Kubernetes</title><link>https://guoxudong.io/post/kubernetes-is-har/</link><pubDate>Wed, 24 Apr 2019 10:18:46 +0800</pubDate><guid>https://guoxudong.io/post/kubernetes-is-har/</guid><description>
&lt;blockquote>
&lt;p>虽然 Kubernetes 赢得了容器之站，但是其仍然很难使用并且时长引起事故。&lt;/p>
&lt;/blockquote>
&lt;p>我想我应该给这篇文章做一点序言。 &lt;a href="https://kubernetes.io/">kubernetes&lt;/a> 为许多应用程序提供新的 runtime ，如果使用得当，它可以成为一个强大的工具，并且可以将您冲复杂的开发生命周期中解放出来。然而在过去的几年里，我看到很多人和公司都会搭建他们的 Kubernetes ，但常常只是处于测试阶段，从未进入到生产。&lt;/p>
&lt;h2 id="kubernetes-是如何运作的">Kubernetes 是如何运作的？&lt;/h2>
&lt;p>粗略的讲， Kubernetes 或者 K8S 看起来十分简单。您运行的 Kubernetes 节点至少被分为两类：Master 和 Workers。Master 节点通常不运行任何真实的工作负载，那是 Workers 节点的工作。&lt;/p>
&lt;p>Kubernetes 的 Master 节点包含一个名叫 API server 的组件，其提供的 API 可以通过 &lt;code>kubectl&lt;/code> 调用。此外还包括一个 scheduler ，负责调度容器，决定容器运行在哪个节点。最后一个组件是 controller-manager ，它实际上是一组多个控制器，负责处理节点中断、复制、加入 services 和 pods ，并且处理授权相关内容。所有的数据都存储在 etcd 中，这是一个可信赖的分布式键值存储服务（包含一些非常酷的功能）。总而言之，Master 节点负责管理集群，这里没什么特别大的惊喜。&lt;/p>
&lt;p>另一方面， 真实的工作负载运行在 Worker 节点上。为此，它还包括许多组件。首先，Worker 节点上会运行 &lt;em>&lt;strong>kubelet&lt;/strong>&lt;/em> ，它是与该节点上的容器一起运行的 API ，负责与管控组件沟通，并按照管控组件指示管理 Worker 节点。另一个组件就是 &lt;em>&lt;strong>kube-proxy&lt;/strong>&lt;/em> ，其负责转发网络连接，根据您的配置运行容器。可能还有其他东西，如 &lt;em>&lt;strong>kube-dns&lt;/strong>&lt;/em> 或 &lt;em>&lt;strong>gVisor&lt;/strong>&lt;/em>。您还需要集成某种 &lt;em>&lt;strong>overlay network&lt;/strong>&lt;/em> 或底层网络设置，以便 Kubernetes 可以管理您的 pod 之间的网络。&lt;/p>
&lt;p>如果您想要一个更完整的概述，建议去看 Kelsey Hightowers 的 &lt;a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes - The Hard Way&lt;/a>。&lt;/p>
&lt;h2 id="生产就绪的-kubernetes">生产就绪的 Kubernetes&lt;/h2>
&lt;p>到目前为止，这听起来并不太糟糕。只是安装几个程序、配置、证书等。不要误会我的意思，这仍然是一个学习曲线，但这也不是系统管理员不能处理的问题。&lt;/p>
&lt;p>然而，简单地手动安装 Kubernetes 并不代表其已经完全准备就绪，所以让我们谈谈让这个东西运行起来所需的步骤。&lt;/p>
&lt;p>首先，&lt;strong>安装&lt;/strong>。如果您想要某种自动安装，无论是使用 Ansible ， Terraform 还是其他工具。&lt;a href="https://github.com/kubernetes/kops">kops&lt;/a> 可以帮助您解决这个问题，但是使用 kops 意味着您将不知道它是如何设置的，并且当您以后想要调试某些东西时可能会引起一些其他问题。应对此自动化进行测试，并定期进行检查。&lt;/p>
&lt;p>其次，您需要&lt;strong>监控&lt;/strong>您的 Kubernetes 安装。所以您需要 &lt;a href="https://prometheus.io/">Prometheus&lt;/a> 、 &lt;a href="https://grafana.com/">Grafana&lt;/a> 等工具。您是在 Kubernetes 里面运行它吗？ 如果您的 Kubernetes 有问题，那么您的监控是否会也会挂掉？ 或者您单独运行它？ 如果是，那么您在哪里运行它？&lt;/p>
&lt;p>另外值得注意的是&lt;strong>备份&lt;/strong>。如果您的 Master 崩溃，数据无法恢复并且您需要重新配置系统上的所有 pod ，您会怎么做？您是否测试了再次运行 CI 系统中所有作业所需的时间？您有灾难恢复计划吗？&lt;/p>
&lt;p>现在，既然我们在谈论 CI 系统，那么您需要为您的镜像运行 Docker 镜像仓库。当然，您可以再次在 Kubernetes 上做，但如果 Kubernetes 崩溃&amp;hellip;&amp;hellip;您知道这个后果。当然，CI 系统与运行版本控制系统都有这个问题。理想情况下，这些系统是与生产环境隔离的，以便在系统出现问题时，至少可以访问 git ，来进行重新部署等操作。&lt;/p>
&lt;h2 id="数据存储">数据存储&lt;/h2>
&lt;p>最后，我们来谈谈最重要的部分：存储。Kubernetes 本身并不提供存储解决方案。当然，您可以将存储挂载到主机安装目录，但这既不推荐也不简单。&lt;/p>
&lt;p>基本上需要在 Kubernetes 下使用某种存储。例如，&lt;a href="https://rook.io/">rook&lt;/a> 使得运行 &lt;a href="https://ceph.com/">Ceph&lt;/a> 作为底层块存储需求的变得相对简单，但我对 Ceph 的体验是它还有有很多地方需要调整，所以您绝不是只需点击下一步就能走出困境。&lt;/p>
&lt;h2 id="调试">调试&lt;/h2>
&lt;p>在与开发人员谈论 Kubernetes 时，一种常见的回答经常出现：在使用 Kubernetes 时，人们常常在调试应用程序时遇到问题。即使是一个例如容器未能启动的简单问题，也会引起混乱。&lt;/p>
&lt;p>当然，这是一个教育问题。在过去的几十年中，开发人员已经学会了调试的“经典”步骤：在 &lt;code>/vat/log/&lt;/code> 中查看日志等。但是对于容器，我们甚至不知道容器运行在哪个服务器上，因此它呈现出了一种范式转换。&lt;/p>
&lt;h2 id="问题复杂">问题：复杂&lt;/h2>
&lt;p>您可能已经注意到我正在跳过共有云提供商给您的东西，即使它不是一个完整的托管 Kubernetes。当然，如果您使用托管的 Kubernetes 解决方案，这很好，除了调试之外，您不需要处理上面这些问题。&lt;/p>
&lt;p>Kubernetes 拥有许多可以移动组件，但 Kubernetes 本身也并不能提供完整的解决方案。例如，&lt;a href="https://www.openshift.com/">RedHat OpenShift&lt;/a> 可以，但它需要花钱，并且仍然需要添加自己的东西。&lt;/p>
&lt;p>现在Kubernetes正处于 &lt;a href="https://www.gartner.com/en/research/methodologies/gartner-hype-cycle">Gartner hype cycle&lt;/a> 的顶峰，每个人都想要它，但很少有人真正理解它。在接下来的几年里，不少公司必须意识到 Kubernetes 并不是银弹，而如何正确有效地使用它才是关键。&lt;/p>
&lt;p>我认为，如果您有能力将 Ops 团队专门用于为开发人员来维护底层平台，那么运行自己的 Kubernetes 是值得的。&lt;/p>
&lt;blockquote>
&lt;p>本文作者：&lt;a href="https://pasztor.at/">Janos Pasztor&lt;/a> 2018-12-04&lt;/p>
&lt;/blockquote>
&lt;p>原文地址：https://pasztor.at/blog/kubernetes-is-hard&lt;/p></description></item><item><title>Post: 使用 Kustomize 帮你管理 kubernetes 应用（二）： Kustomize 的使用方法</title><link>https://guoxudong.io/post/kustomize-2/</link><pubDate>Fri, 19 Apr 2019 16:05:02 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-2/</guid><description>
&lt;p>本文介绍使用和维护 Kustomize 的方法及步骤。&lt;/p>
&lt;h2 id="定制配置">定制配置&lt;/h2>
&lt;p>在这个工作流方式中，所有的配置文件（ YAML 资源）都为用户所有，存在于私有 repo 中。其他人是无法使用的。&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g2813d1ia7j20qo0f0dgk.jpg" alt="">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>创建一个目录用于版本控制&lt;/p>
&lt;p>我们希望将一个名为 &lt;em>&lt;strong>ldap&lt;/strong>&lt;/em> 的 Kubernetes 集群应用的配置保存在自己的 repo 中。
这里使用 &lt;code>git&lt;/code> 进行版本控制。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">git init ~/ldap
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>创建一个 &lt;code>base&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">mkdir -p ~/ldap/base
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在这个目录中创建并提交 &lt;code>kustomization.yaml&lt;/code> 文件和一组资源，例如 &lt;code>deployment.yaml&lt;/code> &lt;code>service.yaml&lt;/code> 等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>创建 &lt;code>overlays&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code>&lt;/pre>&lt;/div>&lt;p>每个目录都需要一个 &lt;code>kustomization.yaml&lt;/code> 文件以及一个或多个 &lt;code>patch&lt;/code> ，例如 &lt;code>healthcheck_patch.yaml&lt;/code> &lt;code>memorylimit_patch.yaml&lt;/code> 等。。&lt;/p>
&lt;p>&lt;code>staging&lt;/code> 目录可能会使用一个 &lt;code>patch&lt;/code> ，用于在 &lt;code>configmap&lt;/code> 增加一个实验配置。&lt;/p>
&lt;p>&lt;code>production&lt;/code> 目录则可能会在 &lt;code>deployment&lt;/code> 中增加在副本数。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>生成 &lt;code>variants&lt;/code>&lt;/p>
&lt;p>运行 &lt;code>kustomize&lt;/code> ，将生成的配置用于 kubernetes 应用部署&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 kubernetes 1.14 版本， &lt;code>kustomize&lt;/code> 已经集成到 &lt;code>kubectl&lt;/code> 命令中，成为了其一个子命令，可使用 &lt;code>kubectl&lt;/code> 来进行部署&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h2 id="使用现成的配置">使用现成的配置&lt;/h2>
&lt;p>在这个工作流方式中，可从别人的 repo 中 fork kustomize 配置，并根据自己的需求来配置。&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g281xyfebej20qo0f0dgr.jpg" alt="">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>通过 fork/modify/rebase 等方式获得配置&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将其克隆为你自己的 &lt;code>base&lt;/code>&lt;/p>
&lt;p>在这个 &lt;code>bash&lt;/code> 目录维护在一个 repo 中，在这个例子使用 &lt;code>ladp&lt;/code> 的 repo&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">mkdir ~/ldap
git clone https://github.com/&lt;span style="color:#40ffff">$USER&lt;/span>/ldap ~/ldap/base
&lt;span style="color:#24909d">cd&lt;/span> ~/ldap/base
git remote add upstream git@github.com:&lt;span style="color:#40ffff">$USER&lt;/span>/ldap
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>创建 &lt;code>overlays&lt;/code>&lt;/p>
&lt;p>如上面的案例一样，创建并完善 &lt;code>overlays&lt;/code> 目录中的内容&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">mkdir -p ~/ldap/overlays/staging
mkdir -p ~/ldap/overlays/production
&lt;/code>&lt;/pre>&lt;/div>&lt;p>用户可以将 &lt;code>overlays&lt;/code> 维护在不同的 repo 中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>生成 &lt;code>variants&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build ~/ldap/overlays/staging | kubectl apply -f -
kustomize build ~/ldap/overlays/production | kubectl apply -f -
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 kubernetes 1.14 版本， &lt;code>kustomize&lt;/code> 已经集成到 &lt;code>kubectl&lt;/code> 命令中，成为了其一个子命令，可使用 &lt;code>kubectl&lt;/code> 来进行部署&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl apply -k ~/ldap/overlays/staging
kubectl apply -k ~/ldap/overlays/production
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>（可选）更新 &lt;code>base&lt;/code>
用户可以定期从上游 repo 中 &lt;code>rebase&lt;/code> 他们的 &lt;code>base&lt;/code> 以保证及时更新&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#24909d">cd&lt;/span> ~/ldap/base
git fetch upstream
git rebase upstream/master
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md">kustomize workflows - github.com&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Post: Rancher 2.2.1 解决工作负载监控为空问题</title><link>https://guoxudong.io/post/rancher-prometheus-fix-question/</link><pubDate>Thu, 18 Apr 2019 17:46:08 +0800</pubDate><guid>https://guoxudong.io/post/rancher-prometheus-fix-question/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Rancher 2.2.X 版本于3月底正式GA，新版本处理其他部分的优化以外，最大亮点莫过于本身集成了 Prometheus ，可以通过 Rancher 自带 UI 或者 Grafana 查看集群的实时监控，对所有监控进行了一次聚合，不用再和之前一样，每个集群都要安装一个 Prometheus 用于监控，而告警部分也可使用 Rancher 自带的通知组件进行告警。通知方式目前支持 Slack 、 邮件、 PagerDuty 、 Webhook 、 企业微信，由于我司办公使用钉钉，所以我们使用了 Webhook 的方式，告警触发后通知我们的消息服务，然后消息服务将其发送到钉钉进行告警。&lt;/p>
&lt;p>&lt;img src="http://wx2.sinaimg.cn/large/ad5fbf65gy1g26xsh6omvj20rk0ilta6.jpg" alt="image">&lt;/p>
&lt;h2 id="问题">问题&lt;/h2>
&lt;p>Rancher 集成 Prometheus 后，监控方面变的十分强大，不用再徘徊于多个集群的 Grafana ，直接在 Rancher 上即可查看，非常方便&lt;/p>
&lt;p>&lt;img src="http://wx2.sinaimg.cn/large/ad5fbf65gy1g26xuv2frnj212b0onn1h.jpg" alt="image">&lt;/p>
&lt;p>但是在使用的时候，我发现了一个问题：就是在查看 工作负载和 Pod 的时候会显示 &lt;em>&lt;strong>没有足够的数据绘制图表&lt;/strong>&lt;/em>&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g26xzvi2cpj20po057q31.jpg" alt="image">&lt;/p>
&lt;p>进入 Grafana 查看会发现，其实监控参数是存在的，但是没有采集到值，所以并没有展示出来。&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g26y4j4s3yj21f50m9wqj.jpg" alt="image">&lt;/p>
&lt;h2 id="解决">解决&lt;/h2>
&lt;p>在检查了配置后并没有找到原因，只好去 GitHub 上提一个 issue 来询问一下开发者或者其他用户有无遇到这个问题。&lt;/p>
&lt;p>Rancher 官方的开发者还是十分负责的， GitHub 上用户名为 &lt;a href="https://github.com/loganhz">Logan&lt;/a> 的官方小哥来我指导解决这个问题。&lt;/p>
&lt;p>小哥发现我是导入的集群，要我进入 Prometheus 查看，发现 &lt;code>cattle-prometheus/exporter-kube-state-cluster-monitoring&lt;/code> 果然没有起来&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g26yb1p4eoj21db0am782.jpg" alt="image">&lt;/p>
&lt;p>解决这个问题，需要在集群监控配置中添加一个高级选项，插入值为：&lt;code>exporter-kubelets.https=false&lt;/code>&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g26ycq6amfj221q0uggp8.jpg" alt="image">&lt;/p>
&lt;p>点击保存，问题就解决了！&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g26yheqwp7j213e0g3di5.jpg" alt="image">&lt;/p>
&lt;h2 id="后记">后记&lt;/h2>
&lt;p>使用 Rancher 有半年，从2.0版本一直用到2.2版本，而18年分别在云栖大会和 KubeCon 上听了 Rancher 创始人梁胜博士的演讲。而从这一个小问题上就可以看到 Rancher 官方对每一个用户都是十分重视的。&lt;/p></description></item><item><title>Post: Kustomize: 无需模板定制你的 kubernetes 配置</title><link>https://guoxudong.io/post/introducing-kustomize-template-free-configuration-customization-for-kubernetes/</link><pubDate>Mon, 15 Apr 2019 17:23:21 +0800</pubDate><guid>https://guoxudong.io/post/introducing-kustomize-template-free-configuration-customization-for-kubernetes/</guid><description>
&lt;blockquote>
&lt;p>作者：Jeff Regan (Google), Phil Wittrock (Google) 2018-05-29&lt;/p>
&lt;/blockquote>
&lt;p>如果你在运行 kubernetes 集群，你可能会拷贝一些包含 kubernetes API 对象的 YAML 文件，并且根据你的需求来修改这些文件，通过这些 YAML 文件来定义你的 kubernetes 配置。&lt;/p>
&lt;p>但是这种方法存在很难找到配置的源头并对其进行改进。今天 Google 宣布推出 &lt;strong>Kustomize&lt;/strong> ，一个作为 &lt;a href="https://github.com/kubernetes/community/tree/master/sig-cli">SIG-CLI&lt;/a> 子项目的命令行工具。这个工具提供了一个全新的、纯粹的声明式的方法来定制 kubernetes 配置，遵循并利用我们熟悉且精心设计的 Kubernetes API。&lt;/p>
&lt;p>有这样一个常见的场景，在互联网上可以看到别人的 CMS（content management system，内容管理系统）的 kubernetes 配置，这个配置是一组包括 Kubernetes API 对象的 YAML 描述文件。然后，在您自己公司的某个角落，您找到一个你非常了解的数据库，希望用它来该 CMS 的数据。&lt;/p>
&lt;p>你希望同时使用它们，此外，你希望自定义配置文件以便你的资源实例在集群中显示，并通过添加一个标签来区分在同一集群中做同样事情的其他资源。同时也希望为其配置适当的 CPU 、内存和副本数。&lt;/p>
&lt;p>此外，你还想要配置整个配置的多种变化：一个专门用于测试和实验的小服务实例（就计算资源而言），或更大的用于对外提供服务的生产级别的服务实例。同时，其他的团队也希望拥有他们自己的服务实例。&lt;/p>
&lt;h2 id="定制就是复用">定制就是复用&lt;/h2>
&lt;p>kubernetes 的配置并不是代码（是使用 YAML 描述的 API 对象，严格来说应该是数据），但是配置的生命周期与代码的生命周期有许多相似之处。&lt;/p>
&lt;p>你需要在版本控制中保留配置。所有者的配置不必与使用者的配置相同。配置可以作为整体的一部分。而用户希望为在不同的情况下复用这些配置。&lt;/p>
&lt;p>与代码复用相同，一种复用配置的方法是简单的全部拷贝并进行自定义。像代码一样，切断与源代码的联系使得从改进变的十分困难。许多团队和环境都使用这种方法，每个团队和环境都拥有自己的配置，这使得简单的升级变得十分棘手。&lt;/p>
&lt;p>另一种复用方法是将源代码抽象为参数化模板。使用一个通过执行脚本来替换所需参数的模板处理工具生成配置，通过为同一模板设置不同的值来达到复用的目的。而这种方式面临的问题是模板和参数文件并不在 kubernetes API 资源的规范中，这种方式必定是一种包装了 kubernetes API 的新东西、新语言。虽然这种方式很强大，但是也带来了学习成本和安装工具的成本。不同的团队需要不同的更改，因此几乎所有可以包含在 YAML 文件中的规范都会需要抽象成参数。&lt;/p>
&lt;h2 id="自定义配置的新选择">自定义配置的新选择&lt;/h2>
&lt;p>&lt;strong>kustomize&lt;/strong> 中工具的声明与规范是由名为 &lt;code>kustomization.yaml&lt;/code> 的文件定义。&lt;/p>
&lt;p>&lt;strong>kustomize&lt;/strong> 将会读取声明文件和 Kubernetes API 资源文件，将其组合然后将完整的资源进行标准化的输出。输出的文本可以被其他工具进一步处理，或者直接通过 &lt;strong>kubectl&lt;/strong> 应用于集群。&lt;/p>
&lt;p>例如，如果 &lt;code>kustomization.yaml&lt;/code> 文件包括：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">commonLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>hello&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">resources&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- deployment.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- configMap.yaml&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- service.yaml&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>确保这三个文件与 &lt;code>kustomization.yaml&lt;/code> 位于同一目录下，然后运行：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build
&lt;/code>&lt;/pre>&lt;/div>&lt;p>将创建包含三个资源的 YAML 流，其中 &lt;code>app: hello&lt;/code> 为每个资源共同的标签。&lt;/p>
&lt;p>同样的，你可以使用 &lt;em>&lt;strong>commonAnnotations&lt;/strong>&lt;/em> 字段给所有资源添加注释， &lt;em>&lt;strong>namePrefix&lt;/strong>&lt;/em> 字段为所有的资源添加共同的前缀名。这些琐碎而有常见的定制只是一个开始。&lt;/p>
&lt;p>一个更常见的例子是，你需要为一组相同资源设置不同的参数。例如：开发、演示和生产的参数。&lt;/p>
&lt;p>为此，&lt;strong>Kustomize&lt;/strong> 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。两者都是由 kustomization 文件表示。基础（Base）声明了共享的内容（资源和常见的资源配置），Overlay 则声明了差异。&lt;/p>
&lt;p>这里是一个目录树，用于管理集群应用程序的 &lt;em>&lt;strong>演示&lt;/strong>&lt;/em> 和 &lt;em>&lt;strong>生产&lt;/strong>&lt;/em> 配置参数：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">someapp/
├── base/
│ ├── kustomization.yaml
│ ├── deployment.yaml
│ ├── configMap.yaml
│ └── service.yaml
└── overlays/
├── production/
│ └── kustomization.yaml
│ ├── replica_count.yaml
└── staging/
├── kustomization.yaml
└── cpu_count.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>&lt;code>someapp/base/kustomization.yaml&lt;/code> 文件指定了公共资源和常见自定义配置（例如，它们一些相同的标签，名称前缀和注释）。&lt;/strong>&lt;/p>
&lt;p>&lt;strong>&lt;code>someapp/overlays/production/kustomization.yaml&lt;/code> 文件的内容可能是：&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">commonLabels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">env&lt;/span>:&lt;span style="color:#666"> &lt;/span>production&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">bases&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- ../../base&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">patches&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>- replica_count.yaml&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个 kustomization 指定了一个 &lt;em>&lt;strong>patch&lt;/strong>&lt;/em> 文件 &lt;code>replica_count.yaml&lt;/code> ，其内容可能是：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>apps/v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>the-deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">100&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>&lt;strong>patch&lt;/strong>&lt;/em> 是部分的资源声明，在这个例子中是 Deployment 的补丁 &lt;code>someapp/base/deployment.yaml&lt;/code> ，仅修改了副本数用以处理生产流量。&lt;/p>
&lt;p>该补丁不仅仅是一个无上下文 {parameter name，value} 元组。其作为部分 deployment spec，可以通过验证，即使与其余配置隔离读取，也具有明确的上下文和用途。&lt;/p>
&lt;p>要为生产环境创建资源，请运行：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kustomize build someapp/overlays/production
&lt;/code>&lt;/pre>&lt;/div>&lt;p>运行结果将作为一组完整资源打印到标准输出，并准备应用于集群。可以用类似的命令定义演示环境的配置。&lt;/p>
&lt;h2 id="综上所述">综上所述&lt;/h2>
&lt;p>使用 &lt;strong>kustomize&lt;/strong> ，您可以仅使用 Kubernetes API 资源文件就可以管理任意数量的 Kubernetes 定制配置。kustomize 的每个产物都是纯 YAML 的，每个都可以进行验证和运行的。&lt;strong>kustomize&lt;/strong> 鼓励通过 fork/modify/rebase 这样的&lt;a href="https://github.com/kubernetes-sigs/kustomize/blob/master/docs/workflows.md">工作流&lt;/a>来管理海量的应用描述文件。&lt;/p>
&lt;p>尝试&lt;a href="https://github.com/kubernetes-sigs/kustomize/tree/master/examples/helloWorld">hello world&lt;/a>示例，开始使用 &lt;strong>kustomize&lt;/strong> 吧！有关的反馈与讨论，可以通过加入&lt;a href="https://groups.google.com/forum/#!forum/kustomize">邮件列表&lt;/a>或提 &lt;a href="https://github.com/kubernetes-sigs/kustomize/issues/new">issue&lt;/a>，欢迎提交PR。&lt;/p>
&lt;h2 id="译者按">译者按&lt;/h2>
&lt;p>随着 kubernetes 1.14 的发布，kustomize 被集成到 &lt;code>kubectl&lt;/code> 中，用户可以利用 &lt;code>kubectl apply -k dir/&lt;/code> 将指定目录的 &lt;code>kustomization.yaml&lt;/code> 提交到集群中。&lt;/p>
&lt;p>&lt;strong>原文链接&lt;/strong> &lt;a href="https://kubernetes.io/blog/2018/05/29/introducing-kustomize-template-free-configuration-customization-for-kubernetes/">https://kubernetes.io/blog/2018/05/29/introducing-kustomize-template-free-configuration-customization-for-kubernetes/&lt;/a>&lt;/p></description></item><item><title>Post: 使用 Kustomize 帮你管理 kubernetes 应用（一）：什么是 Kustomize ？</title><link>https://guoxudong.io/post/kustomize-1/</link><pubDate>Mon, 15 Apr 2019 13:32:59 +0800</pubDate><guid>https://guoxudong.io/post/kustomize-1/</guid><description>
&lt;h2 id="初识-kustomize">初识 Kustomize&lt;/h2>
&lt;p>第一次听说 Kustomize 其实是在 kubernetes 1.14 发布时候，它被集成到 &lt;code>kubectl&lt;/code> 中，成为了一个子命令，但也只是扫了一眼，并没有深究。真正让我注意到它，并主动开始了解其功能和使用方法的，是张磊大神在云栖社区发表的一篇文章&lt;a href="https://yq.aliyun.com/articles/697883">《从Kubernetes 1.14 发布，看技术社区演进方向》&lt;/a>，他在文中是这么说的：&lt;/p>
&lt;blockquote>
&lt;p>Kustomize 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件，而不是像 Helm 那样只提供应用描述文件模板，然后通过字符替换（Templating）的方式来进行定制化。&lt;/p>
&lt;/blockquote>
&lt;p>这不正我在苦苦寻找的东西嘛！自从公司确定了应用容器化的方案，至今已有半年多了，这期间我们的服务一个接一个的实现了容器化，部署到了 kubernetes 集群中。kubernetes 集群也有原先了1个测试集群，几个节点，发展到了如今的多个集群，几十个节点。而在推进容器化的过程中，每个服务都对对应多个应用描述文件（ YAML 文件），而根据环境的不同，又配置了多套的应用描述文件。随着服务越部越多，应用描述文件更是呈爆炸式的增长。&lt;/p>
&lt;p>感谢 devops 文化，它是我不需要为每个应用去写 YAML 文件，各个应用的开发组承担了这一工作，我只需要为他们提供基础模板即可。但应用上线后出现的 OOM 、服务无法拉起等 YAML 文件配置有误导致的问题接踵而至，使得我必须要深入各个服务，为他们配置符合他们配置。虽然也使用了 &lt;code>helm&lt;/code> ，但是其只提供应用描述文件模板，在不同环境拉起一整套服务会节省很多时间，而像我们这种在指定环境快速迭代的服务，并不会减少很多时间。针对这种情况，我已经计划要自己开发一套更符合我们工作这种场景的应用管理服务，集成在我们自己的 devops 平台中。&lt;/p>
&lt;p>这时 Kustomize 出现了，我明锐的感觉到 Kustomize 可能就是解决我现阶段问题的一剂良药。&lt;/p>
&lt;h2 id="什么是-kustomize-">什么是 Kustomize ？&lt;/h2>
&lt;blockquote>
&lt;h4 id="kubernetes-native-configuration-management">Kubernetes native configuration management&lt;/h4>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Kustomize introduces a template-free way to customize application configuration that simplifies the use of off-the-shelf applications. Now, built into &lt;code>kubectl&lt;/code> as &lt;code>apply -k&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>kustomize&lt;/code> 允许用户以一个应用描述文件 （YAML 文件）为基础（Base YAML），然后通过 Overlay 的方式生成最终部署应用所需的描述文件。而其他用户可以完全不受影响的使用任何一个 Base YAML 或者任何一层生成出来的 YAML 。这使得每一个用户都可以通过类似fork/modify/rebase 这样 Git 风格的流程来管理海量的应用描述文件。这种 PATCH 的思想跟 Docker 镜像是非常相似的，它可以规避“字符替换”对应用描述文件的入侵，也不需要用户学习额外的 DSL 语法（比如 Lua）。&lt;/p>
&lt;p>而其成为 &lt;code>kubectl&lt;/code> 子命令则代表这 &lt;code>kubectl&lt;/code> 本身的插件机制的成熟，未来可能有更多的工具命令集成到 &lt;code>kubectl&lt;/code> 中。拿张磊大神的这张图不难看出，在 kubernetes 原生应用管理系统中，应用描述文件在整个应用管理体系中占据核心位置，通过应用描述文件可以组合和编排多种 kubernetes API 资源，kubernetes 通过控制器来保证集群中的资源与应用状态与描述文件完全一致。&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g23cqlrodkj21bq0r8znk.jpg" alt="">&lt;/p>
&lt;p>Kustomize 不像 Helm 那样需要一整套独立的体系来完成管理应用，而是完全采用 kubernetes 的设计理念来完成管理应用的目的。同时使用起来也更加的得心应手。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://kustomize.io/">Kustomize - kustomize.io&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://yq.aliyun.com/articles/697883">从Kubernetes 1.14 发布，看技术社区演进方向 - yq.aliyun.com&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Post: 单节点版rancher升级指南</title><link>https://guoxudong.io/post/rancher-update-2.2.1/</link><pubDate>Sun, 31 Mar 2019 11:15:35 +0800</pubDate><guid>https://guoxudong.io/post/rancher-update-2.2.1/</guid><description>
&lt;blockquote>
&lt;p>Rancher 不仅可以在任何云提供商的任何地方部署 Kubernetes 集群，而且还将它们集中在集中式的身份验证和访问控制之下。由于它与资源的运行位置无关，因此您可以轻松地在不同的环境部署你的 kubernetes 集群并操作他们。 Rancher 不是将部署几个独立的 Kubernetes 集群，而是将它们统一为一个单独的托管Kubernetes Cloud。&lt;/p>
&lt;/blockquote>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>目前我们使用的是 rancher 2.1.1版本，在去年 rancher 发布 &lt;code>v2.1.*&lt;/code> 版本的时候做过一次升级，当时遇到了很多问题，虽然都一一解决，但是并没有有效的记录下来，这里在升级 &lt;code>v2.2.*&lt;/code> 版本的时候做一个记录以便在今后升级的时候的提供参考作用。&lt;/p>
&lt;h2 id="升级前的准备">升级前的准备&lt;/h2>
&lt;ul>
&lt;li>首先查看当前 rancher 版本，记下这个版本号后面需要使用。查看方式就是登陆 rancher 在左下角就可以看到当前版本号，我们这里使用的&lt;code>v2.1.1&lt;/code>版本。&lt;/li>
&lt;li>打开官方文档，这里推荐对照官方文档进行升级，一般官方文档都会及时更新并提供最佳升级方法，而一般的博客会因为其写作时间、使用版本、部署环境的不同有所偏差。官方文档： &lt;a href="https://www.cnrancher.com/docs/rancher/v2.x/cn/upgrades/single-node-upgrade/">https://www.cnrancher.com/docs/rancher/v2.x/cn/upgrades/single-node-upgrade/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="升级">升级&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>首先获取正在运行的 rancher 容器 ID,由以下命令可知 &lt;code>RANCHER_CONTAINER_ID&lt;/code> 为 &lt;code>83167cb60134&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS
PORTS NAMES
83167cb60134 rancher/rancher:latest &lt;span style="color:#ed9d13">&amp;#34;entrypoint.sh&amp;#34;&lt;/span> &lt;span style="color:#3677a9">4&lt;/span> months ago Up &lt;span style="color:#3677a9">4&lt;/span> months 0.0.0.0:80-&amp;gt;80/tcp, 0.0.0.0:443-&amp;gt;443/tcp priceless_newton
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>停止该容器&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker stop {RANCHER_CONTAINER_ID}
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>创建正在运行的 Rancher Server 容器的数据卷容器，将在升级中使用，这里命名为 &lt;code>rancher-data&lt;/code> 容器。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>替换{RANCHER_CONTAINER_ID}为上一步中的容器ID。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>替换{RANCHER_CONTAINER_TAG}为你当前正在运行的Rancher版本，如上面的先决条件中所述。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker create --volumes-from {RANCHER_CONTAINER_ID} --name rancher-data rancher/rancher:{RANCHER_CONTAINER_TAG}
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>备份 &lt;code>rancher-data&lt;/code> 数据卷容器&lt;/p>
&lt;p>如果升级失败，可以通过此备份还原Rancher Server，容器命名:rancher-data-snapshot-&amp;lt;CURRENT_VERSION&amp;gt;.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>替换{RANCHER_CONTAINER_ID}为上一步中的容器ID。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>替换{CURRENT_VERSION}为当前安装的Rancher版本的标记。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>替换{RANCHER_CONTAINER_TAG}为当前正在运行的Rancher版本，如先决条件中所述 。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker create --volumes-from {RANCHER_CONTAINER_ID} --name rancher-data-snapshot-{CURRENT_VERSION} rancher/rancher:{RANCHER_CONTAINER_TAG}
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>拉取Rancher的最新镜像,这里确保有外网，可能拉取到新的镜像，如果没有外网，这里就需要将镜像上传到私有镜像仓库，将拉取地址设置为私有镜像仓库即可&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker pull rancher/rancher:latest
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>通过 &lt;code>rancher-data&lt;/code> 数据卷容器启动新的 Rancher Server 容器。&lt;/p>
&lt;p>&lt;strong>这里要注意到，我们这是使用的是独立容器+外部七层负载均衡，是通过阿里云SLB进行SSL证书认证，需要在启动的时候增加&lt;code>--no-cacerts&lt;/code>&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker run -d --volumes-from rancher-data --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher:latest --no-cacerts
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>升级过程会需要一定时间，不要在升级过程中终止升级，强制终止可能会导致数据库迁移错误。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>升级 Rancher Server后， server 容器中的数据会保存到 &lt;code>rancher-data&lt;/code> 容器中，以便将来升级。&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>删除旧版本 Rancher Server 容器&lt;/p>
&lt;p>如果你只是停止以前的Rancher Server容器(并且不删除它),则旧版本容器可能随着主机重启后自动运行，导致容器端口冲突。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>升级成功&lt;/p>
&lt;p>访问 rancher 可以看到右下角版本已经完成更新。&lt;/p>
&lt;p>&lt;img src="http://wx4.sinaimg.cn/large/ad5fbf65gy1g1lzcmucn6j20ck03qt8p.jpg" alt="image">&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Post: 自动合并Kubeconfig，实现多k8s集群切换</title><link>https://guoxudong.io/post/merge-kubeconfig/</link><pubDate>Sun, 17 Mar 2019 10:45:02 +0800</pubDate><guid>https://guoxudong.io/post/merge-kubeconfig/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;blockquote>
&lt;p>随着微服务和容器化的深入人心，以及kubernetes已经成为容器编排领域的事实标准，越来越多的公司将自己的服务迁移到kubernetes集群中。而随着kubernetes集群的增加，集群管理的问题就凸显出来，不同的环境存在不同的集群，不同的业务线不同的集群，甚至有些开发人员都有自己的集群。诚然，如果集群是使用公有云如阿里云或华为云的容器服务，可以登录其控制台进行集群管理；或者使用rancher这用的多集群管理工具进行统一的管理。但是在想操作&lt;code>istio&lt;/code>特有的容器资源，或者想使用&lt;code>istioctl&lt;/code>的时候，或者像我一样就是想使用&lt;code>kubectl&lt;/code>命令的同学，这个时候多集群的切换就显的十分重要了。&lt;/p>
&lt;/blockquote>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>&lt;code>kubectl&lt;/code>命令行工具通过&lt;code>kubeconfig&lt;/code>文件的配置来选择集群以及集群的API Server通信的所有信息。&lt;code>kubeconfig&lt;/code>用来保存关于集群，用户，名称空间和身份验证机制的信息。默认情况下&lt;code>kubectl&lt;/code>使用的配置文件名称是在&lt;code>$HOME/.kube&lt;/code>目录下的&lt;code>config&lt;/code>文件，可以通过设置环境变量KUBECONFIG或者&amp;ndash;kubeconfig指定其他的配置文件。详情可看官方文档https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/&lt;/p>
&lt;h2 id="原理">原理&lt;/h2>
&lt;p>使用&lt;code>kubeconfig&lt;/code>文件，您可以组织您的群集，用户和名称空间。 还可以定义上下文以快速轻松地在群集和名称空间之间切换。&lt;/p>
&lt;h3 id="上下文context">上下文(Context)&lt;/h3>
&lt;p>&lt;code>kubeconfig&lt;/code>文件中的上下文元素用于以方便的名称对访问参数进行分组。 每个上下文有三个参数：集群，命名空间和用户。 默认情况下，kubectl命令行工具使用当前上下文中的参数与集群进行通信。可以使用下面的命令设置上下文：&lt;/p>
&lt;pre>&lt;code>kubectl config use-context
&lt;/code>&lt;/pre>
&lt;h3 id="配置内容">配置内容&lt;/h3>
&lt;pre>&lt;code>kubectl config view
&lt;/code>&lt;/pre>
&lt;ol>
&lt;li>如果设置了&lt;code>--kubeconfig&lt;/code>标志，则只使用指定的文件。该标志只允许有一个实例。&lt;/li>
&lt;li>如果环境变量&lt;code>KUBECONFIG&lt;/code>存在，那么就使用该环境变量&lt;code>KUBECONFIG&lt;/code>里面的值，如果不存在该环境变量&lt;code>KUBECONFIG&lt;/code>，那么默认就是使用&lt;code>$HOME/.kube/config&lt;/code>文件。&lt;/li>
&lt;/ol>
&lt;h3 id="kubeconfig内容">&lt;code>kubeconfig&lt;/code>内容&lt;/h3>
&lt;p>从下面kubeconfig文件的配置来看集群、用户、上下文、当前上下文的关系就比较明显了。&lt;/p>
&lt;pre>&lt;code>apiVersion: v1
kind: Config
preferences: {}
clusters:
- cluster:
name: {cluster-name}
users:
- name: {user-name}
contexts:
- context:
cluster: {cluster-name}
user: {user-name}
name: {context-name}
current-context: {context-name}
&lt;/code>&lt;/pre>
&lt;h2 id="为何要自动合并">为何要自动合并&lt;/h2>
&lt;p>在日常的工作中，如果我们需要操作多个集群，会得到多个kubeconfig配置文件。一般的kubeconfig文件都是yaml格式的，但是也有少部分的集群kubeconfig时已json文件的形式给出的（比如华为云的=。=），比如我们公司再阿里云、华为云和自建环境上均存在kubernetes集群，平时操作要在多集群之间切换，这也就催生了我写这个工具（其实就是一个脚本）的动机。&lt;/p>
&lt;h2 id="自动合并生成kubeconfig">自动合并生成kubeconfig&lt;/h2>
&lt;p>众所周知，yaml是一种直观的能够被电脑识别的数据序列化格式，是一个可读性高并且容易被人类阅读的语言和json相比（没有格式化之前）可读性更强。而我这个工具并不是很关心kubeconfig的格式，只要将想要合并的kubeconfig放入指定文件即可。&lt;/p>
&lt;p>GitHub：https://github.com/sunny0826/mergeKubeConfig&lt;/p>
&lt;h3 id="适用环境">适用环境&lt;/h3>
&lt;ul>
&lt;li>需要在终端使用命令行管理多集群&lt;/li>
&lt;li>kubernetes集群中安装了istio，需要使用&lt;code>istioctl&lt;/code>命令，但是集群节点并没有安装&lt;code>istioctl&lt;/code>，需要在本地终端操作&lt;/li>
&lt;li>不愿频繁编辑.kube目录中的config文件的同学&lt;/li>
&lt;/ul>
&lt;h3 id="准备工作">准备工作&lt;/h3>
&lt;ul>
&lt;li>Python环境：2.7或者3均可&lt;/li>
&lt;li>需要依赖包：&lt;code>PyYAML&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="开始使用">开始使用&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>安装依赖：&lt;/p>
&lt;pre>&lt;code> pip install PyYAML
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>运行脚本&lt;/p>
&lt;ul>
&lt;li>
&lt;p>默认运行方式，kubeconfig文件放入&lt;code>configfile&lt;/code>文件,注意删掉作为示例的两个文件&lt;/p>
&lt;pre>&lt;code> python merge.py
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>自定义kubeconfig文件目录&lt;/p>
&lt;pre>&lt;code> python merge.py -d {custom-dir}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="运行后操作">运行后操作&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>将生成的config文件放入.kube目录中&lt;/p>
&lt;pre>&lt;code> cp config ~/.kube
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>查看所有的可使用的kubernetes集群角色&lt;/p>
&lt;pre>&lt;code> kubectl config get-contexts
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>更多关于kubernetes配置文件操作&lt;/p>
&lt;pre>&lt;code> kubectl config --help
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>切换kubernetes配置&lt;/p>
&lt;pre>&lt;code> kubectl config use-context {your-contexts}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>在使用kubernetes初期，在多集群之间我一直是频繁的切换&lt;code>.kube/config&lt;/code>文件来达到切换操作集群的目的。这也导致了我的&lt;code>.kube&lt;/code>目录中存在这多个类似于&lt;code>al_test_config.bak&lt;/code>、&lt;code>al_prod_config.bak&lt;/code>、&lt;code>hw_test_config.bak&lt;/code>的文件，本地环境已经自建环境，在集群切换的时候十分头疼。而后来使用&lt;code>--kubeconfig&lt;/code>来进行切换集群，虽然比之前的方法要方便很多，但是并不十分优雅。这个简单的小工具一举解决了我的文件，对于我这个&lt;code>kubectl&lt;/code>重度依赖者来说十分重要。&lt;/p></description></item><item><title>Post: 解决kubernetes中ingress-nginx配置问题</title><link>https://guoxudong.io/post/k8s-ingress-config/</link><pubDate>Wed, 06 Mar 2019 14:42:05 +0800</pubDate><guid>https://guoxudong.io/post/k8s-ingress-config/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>随着公司容器化的深入，越来越多的服务陆续迁移到kubernetes集群中，有些问题在测试环境并未凸显，但是在生产环境中这些问题就显得格外的扎眼。这里就对实践中kubernetes集群中的7层负载均衡器ingress遇到的问题进行总结。&lt;/p>
&lt;h2 id="https负载均衡器-ingress">HTTP(S)负载均衡器-ingress&lt;/h2>
&lt;p>Ingress是kubernetes API的标准资源类型之一，其本质就是一组基于DNS名称(host)或URL路径把请求转发至指定的Service资源的规则，&lt;strong>用于将集群外的请求流量转发至集群内部完成服务发布&lt;/strong>。&lt;/p>
&lt;p>Ingress控制器(Ingress Controller)可以由任何具有反向代理(HTTP/HTTPS)功能的服务程序实现，如Nginx、Envoy、HAProxy、Vulcand和Traefik等。Ingress控制器本身也作为Pod对象与被代理的运行为Pod资源的应用运行于同一网络中。我们在这里选择了NGINX Ingress Controller，由于对NGINX的配置较为熟悉，同时我们使用的kubernetes是阿里云的容器服务，构建集群的时候，容器服务会自带NGINX Ingress Controller。&lt;/p>
&lt;p>&lt;img src="http://wx2.sinaimg.cn/large/ad5fbf65ly1g0t3yj7wecj20w50doab9.jpg" alt="image">&lt;/p>
&lt;h2 id="根据实际情况ingress调优">根据实际情况Ingress调优&lt;/h2>
&lt;h3 id="1-解决400-request-header-or-cookie-too-large问题">1. 解决400 Request Header Or Cookie Too Large问题&lt;/h3>
&lt;h2 id="preview_only-false">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;h4 id="现象">现象&lt;/h4>
&lt;p>微信小程序需要调用后端接口，需要在header中传一段很长的token参数，直接使用浏览器访问该端口可以访问通，但是在加上token访问之后，会报“400 Request Header Or Cookie Too Large”&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">title&lt;/span>&amp;gt;400 Request Header Or Cookie Too Large&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">title&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">body&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">h1&lt;/span>&amp;gt;400 Bad Request&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">h1&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;Request Header Or Cookie Too Large&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">hr&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;nginx/1.15.6&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">center&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#6ab825;font-weight:bold">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="问题定位">问题定位&lt;/h4>
&lt;p>直接修改Service使用nodeport的形式访问，则没有报错，初步定位需要在ingress中nginx配置客户端的请求头，进入Ingress Controller的Pod查询配置，果然是请求头空间不足。&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ cat nginx.conf | grep client_header_buffer_size
client_header_buffer_size 1k;
$ cat nginx.conf | grep large_client_header_buffers
large_client_header_buffers &lt;span style="color:#3677a9">4&lt;/span> 8k;
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="解决方法">解决方法&lt;/h4>
&lt;p>在ingress中添加注释&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-nginx" data-lang="nginx">&lt;span style="color:#6ab825;font-weight:bold">nginx.ingress.kubernetes.io/server-snippet:&lt;/span> &lt;span style="color:#ed9d13">client_header_buffer_size&lt;/span> &lt;span style="color:#3677a9">2046k&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="preview_only-false-1">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;p>&lt;strong>Server snippet&lt;/strong>&lt;br>Using the annotation &lt;code>nginx.ingress.kubernetes.io/server-snippet&lt;/code> it is possible to add custom configuration in the server configuration block.
&lt;br>该注释是将自定义配置加入nginx的server配置中&lt;/p>
&lt;h2 id="preview_only-false-2">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;h3 id="2-解决请求超时问题">2. 解决请求超时问题&lt;/h3>
&lt;h4 id="现象-1">现象&lt;/h4>
&lt;p>有一个数据导出功能，需要将大量数据进行处理，然后以Excel格式返回，在导出一个大约3W条数据的时候，出现访问超时情况。&lt;/p>
&lt;p>&lt;img src="https://ws2.sinaimg.cn/mw690/ad5fbf65ly1g0ubdwwzo5j21b30bjaat.jpg" alt="image">&lt;/p>
&lt;h4 id="解决方法-1">解决方法&lt;/h4>
&lt;p>调整proxy_read_timeout，连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理
在ingress中添加注释&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-nginx" data-lang="nginx">&lt;span style="color:#6ab825;font-weight:bold">nginx.ingress.kubernetes.io/proxy-read-timeout:&lt;/span> &lt;span style="color:#3677a9">600&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>这里需要注意的事该注释的value需要时number类型，不能加s，否则将不生效&lt;/p>
&lt;/blockquote>
&lt;h3 id="3-增加白名单">3. 增加白名单&lt;/h3>
&lt;h4 id="现象-2">现象&lt;/h4>
&lt;p>在实际的使用中，会有一部分应用需要设置只可以在办公场地的网络使用，之前使用阿里云 SLB 的时候可以针对端口进行访问控制，但是现在走 ingress ，都是从80 or 443端口进，所以需要在 ingress 设置&lt;/p>
&lt;h4 id="解决方法-2">解决方法&lt;/h4>
&lt;blockquote>
&lt;p>&lt;strong>Whitelist source range&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>You can specify allowed client IP source ranges through the nginx.ingress.kubernetes.io/whitelist-source-range annotation. The value is a comma separated list of CIDRs, e.g. 10.0.0.0/24,172.10.0.1.&lt;/p>
&lt;/blockquote>
&lt;p>在 ingress 里配置 &lt;code>nginx.ingress.kubernetes.io/whitelist-source-range&lt;/code> ，如有多个ip段，用逗号分隔即可&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-nginx" data-lang="nginx">&lt;span style="color:#6ab825;font-weight:bold">nginx.ingress.kubernetes.io/whitelist-source-range:&lt;/span> &lt;span style="color:#3677a9">10&lt;/span>&lt;span style="color:#ed9d13">.0.0.0/24&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果想全局适用，可以在阿里云 SLB 里操作，也可以将该配置加入到 &lt;code>NGINX ConfigMap&lt;/code> 中。&lt;/p>
&lt;h2 id="preview_only-false-3">image:
caption: &amp;ldquo;Image from: &lt;a href="https://www.pexels.com">&lt;strong>Pexels&lt;/strong>&lt;/a>&amp;rdquo;
focal_point: &amp;quot;&amp;quot;
preview_only: false&lt;/h2>
&lt;p>根据工作中遇到的实际问题，持续更新中&amp;hellip;&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>使用NGINX ingress controller的好处就是对于nginx配置相对比较熟悉，性能也不差。相关nginx配置的对应的ingress可以在 &lt;a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/&lt;/a> 上查到。&lt;/p></description></item><item><title>Post: Pod质量服务类别(QoS)</title><link>https://guoxudong.io/post/k8s-qos/</link><pubDate>Mon, 04 Mar 2019 19:18:13 +0800</pubDate><guid>https://guoxudong.io/post/k8s-qos/</guid><description>
&lt;blockquote>
&lt;p>根据Pod对象的requests和limits属性，kubernetes将Pod对象归类到BestEffort、Burstable和Guaranteed三个服务质量（Quality of Service，QoS）类别。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Guaranteed
&lt;ul>
&lt;li>cpu:requests=limits&lt;/li>
&lt;li>memory:requests=limits&lt;/li>
&lt;li>这类Pod具有最高优先级&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Burstable
&lt;ul>
&lt;li>至少一个容器设置了cpu或内存资源的requests&lt;/li>
&lt;li>这类Pod具有中等优先级&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>BestEffort
&lt;ul>
&lt;li>未有任何一个容器设置requests或limits属性&lt;/li>
&lt;li>这类Pod具有最低优先级&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="http://ww1.sinaimg.cn/large/ad5fbf65ly1g0rv2ipzqkj20hx0edmx8.jpg" alt="">&lt;/p>
&lt;p>同级别优先级的Pod资源在OOM时，与自身的requests属性相比，其内存占用比例最大的Pod对象将被首先杀死。如上图同属Burstable类别的Pod A将先于Pod B被杀死，虽然其内存用量小，但与自身的requests值相比，它的占用比例95%要大于Pod B的80%。&lt;/p></description></item><item><title>Post: 阿里云日志服务采集k8s日志并实现livetail功能</title><link>https://guoxudong.io/post/dashboard-k8s/</link><pubDate>Thu, 14 Feb 2019 14:07:06 +0800</pubDate><guid>https://guoxudong.io/post/dashboard-k8s/</guid><description>
&lt;h1 id="前言">前言&lt;/h1>
&lt;blockquote>
&lt;p>目前的项目日志都是通过Logtail直接采集，投递到OSS持久化，同时可以通过阿里云日志服务、devops自建平台进行查看（虽然大部分人是直接登录ECS查看=。=），
在开始进行容器化之后，同样遇到日志的问题，目前的解决方案是阿里云日志服务持久化和展现格式化后的日志、使用rancher查看实时日志，
但是之前由于rancher平台出现一些问题，导致不能及时查看日志的情况，在这个背景下对阿里云日志服务采集k8s日志和livetail进行搭建并调研此方案是否可行。&lt;/p>
&lt;/blockquote>
&lt;h1 id="简介转自阿里云官方文档">简介（转自阿里云官方文档）&lt;/h1>
&lt;p>日志服务（Log Service，简称 LOG）是针对日志类数据的一站式服务，在阿里巴巴集团经历大量大数据场景锤炼而成。您无需开发就能快捷完成日志数据采集、消费、投递以及查询分析等功能，提升运维、运营效率，建立 DT 时代海量日志处理能力。&lt;/p>
&lt;h1 id="kubernetes日志采集组件安装">kubernetes日志采集组件安装&lt;/h1>
&lt;h2 id="安装logtail">安装Logtail&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>进入阿里云容器服务找到集群id
&lt;img src="https://guoxudong.io/images/source/log_ser.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过ssh登录master节点，或者任意安装了kubectl并配置了该集群kubeconfig的服务器&lt;/p>
&lt;/li>
&lt;li>
&lt;p>执行命令，将${your_k8s_cluster_id}替换为集群id&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">wget http://logtail-release-cn-hangzhou.oss-cn-hangzhou.aliyuncs.com/kubernetes/alicloud-log-k8s-install.sh -O alicloud-log-k8s-install.sh; chmod &lt;span style="color:#3677a9">744&lt;/span> ./alicloud-log-k8s-install.sh; sh ./alicloud-log-k8s-install.sh &lt;span style="color:#ed9d13">${&lt;/span>&lt;span style="color:#40ffff">your_k8s_cluster_id&lt;/span>&lt;span style="color:#ed9d13">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Project k8s-log-${your_k8s_cluster_id}下会自动创建名为config-operation-log的Logstore，用于存储alibaba-log-controller的运行日志。请勿删除此Logstore，否则无法为alibaba-log-controller排查问题。&lt;/li>
&lt;li>若您需要将日志采集到已有的Project，请执行安装命令sh ./alicloud-log-k8s-install.sh${your_k8s_cluster_id} ${your_project_name} ，并确保日志服务Project和您的Kubernetes集群在同一地域。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>该条命令其实就是执行了一个shell脚本，使用helm安装了采集kubernetes集群日志的组件&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-vim" data-lang="vim">#!&lt;span style="color:#ed9d13">/bin/&lt;/span>bash&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> [ $# -eq &lt;span style="color:#3677a9">0&lt;/span> ] ; then&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> echo &lt;span style="color:#ed9d13">&amp;#34;[Invalid Param], use sudo ./install-k8s-log.sh {your-k8s-cluster-id}&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> exit &lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>fi&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>clusterName=$(echo $&lt;span style="color:#3677a9">1&lt;/span> | tr &lt;span style="color:#ed9d13">&amp;#39;[A-Z]&amp;#39;&lt;/span> &lt;span style="color:#ed9d13">&amp;#39;[a-z]&amp;#39;&lt;/span>)&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>curl --connect-timeout &lt;span style="color:#3677a9">5&lt;/span> http:&lt;span style="color:#ed9d13">//&lt;/span>&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">200&lt;/span>&lt;span style="color:#ed9d13">/latest/&lt;/span>meta-data/region-id&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> [ $? != &lt;span style="color:#3677a9">0&lt;/span> ]; then&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> echo &lt;span style="color:#ed9d13">&amp;#34;[FAIL] ECS meta server connect fail, only support alibaba cloud k8s service&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> exit &lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>fi&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>regionId=`curl http:&lt;span style="color:#ed9d13">//&lt;/span>&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">200&lt;/span>&lt;span style="color:#ed9d13">/latest/&lt;/span>meta-data/region-id`&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>aliuid=`curl http:&lt;span style="color:#ed9d13">//&lt;/span>&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">100&lt;/span>.&lt;span style="color:#3677a9">200&lt;/span>&lt;span style="color:#ed9d13">/latest/&lt;/span>meta-data/owner-account-id`&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>helmPackageUrl=&lt;span style="color:#ed9d13">&amp;#34;http://logtail-release-$regionId.oss-$regionId.aliyuncs.com/kubernetes/alibaba-cloud-log.tgz&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>wget $helmPackageUrl -O alibaba-cloud-log.tgz&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> [ $? != &lt;span style="color:#3677a9">0&lt;/span> ]; then&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> echo &lt;span style="color:#ed9d13">&amp;#34;[FAIL] download alibaba-cloud-log.tgz from $helmPackageUrl failed&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> exit &lt;span style="color:#3677a9">1&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>fi&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>project=&lt;span style="color:#ed9d13">&amp;#34;k8s-log-&amp;#34;&lt;/span>$clusterName&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> [ $# -ge &lt;span style="color:#3677a9">2&lt;/span> ]; then&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> project=$&lt;span style="color:#3677a9">2&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>fi&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>echo [INFO] your k8s is using project : $project&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>helm install alibaba-cloud-log.tgz --name alibaba-log-controller \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set ProjectName=$project \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set RegionId=$regionId \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set InstallParam=$regionId \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set MachineGroupId=&lt;span style="color:#ed9d13">&amp;#34;k8s-group-&amp;#34;&lt;/span>$clusterName \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set Endpoint=$regionId&lt;span style="color:#ed9d13">&amp;#34;-intranet.log.aliyuncs.com&amp;#34;&lt;/span> \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set AlibabaCloudUserId=&lt;span style="color:#ed9d13">&amp;#34;:&amp;#34;&lt;/span>$aliuid \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set LogtailImage.Repository=&lt;span style="color:#ed9d13">&amp;#34;registry.$regionId.aliyuncs.com/log-service/logtail&amp;#34;&lt;/span> \&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> --set ControllerImage.Repository=&lt;span style="color:#ed9d13">&amp;#34;registry.$regionId.aliyuncs.com/log-service/alibabacloud-log-controller&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>installRst=$?&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> &lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">if&lt;/span> [ $installRst -eq &lt;span style="color:#3677a9">0&lt;/span> ]; then&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> echo &lt;span style="color:#ed9d13">&amp;#34;[SUCCESS] install helm package : alibaba-log-controller success.&amp;#34;&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> exit &lt;span style="color:#3677a9">0&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">else&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> echo &lt;span style="color:#ed9d13">&amp;#34;[FAIL] install helm package failed, errno &amp;#34;&lt;/span> $installRst&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span> exit &lt;span style="color:#3677a9">0&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>fi&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>命令执行后，会在kubernetes集群中的每个节点运行一个日志采集的pod：logatail-ds，该pod位于kube-system&lt;/p>
&lt;p>&lt;img src="https://guoxudong.io/images/source/log_detail.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>安装完成后，可使用以下命令来查看pod状态，若状态全部成功后，则表示安装完成&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ helm status alibaba-log-controller
LAST DEPLOYED: Thu Nov &lt;span style="color:#3677a9">22&lt;/span> 15:09:35 &lt;span style="color:#3677a9">2018&lt;/span>
NAMESPACE: default
STATUS: DEPLOYED
RESOURCES:
==&amp;gt; v1/ServiceAccount
NAME SECRETS AGE
alibaba-log-controller &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1beta1/CustomResourceDefinition
NAME AGE
aliyunlogconfigs.log.alibabacloud.com &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1beta1/ClusterRole
alibaba-log-controller &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1beta1/ClusterRoleBinding
NAME AGE
alibaba-log-controller &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1beta1/DaemonSet
NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
logtail-ds &lt;span style="color:#3677a9">16&lt;/span> &lt;span style="color:#3677a9">16&lt;/span> &lt;span style="color:#3677a9">16&lt;/span> &lt;span style="color:#3677a9">16&lt;/span> &lt;span style="color:#3677a9">16&lt;/span> &amp;lt;none&amp;gt; &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1beta1/Deployment
NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE
alibaba-log-controller &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#3677a9">1&lt;/span> &lt;span style="color:#40ffff">6d&lt;/span>
==&amp;gt; v1/Pod(related)
NAME READY STATUS RESTARTS AGE
logtail-ds-2fqs4 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-4bz7w 1/1 Running &lt;span style="color:#3677a9">1&lt;/span> 6d
logtail-ds-6vg88 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-7tp6v 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-9575c 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-bgq84 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-kdlhr 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-lknxw 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-pdxfk 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-pf4dz 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-rzsnw 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-sqhbv 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-vvtwn 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-wwmhg 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-xbp4j 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
logtail-ds-zpld9 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
alibaba-log-controller-85f8fbb498-nzhc8 1/1 Running &lt;span style="color:#3677a9">0&lt;/span> 6d
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;h1 id="配置日志组件展示">配置日志组件展示&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>在集群内安装好日志组件后，登录阿里云日志服务控制台，就会发现有一个新的project，名称为k8s-log-{集群id}
&lt;img src="https://guoxudong.io/images/source/log_src_de.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>创建Logstore
&lt;img src="https://guoxudong.io/images/source/log-1.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据导入
&lt;img src="https://guoxudong.io/images/source/log-2.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选择数据类型中选择docker标准输出
&lt;img src="https://guoxudong.io/images/source/log-3.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据源配置，这里可以使用默认的
&lt;img src="https://guoxudong.io/images/source/log-4.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选择数据源
&lt;img src="https://guoxudong.io/images/source/log-5.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>配置好之后等待1-2分钟，日志就会进来了
&lt;img src="https://guoxudong.io/images/source/log-6.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为了快速查询和过滤，需要配置索引
&lt;img src="https://guoxudong.io/images/source/log-7.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>添加容器名称、命名空间、pod名称作为索引（后续使用livetail需要）
&lt;img src="https://guoxudong.io/images/source/log-8.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>这样就完成了一个k8s集群日志采集和展示的基本流程了&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="livetail功能使用">livetail功能使用&lt;/h1>
&lt;h2 id="背景介绍">背景介绍&lt;/h2>
&lt;p>在线上运维的场景中，往往需要对日志队列中进入的数据进行实时监控，从最新的日志数据中提取出关键的信息进而快速地分析出异常原因。在传统的运维方式中，如果需要对日志文件进行实时监控，需要到服务器上对日志文件执行命令tail -f，如果实时监控的日志信息不够直观，可以加上grep或者grep -v进行关键词过滤。日志服务在控制台提供了日志数据实时监控的交互功能LiveTail，针对线上日志进行实时监控分析，减轻运维压力。&lt;/p>
&lt;h2 id="使用方法">使用方法&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>这里选择来源类型为kubernetes，命名空间、pod名称、容器名称为上一步新建的3个索引的内容，过滤关键字的功劳与tail命令后加的grep命令是一样的，用于关键词过滤
&lt;img src="https://guoxudong.io/images/source/log-9.png" alt="image">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>点击开启livetail，这时就有实时日志展示出来了
&lt;img src="https://guoxudong.io/images/source/log-10.png" alt="image">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>以上就是阿里云livetail日志服务功能&lt;/strong>&lt;/p></description></item><item><title>Post: kubernetes中pod同步时区问题</title><link>https://guoxudong.io/post/pod-timezone/</link><pubDate>Wed, 30 Jan 2019 20:18:13 +0800</pubDate><guid>https://guoxudong.io/post/pod-timezone/</guid><description>
&lt;blockquote>
&lt;p>新版监控大屏于18年最后一天正式上线，之后陆续进行了几次优化和修改，最近发现一个比较大的bug，就是监控显示的时间轴不对，显示的就是和目前的时间相差8小时，这就引出了docker中的时区问题&lt;/p>
&lt;/blockquote>
&lt;h1 id="问题的原因">问题的原因&lt;/h1>
&lt;p>默认的情况，在K8S里启动一个容器，该容器的设置的时区是UTC0，但是对用户而言，主机环境并不在UTC0。我们在UTC8。如果不把容器的时区和主机主机设置为一致，则在查找日志等时候将非常不方便，也容易造成误解。但是K8S以及Docker容器没有一个简便的设置/开关在系统层面做配置。都需要我们从单个容器入手做设置，具体有两个方法：&lt;/p>
&lt;ul>
&lt;li>直接修改镜像的时间设置，好处是应用部署时无需做特殊设置，但是需要手动构建Docker镜像。&lt;/li>
&lt;li>部署应用时，单独读取主机的“/etc/localtime”文件，即创建pod时同步时区，无需修改镜像，但是每个应用都要单独设置。&lt;/li>
&lt;/ul>
&lt;h1 id="问题的解决">问题的解决&lt;/h1>
&lt;p>这里我们选择第二种方法，即修改部署应用的yaml文件，创建pod时同步时区&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>extensions/v1beta1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Deployment&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>myweb&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">2&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">template&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">labels&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">app&lt;/span>:&lt;span style="color:#666"> &lt;/span>myweb&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">spec&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">containers&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>myweb&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">image&lt;/span>:&lt;span style="color:#666"> &lt;/span>nginx:apline&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">ports&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#3677a9">80&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#挂载到pod中&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>host-time&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#666"> &lt;/span>/etc/localtime &lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#999;font-style:italic">#需要被挂载的宿主机的时区文件&lt;/span>&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>- &lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>host-time&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">hostPath&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">path&lt;/span>:&lt;span style="color:#666"> &lt;/span>/etc/localtime&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="效果对比">效果对比&lt;/h1>
&lt;h2 id="修改时区前">修改时区前&lt;/h2>
&lt;p>&lt;img src="https://guoxudong.io/images/source/time-1.png" alt="image">&lt;/p>
&lt;h2 id="修改时区后">修改时区后&lt;/h2>
&lt;p>&lt;img src="https://guoxudong.io/images/source/time-2.png" alt="image">&lt;/p></description></item><item><title>Post: 为ingress配置SSL证书，实现HTTPS访问</title><link>https://guoxudong.io/post/https-ingress/</link><pubDate>Sat, 29 Dec 2018 21:28:13 +0800</pubDate><guid>https://guoxudong.io/post/https-ingress/</guid><description>
&lt;blockquote>
&lt;p>devops平台率先在公司内使用kubernetes集群提供后端服务，但是由于之前一直处于探索阶段，所以使用的事http的方式提供后端服务，但是在开发统一入口后，出现了访问HTTPS页面的跨域问题，由此引出了后端服务配置SSL证书的问题&lt;/p>
&lt;/blockquote>
&lt;h1 id="使用rancher配置ssl证书">使用rancher配置SSL证书&lt;/h1>
&lt;h2 id="下载ssl证书文件">下载SSL证书文件&lt;/h2>
&lt;p>首先需要获得SSL证书文件，可以直接在阿里云SSL证书管理控制台下载&lt;/p>
&lt;p>选中需要下载证书，选择下载nginx证书
&lt;img src="https://guoxudong.io/images/source/zhengshu.png" alt="image">&lt;/p>
&lt;h2 id="将证书上传项目">将证书上传项目&lt;/h2>
&lt;p>打开rancher，选择要使用证书的项目，点击资源中的证书&lt;/p>
&lt;h2 id="将证书上传项目-1">将证书上传项目&lt;/h2>
&lt;p>打开rancher，选择要使用证书的项目，点击资源中的证书
&lt;img src="https://guoxudong.io/images/source/https-1.png" alt="image">
添加证书，点击从文件上传
&lt;img src="https://guoxudong.io/images/source/https-2.png" alt="image">
上传证书文件中的秘钥和证书，点击保存即可&lt;/p>
&lt;h1 id="使用yaml上传证书">使用yaml上传证书&lt;/h1>
&lt;p>这个证书的原理其实是在相应的命名空间创建了一个包含证书信息的secrets&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#6ab825;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#666"> &lt;/span>v1&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">data&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tls.crt&lt;/span>:&lt;span style="color:#666"> &lt;/span>{私钥}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">tls.key&lt;/span>:&lt;span style="color:#666"> &lt;/span>{证书}&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">kind&lt;/span>:&lt;span style="color:#666"> &lt;/span>Secret&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">name&lt;/span>:&lt;span style="color:#666"> &lt;/span>keking-cn&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666"> &lt;/span>&lt;span style="color:#6ab825;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#666"> &lt;/span>devops-plat&lt;span style="color:#666">
&lt;/span>&lt;span style="color:#666">&lt;/span>&lt;span style="color:#6ab825;font-weight:bold">type&lt;/span>:&lt;span style="color:#666"> &lt;/span>kubernetes.io/tls&lt;span style="color:#666">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在kubernetes上运行该yaml即可&lt;/p>
&lt;h1 id="rancher中证书绑定">rancher中证书绑定&lt;/h1>
&lt;p>选中需要绑定证书的ingress，点击编辑，选中证书，保存即可（由于ingress-controller中没有绑定默认证书，所以这里不能选中默认）
&lt;img src="https://guoxudong.io/images/source/https-3.png" alt="image">
保存完毕，证书即可生效&lt;/p></description></item><item><title>Post: Kubernetes删除一直处于Terminating状态的namespace</title><link>https://guoxudong.io/post/k8s-d-n/</link><pubDate>Fri, 16 Nov 2018 18:18:13 +0800</pubDate><guid>https://guoxudong.io/post/k8s-d-n/</guid><description>
&lt;blockquote>
&lt;p>近期由于公司需要将部署在ucloud上的rancher迁移到阿里云上，所以需要将原有Rancher依赖的namespace（cattle-system）删除，但在删除中出现了删除的namespace一直处于Terminating状态的情况&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://guoxudong.io/images/source/d-n-1.png" alt="imgage">&lt;/p>
&lt;h1 id="解决方案">解决方案&lt;/h1>
&lt;p>运行命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl edit namespaces cattle-system
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到namespaces的yaml配置：&lt;/p>
&lt;p>&lt;img src="https://guoxudong.io/images/source/d-n-2.png" alt="imgage">&lt;/p>
&lt;p>将finalizer的value删除，这里将其设置为[]&lt;/p>
&lt;p>保存即可看到该namespace已被删除&lt;/p>
&lt;p>&lt;img src="https://guoxudong.io/images/source/d-n-3.png" alt="imgage">&lt;/p></description></item><item><title>Post: kubernetes集群概述</title><link>https://guoxudong.io/post/k8s-topo/</link><pubDate>Wed, 03 Oct 2018 12:18:13 +0800</pubDate><guid>https://guoxudong.io/post/k8s-topo/</guid><description>
&lt;blockquote>
&lt;p>随着2017年AWS，Azure和阿里云相继在其原有容器服务上新增了对kubernetes的支持，而Docker官网也在同年10月宣布同时支持Swarm好kubernetes容器编排系统。kubernetes俨然已成为容器编排领域事实上的标准，而2018年更是各大公司相继将服务迁移到kubernetes上，而kubernetes则以惊人更新速度，保持着每个季度发布一个大版本的速度高速发展着。&lt;/p>
&lt;/blockquote>
&lt;h1 id="kubernetes特征">kubernetes特征&lt;/h1>
&lt;p>kubernetes是一种在一组主机上运行和协同容器化应用程序的系统，旨在提供可预测性、可拓展性与高可用性的方法来完全管理容器化应用和服务的生命周期平台。用户可以定义应用程序的运行方式，以及与其他应用程序或外部世界交互的途径，并能实现服务的扩容和缩容，执行平滑滚动更新，以及在不同版本的应用程序之间调度流量以测试功能或回滚有问题的部署。kubernetes提供了接口和可组合帆软平台原语，使得用户能够以高度的灵活性和可靠性定义及管理应用程序。&lt;/p>
&lt;h1 id="kubernetes组件及网络通信">kubernetes组件及网络通信&lt;/h1>
&lt;p>kubernetes集群的客户端可以分为两类：API Server客户端和应用程序（运行为Pod中的容器）客户端。
&lt;img src="https://guoxudong.io/images/source/kubernetes-topo.png" alt="image">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>第一类客户端通常包含用户和Pod对象两种，它们通过API Server访问kubernetes集群完成管理任务，例如，管理集群上的各种资源对象。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第二类客户端一般也包含人类用户和Pod对象两种，它们的访问目标是Pod上运行于容器中的应用程序提供的各种具体的服务，如redis或nginx等，不过，这些访问请求通常要经由Service或Ingress资源对象进行。另外，第二类客户端的访问目标对象的操作要经由第一类客户端创建和配置完成后才进行。&lt;/p>
&lt;p>访问API Server时，人类用户一般借助于命令行工具kubectl或图形UI（例如kubernetes dashboard）进行，也通过编程接口进行访问，包括REST API。访问Pod中的应用时，其访问方式要取决于Pod中的应用程序，例如，对于运行Nginx容器的Pod来说，其最常用工具就是浏览器。&lt;/p>
&lt;p>管理员（开发人员或运维人员）使用kubernetes集群的常见操作包括通过控制器创建Pod，在Pod的基础上创建Service供第二类客户端访问，更新Pod中的应用版本（更新和回滚）以及对应用规模进行扩容或缩容等，另外还有集群附件管理、存储卷管理、网络及网络策略管理、资源管理和安全管理等。&lt;/p>
&lt;/li>
&lt;/ul></description></item></channel></rss>